{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4E0jSQqcPWEh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import imageio\n",
        "from torch import nn\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fGCufEHPWEl"
      },
      "source": [
        "## Problem definition\n",
        "Suppose we have a time series P(t). P(t) is the solution of a differential equation $$ \\frac{dP}{dt} = f(t,P(t))$$ We don't know the differential equation, nor the solution-time series P(t). We have some points (ti, pi) but not P(t). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBU_OdKPWEp"
      },
      "source": [
        "## time series - sine data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khqfO6bnPWEq"
      },
      "source": [
        "Let's suppose a simple example, P(t) = sint, which is solution of diff.eq P'(t) = cost. \n",
        "##### We pretend like we don't know P(t), just some points (ti,pi), specifically we have 100 points in (-3,3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_xnSiZ6PWEs"
      },
      "source": [
        "# First approach :\n",
        "One first approach is to approximate P(t) with interpolation, for example a Neural Network. We can use also other models like splines. Neural Network is a continues function approximator with great results, for this reason is a good choice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMnoEZZOPWEt"
      },
      "source": [
        "#### model for P(t) approximation\n",
        "is nn.Sequential with 200 neurons in hidden layer, it's the same with model 1 but written in other way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4-5TmE_fPWEv"
      },
      "outputs": [],
      "source": [
        "#net2 is the network that approximates the time series P(t)\n",
        "net2 = torch.nn.Sequential(\n",
        "        torch.nn.Linear(1, 10),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(10, 1),\n",
        "    )\n",
        "optimizer = torch.optim.Adam(net2.parameters(), lr=0.1)\n",
        "loss_func = torch.nn.MSELoss() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dTMrxNARPWEy"
      },
      "outputs": [],
      "source": [
        "x = torch.unsqueeze(torch.linspace(-5, 5, 100), dim=1) \n",
        "\n",
        "y = torch.sin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "46ngKPOcPWEz",
        "outputId": "a53aaf8a-7a61-40e4-dded-4d3c9ad19277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7910, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6053, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.6698, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5910, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5266, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5443, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5732, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5546, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5156, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4966, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.5074, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4985, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4753, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4504, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4342, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4271, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4208, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.4080, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3889, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3690, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3524, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3378, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3221, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3047, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2880, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2733, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2588, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2095, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1810, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1660, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1165, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0003, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#training\n",
        "my_images = []\n",
        "fig, ax = plt.subplots(figsize=(16,10))\n",
        "losses=[]\n",
        "for t in range(300):\n",
        "  \n",
        "    prediction = net2(x)     # input x and predict based on x\n",
        "\n",
        "    loss = loss_func(prediction, y) \n",
        "    losses.append(loss)\n",
        "    print(loss)\n",
        "\n",
        "    optimizer.zero_grad()   # clear gradients for next train\n",
        "    loss.backward()         # backpropagation, compute gradients\n",
        "    optimizer.step()        # apply gradients\n",
        "    \n",
        "    if t % 10 == 0:\n",
        "        # plot and show learning process\n",
        "        plt.cla()\n",
        "        ax.set_xlim(-11.0, 13.0)\n",
        "        ax.set_ylim(-1.1, 1.2)\n",
        "        ax.scatter(x.data.numpy(), y.data.numpy(), color = \"blue\")\n",
        "        ax.plot(x.data.numpy(), prediction.data.numpy(), 'g-', lw=3)\n",
        "        ax.text(9.50, -0.8, 'Step = %d' % t, fontdict={'size': 18, 'color':  'red'})\n",
        "        ax.text(9.50, -0.95, 'Loss = %.4f' % loss.data.numpy(),\n",
        "                fontdict={'size': 18, 'color':  'red'})\n",
        "\n",
        "        # Used to return the plot as an image array \n",
        "        # (https://ndres.me/post/matplotlib-animated-gifs-easily/)\n",
        "        fig.canvas.draw()       # draw the canvas, cache the renderer\n",
        "        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
        "        image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "        my_images.append(image)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "# save images as a gif    \n",
        "imageio.mimsave('./curve_2_bignet.gif', my_images, fps=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0pX-NgPWE1",
        "outputId": "a9720b88-dee4-4802-d6cc-a0aa1c121968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model trained and stored at net_six.pth\n"
          ]
        }
      ],
      "source": [
        "#we want to store the model that we train!\n",
        "torch.save(net2.state_dict(),\"net_sinx.pth\")\n",
        "print(\"model trained and stored at net_six.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G9ckTS_PWE2",
        "outputId": "6490d57e-950b-4f1d-8c13-e3c0c82dc9ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZddwwDk7PWE3",
        "outputId": "e2303b3c-9d4a-4688-f660-20956bf53627"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0003, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "loss_func(prediction,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jpbIa0QPWE4",
        "outputId": "6ab9e17f-a066-4dc4-8ed1-acd2b32d2526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0003, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "loss_func(net2(x), y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkqyWXRkPWE5"
      },
      "source": [
        "### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "is6UkrrQPWE6",
        "outputId": "a2c50690-aa48-4387-b27e-4f7e8af7de92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f808672ff10>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3iU15X48e9RBzXUK4gmiiS6DLaJGzYyuIDjksV2dknixMkm2Wy2JLF/2U3PbnaTTbLJepN4nThOcwlxArbBgDHYjm2KwFRRJKoQaogioV7O74955chYos1I75TzeZ55NPMWzRlm0Jl733vvEVXFGGNM6ApzOwBjjDHuskRgjDEhzhKBMcaEOEsExhgT4iwRGGNMiItwO4ArkZqaqqNHj3Y7DGOMCShbt249qapp528PyEQwevRoSktL3Q7DGGMCiogc7W+7dQ0ZY0yIs0RgjDEhzhKBMcaEOEsExhgT4iwRGGNMiPNJIhCRX4hInYjsHmC/iMiPRKRCRHaKyMw++5aKSLlzW+qLeIwxxlw6X7UIfgksuMD+hUC+c3sY+AmAiCQDXwXmALOBr4pIko9iMsYYcwl8Mo9AVV8XkdEXOGQx8Cv1rHm9UURGiEgWcCOwVlVPAYjIWjwJ5WlfxHWpOrt72FF5hn01TZxt7UQERiUPZ1ruCEYmDx/KUIwZUqrK/tomyk40Un22DYD0+GgKshMoyEpARFyO0AyFoZpQlgNU9nl83Nk20Pb3EZGH8bQmGDVqlE+CqjrTys9eO8iKHSc409LZ7zEFWQl85NrR3DUjh6gIu6RigkNTWye/3niUZzZXcuxUS7/HZCfGcF/xSD46dzQjhkcNcYRmKAXMzGJVfRx4HKC4uNirajptnd38+NVyHn/9EAALi7JYWJTJlNxE0uKj6epWjjQ08/bBBp7fVsUX/7CTxzZU8G8fnMLc8anevxhjXKKq/PGdKr75YhmnWzqZOz6FT984juLRyeQmDQPgxJlWth07w4s7T/Df68r5xZ8P86WFk3hg9ijCwqyFEIyGKhFUASP7PM51tlXh6R7qu33DYAZSeaqFT/yqlH01Tdw9M4d/LplI9ohh7zkmOgIKsxMpzE7koQ+MYcP+er7+wh4efGITn7x+LF+4dSIR4dY6MIGlub2LLyzbwcpdNcwcNYJf3lnItJEj3nfc2LQ4xqbFce+sXPbVNPLNF8v4lz/tZk1ZLT9aMt1aB0FIfFWq0rlG8KKqFvWz73bgs8BteC4M/0hVZzsXi7cCvaOItgGzeq8ZDKS4uFivZK2hjYca+NvfbKVH4YdLpnPTxPRLPrets5tvvVTGbzYe44YJafz0w7MYFhV+2TEY44bqs6189MktHKht4osLJvHwdWMv+du9qvLbTcf4+gt7yB4xjF99bDZ5KbGDHLEZDCKyVVWLz9/uq+GjTwNvAxNF5LiIPCQinxKRTzmHrAQOARXA/wGfBnD+4H8T2OLcvnGxJHClVJXH1leQHBvF8s/MvawkABATGc637prCv989hTfK61n65GbOtXcNRqjG+FT12VaWPL6RqtOtPPnR2XzqhnGX1cUjInz46jyeefgaGls7+aufbeRQ/blBjNgMNZ+1CIbSlbYITjd3EB4uJMREevX8K3ac4B+e3U5xXhK/emg20RHWMjD+qa6pjft++janznXwq4dmM2OUd6Oz91Y38uATm4gIE/74mbnknNetavzboLYIAkVSbJTXSQBg0bRsvv+haWw6fIovLdtJICZTE/zaOrt5+FdbqWts5ykfJAGAyVkJ/O4Tc2jt7OZjT26hsa3/0XYmsIRUIvClxdNz+OeSCfxp+wkeW1/hdjjGvIeq8sVlO9leeYYf/NV0ZvogCfSalJnATx6cxcH6c/zd796hp8e+CAU6SwRe+MxN41k8PZvvrz3AWwdPuh2OMe/6zaZjrNhxgi/cOpEFRZk+//0fyE/la4sKee1APT957aDPf78ZWpYIvCAi/NsHpzA6NZa/f2Y79U3tbodkDPtrmvjWi2VcPyGNv71h3KA9z4NzRnHntGz+a81+Nh8elDEeZohYIvBSbHQEjz0wk7OtnXxleb9r7hkzZNo6u/nc0+8QHxPBf903bVAngHm+CBUxMnk4//jcdpptFF3AskTgA5OzEvj8Lfms2l3Dyl3VbodjQthj6yvYX9vEd++bRlp89KA/X3xMJN+9dxrHT7fy3dX7B/35zOCwROAjD183lik5iXxl+W5ONXe4HY4JQQdqm/jpawe5e0bOZc+T8cbsMcn8zTV5PPX2EUqPWBdRILJE4CMR4WH8571TOdPSyX+s2ud2OCbE9PQojz6/i7joCL58++Qhf/4vLphEduIwHn1+F53dPUP+/MY7lgh8aLKzUulzWyvZdfys2+GYELJs23G2Hj3Nl28vICVu8LuEzhcXHcHXFhVSXneO3248OuTPb7xjicDHPndLPimxUXzthT020cwMiZaOLr63ej8zRo3gnpn9ruI+JG6ZnM51+al8f+0B6x4NMJYIfCwhJpIv3DqRrUdPs3z7CbfDMSHg8dcPUdfUzr/cPtnVQjIiwr/eUUBzRzffX2sXjgOJJYJBcN+skRRmJ/C9Nfvp6LL+UjN4ahvb+Nlrh7h9Shaz8pLdDocJGfF8eM4ont5caQvTBRBLBIMgLEz451sncvx0K8+WVl78BGOu0PfXHKCrp4cvLpjodijv+uy8fKLCw/jhK+Vuh2IukSWCQXLjhDSK85L48bpyWju63Q7HBKGjDc0s23acB+fk+VV9gLT4aD46dzQv7DzBvppGt8Mxl8ASwSAR8bQK6pra+fXGI26HY4LQ/7xaQUSY8OkbB28ZiSv18PVjiYuK4L/WHHA7FHMJLBEMoqvHpnBdfio/2XDQpt8bnzrW0MLz71Rx/+xRpCfEuB3O+4wYHsUnrh/L2rJadlSecTsccxG+qlC2QET2i0iFiDzSz/4fiMh253ZARM702dfdZ98KX8TjTz5/ywROt3Ty9OZjbodigsj/rC8nPEz4Wz9sDfT62AfGkDgskv/dYMu0+zuvE4GIhAOPAQuBAuB+ESnoe4yq/oOqTlfV6cCPgef77G7t3aeqi7yNx9/MyktizphknnjjMO1ddq3AeK/yVAt/2FbFA7NHkeGHrYFecdERLL0mj9V7aqmoa3I7HHMBvmgRzAYqVPWQqnYAzwCLL3D8/cDTPnjegPHpm8ZT09jG8ndsXoHx3i/ePIwAn7xhrNuhXNTSa0cTExnGT1875HYo5gJ8kQhygL5jJI87295HRPKAMcCrfTbHiEipiGwUkbsGehIRedg5rrS+vt4HYQ+d6/NTKcxO4KevHaTbqjkZL5xt6eTZLZUsmpZNVqL/1wtOiYtmyVWj+NM7VZw40+p2OGYAQ32xeAmwTFX79pHkOcWUHwB+KCL9dnqq6uOqWqyqxWlpaUMRq8+IePpyD51sZs2eGrfDMQHsd5uP0dLRzcev8//WQK+PXzcGBf7vDWsV+CtfJIIqYGSfx7nOtv4s4bxuIVWtcn4eAjYAM3wQk99ZWJTFqOTh/OLNw26HYgJUR1cPT755mA+MT6UgO8HtcC5ZbtJwFk3L5rktlTRZsXu/5ItEsAXIF5ExIhKF54/9+0b/iMgkIAl4u8+2JBGJdu6nAnOBMh/E5HfCw4S/uSaPLUdOs7vKViY1l2/FjhPUNbXziesDpzXQ6yPXjqa5o5tlW4+7HYrph9eJQFW7gM8Cq4G9wHOqukdEviEifUcBLQGe0fcuyTkZKBWRHcB64DuqGpSJAOC+4pEMjwrnl28dcTsUE2BUlSfeOMTEjHiuz091O5zLNm3kCGaOGsFTbx2hx66T+R2fXCNQ1ZWqOkFVx6nqt51tX1HVFX2O+ZqqPnLeeW+p6hRVneb8/Lkv4vFXicMiuWdmLiu2n+DkOSt0by7dliOn2VfTxEfnjnZ1hVFvfGTuGI40tPDagcAa7BEKbGbxEFt6bR4d3T08YxPMzGX4zcajxMdEsGh6ttuhXLGFRZlkJETzpLWI/Y4lgiE2Pj2e6/JT+fXGo1bSz1yS+qZ2Vu2u5t5ZuQyPinA7nCsWGR7Gh+fk8fqBeg7aEtV+xRKBCz5y7WhqG9tZW1brdigmADxXWklnt/LgnDy3Q/Ha/XNGERUexq/ftnKW/sQSgQtunJhOdmKMrT9kLqq7R/ndpmNcOy6F8elxbofjtdS4aG4tyuT5bcdp67QlV/yFJQIXhIcJH7pqJG+Un6TyVIvb4Rg/tmF/HVVnWvnw1YHfGuh1/1UjaWzrYtXuardDMQ5LBC75UPFIwgSe3WIVzMzAfrPxKOnx0cwvyHA7FJ+5emwKeSnDeXqzffb9hSUCl2SPGMYNE9L4/dZKuuyiselH1ZlWNhyoZ8lVI4kMD57/qmFhwl9dNZLNh0/ZRWM/ETyfrgC0ZPYoahvbWb/fxlWb93t+63FUPRMRg829s3KJCBNrEfsJSwQumjcpnfT4aJtTYN5HVVm27ThXj01mZPJwt8PxufT4GG6enM4fth6no8taxG6zROCiyPAw7ivOZf3+OqrP2hK95i82Hz7F0YYW7psVfK2BXktmj6KhucOGUfsBSwQu+1DxSHoU/vjOQAu2mlD0+63HiYuOYOGUTLdDGTTX56eRnRjDc6XWPeQ2SwQuy0uJ5arRSTy/rYr3rsdnQlVzexcrd1Vz+5SsgJ5JfDHhYcJdM3J4o7yeuqY2t8MJaZYI/MDdM3OpqDvHLlue2gAv7aqmpaOb+4pz3Q5l0N09M4cehRXbrYyrmywR+IHbpmQRFRHG89use8jAstLjjE2NZVZektuhDLrx6fFMy020z77LLBH4gcRhkcyfnMGKHSdsIboQd+RkM5uPnOKeWbkBu9z05frgjBzKqhvZV9PodighyxKBn7h7Zg6nmjt4zeYUhLQ/ba9CxPN5CBV3TssmIkz4o7UKXOOTRCAiC0Rkv4hUiMgj/ez/iIjUi8h25/bxPvuWiki5c1vqi3gC0fUT0kiJjeL5d6yUX6hSVVZsP8GcMclkJQ5zO5whkxIXzY0T0/jT9iq6rXqZK7xOBCISDjwGLAQKgPtFpKCfQ59V1enO7Qnn3GTgq8AcYDbwVREJ/o7RfkSGh3HntGxeKavjbIsV+A5Fu6saOXSymcXTQ6c10OvumbnUNrbz1sGTbocSknzRIpgNVKjqIVXtAJ4BFl/iubcCa1X1lKqeBtYCC3wQU0C6Z2YuHd09vLjLRlCEouXbq4gMF24rynI7lCE3b1I68TERdtHYJb5IBDlA3xkhx51t57tHRHaKyDIR6Z0ueannIiIPi0ipiJTW1wdnP3pRTgLj0+NYbkPpQk53j/LCzhPcODGdxOGRbocz5GIiw7ljajYv766hpaPL7XBCzlBdLH4BGK2qU/F863/qcn+Bqj6uqsWqWpyWlubzAP2BiLBoWjZbjpyyJSdCzKbDDdQ2trM4gGsSe2vRtGxaO7t5dV+d26GEHF8kgiqg74Iouc62d6lqg6q2Ow+fAGZd6rmh5o6pWajCSzutaEcoWbH9BLFR4dw8KXjqDlyu2WOSSY+P5oUd1iIear5IBFuAfBEZIyJRwBJgRd8DRKRvp+ciYK9zfzVQIiJJzkXiEmdbyBqbFkdRTgIvWCIIGe1d3azcVc2thZkMiwp3OxzXhIcJt0/NYv3+ehrbbMDEUPI6EahqF/BZPH/A9wLPqeoeEfmGiCxyDvuciOwRkR3A54CPOOeeAr6JJ5lsAb7hbAtpd07NZkflGStjGSI27K+nsa2LxTNCb7TQ+e6clk1HVw9r99iKpEPJJ9cIVHWlqk5Q1XGq+m1n21dUdYVz/1FVLVTVaap6k6ru63PuL1R1vHN70hfxBLrbp3oaUC/stCZyKFix/QQpsVHMHZfidiiumzFyBDkjhvGiffaHlM0s9kO5ScOZOWoEL+yw7qFg19zexSt7a7l9ahYRQVSO8kqJCHdMy+KN8pOcbu5wO5yQYZ88P3XntGz2VjdSUdfkdihmEL26r472rh7umBq6o4XOd+fUbLp6lJf31LgdSsiwROCnbp+ShQjWKghyK3dVkxYfHRIrjV6qwuwExqbG2uihIWSJwE+lJ8Rw9ZgUXth5wgrWBKmWji7W769jYVEm4WGhsdLopRAR7piaxcZDDVawZohYIvBjd07L5lB9M2XVtjxvMFq/r562zh5umxJ6S0pczJ3TsulRWGnDqIeEJQI/tsD5prhql/WVBqOVu6pJjYvmqtHJbofid/Iz4pmYEc9K++wPCUsEfiw5Noo5Y5JZtdu+FQWb1g7PUgoLijKsW2gAC4oy2XL0lHUPDQFLBH5uYVEmB+ubKa+10UPBZMP+Olo7u61b6AIWTslEFdbY5LJBZ4nAz91amIkI1kQOMi/tqiYlNorZ1i00oIkZ8YxJjeXl3fbZH2yWCPxcekIMxXlJ1j0URNqcFTZvLcq0SWQXICIsKMrk7UMNNrlskNmnMAAsKMpiX00TR042ux2K8YEN++tp6ejmdusWuqjbirLo7lHW7rXuocFkiSAALCjKBGCVNZGDwspd1e8OBDAXVpSTQG7SMOseGmSWCAJAzohhTMtN5GXrHgp4bZ3drNtby62FGdYtdAlEhAWFmfy5/KQtTT2I7JMYIBYUZbHj+FmOn7alqQPZ6wfqae6w0UKXY+GUTDq6e3h1r1UuGyyWCALEQqd7yJrIge3l3TWMGB7J1WNtyelLNWNkEhkJ0TZgYhD5JBGIyAIR2S8iFSLySD/7/1FEypzi9etEJK/Pvm4R2e7cVpx/rvEYnRrL5KwESwQBrKu7h3X76pg3KZ1I6xa6ZGFhwq2Fmbx2oN4K2w8Srz+NIhIOPAYsBAqA+0Wk4LzD3gGKneL1y4D/7LOvVVWnO7dFmAEtLMpk67HT1DXaTMtAtPnIKc62dlJSkOl2KAFnQVEmbZ09bNhf73YoQckXX0tmAxWqekhVO4BngMV9D1DV9ara27m9EU+RenOZFhZ5ZlqutnXaA9KaPbVER4Rx/YRUt0MJOLNHJ5McG2Uj5waJLxJBDlDZ5/FxZ9tAHgJW9XkcIyKlIrJRRO4a6CQRedg5rrS+PjS/FeRnxDMuLdZmGQcgVWVtWS3X5acxPCrC7XACTkR4GCUFGby6t5a2zm63wwk6Q9pRKSIfBoqB7/bZnKeqxcADwA9FZFx/56rq46parKrFaWlpQxCtf1pYlMXmI6dspmWA2XOikaozrZQUZrgdSsBaUJRJc0c3b1acdDuUoOOLRFAFjOzzONfZ9h4icgvwZWCRqrb3blfVKufnIWADMMMHMQWt+QUZdPcor+6zoXSBZE1ZLWECN09KdzuUgHXNuBTioiNYW2azjH3NF4lgC5AvImNEJApYArxn9I+IzAB+hicJ1PXZniQi0c79VGAuUOaDmILWlJxEMhNi7D9DgFlbVktxXjIpcdFuhxKwoiPCuXFiGq/sraW7x6r2+ZLXiUBVu4DPAquBvcBzqrpHRL4hIr2jgL4LxAG/P2+Y6GSgVER2AOuB76iqJYILCAsT5hdk8NqBeusrDRCVp1rYW91o3UI+UFKYyclzHWyvPO12KEHFJ1etVHUlsPK8bV/pc/+WAc57C5jiixhCSUlhBr/eeJQ/l5/klgL74+Lv1jitt/n2XnntxolpRIYLa/bUMivP1mryFZvVEoDmjEkhPjqCNWU2eigQrNlTw8SMePJSYt0OJeAlxHhmZa/eU4OqdQ/5iiWCABQVEcZNk9JZt7fO+kr93KnmDrYcOWXdQj5UUpjJkYYWKurOuR1K0LBEEKBKCjNoaO5g2zHrK/Vnr+6ro0ex2cQ+NH+yJ6musQETPmOJIEDdMCGNqPAw1tgsY7+2Zk8NWYkxFOUkuB1K0MhMjGHayBGWCHzIEkGAio+J5NrxKawpq7W+Uj/V2tHN6+X1lBRkICJuhxNUSgoy2FF5hpqztu6WL1giCGDzCzI42tDCgVrrK/VHb5TX09bZw3zrFvK5EmcElpWw9A1LBAGst690rY0e8ktrymqJj4lgzlgb5uhr49PjGJMaaxMrfcQSQQBLT4hhxijrK/VHXd09rNtby81We2BQiAglBRm8fdBKWPqCfUIDXElBJjuPn+XEmVa3QzF9bD16mtMtnZQUWrfQYJlfkEFnt1qNAh+wRBDgesenv2J9pX5lTVktUeFhXD8hdFfKHWwzRiWRGhdl3UM+YIkgwI1Li2NsmvWV+hNVZU1ZDXPHe1bLNIMjPEy4ZXIG6/fV0d5l6255wxJBECgpyOTtgw2cbbW+Un+wr6aJylOt1i00BEoKMzjX3sXGQ6fcDiWgWSIIAiWFGXT1KBv2W40Cf7C2rBYRuHmy1R4YbNeOS2V4VLhNrPSSJYIgMD13BGnx0azZY91D/mBNWQ0zRyWRHh/jdihBLyYynBsmeGoU9Ni6W1fMEkEQ6K1RsGG/9ZW6repMK7urGm3J6SFUUphBbWM7O6vOuh1KwLJEECTmF2TQ3NHNWxUNbocS0tY6XRQllgiGzLyJGUSECaute+iK+SQRiMgCEdkvIhUi8kg/+6NF5Fln/yYRGd1n36PO9v0icqsv4glF145LITYq3CaXuWxNWS3j0+MYmxbndighI3F4JHPGJtvIOS94nQhEJBx4DFgIFAD3i0jBeYc9BJxW1fHAD4D/cM4twFPjuBBYAPyv8/vMZYqOCOfGSemsLbO+Urecaelg0+FT1hpwwfzJGVTUneNQva27dSV80SKYDVSo6iFV7QCeARafd8xi4Cnn/jLgZvEsx7gYeEZV21X1MFDh/D5zBUoKMjh5rp13Ks+4HUpIWr/fUyjIho0OvfnOv7m1Cq6MLxJBDlDZ5/FxZ1u/xzjF7s8CKZd4LgAi8rCIlIpIaX29TSnvz02T0okMF/vP4JI1e2pJj49mak6i26GEnJwRwyjKSbCu0SsUMBeLVfVxVS1W1eK0NJu235/eeq5Wy3jotXV289qBeuYXZBAWZrUH3FBSkMm2Y6epa7IaBZfLF4mgChjZ53Gus63fY0QkAkgEGi7xXHMZSgoyOFTfbPVch9ibFSdp6ei2biEXlRRmoArr9trEysvli0SwBcgXkTEiEoXn4u+K845ZASx17t8LvKqeslorgCXOqKIxQD6w2QcxhaxbCnrruVqrYCit2VNLfHQE14xNcTuUkDUxI56RycNslvEV8DoROH3+nwVWA3uB51R1j4h8Q0QWOYf9HEgRkQrgH4FHnHP3AM8BZcDLwGdU1WZEeSErcRjTchNtlvEQ6u5R1u2r5YaJaURFBExva9Dx1CjI5M2DDZxr73I7nIDik0+tqq5U1QmqOk5Vv+1s+4qqrnDut6nqfao6XlVnq+qhPud+2zlvoqqu8kU8oW5+QQbbK89Q12h9pUPhnWOnOXmuw7qF/EBJQQYdXT28fsAGlFwO+/oShHr/IFk916GxpqyWyHDhxok2iMFts/KSSI6Nsu6hy2SJIAjlp8cxOmW4dQ8NAVVl9Z4arhmXSkJMpNvhhLyI8DBunpTOun11dHb3uB1OwLBEEIREhJLCTN46eJImq+c6qMrrznG0ocVmE/uR+QUZNLV1sclqFFwySwRByuq5Do3eLghbbdR/XJefRkxkmI2cuwyWCILUzFFJpMRaPdfBtqaslukjR5CRYLUH/MWwqHCuz09jbVktnlHq5mIsEQSpvvVcO7qsr3QwnDjTys7jZykptNaAvykpzKT6bBu7qxrdDiUgWCIIYiWFGTS1d7HxkNUoGAyvOKOySgps2Ki/uXlSOmFiEysvlSWCIDZ3vFPP1f4zDIo1e2oZmxbL+HSrPeBvkmKjuGp0so2cu0SWCIJYTORf+kqtRoFvnW3pZOOhBmsN+LGSwkz21zZx5GSz26H4PUsEQa63nusuq+fqU+v319HVo3Z9wI/1Dum1ARMXZ4kgyM2blE54mFj3kI+tKashPT6a6bkj3A7FDGBk8nAmZyVYIrgElgiC3IjhUcwZY32lvtTW2c2G/VZ7IBCUFGRQevQUJ8+1ux2KX7NEEALmF2RQbvVcfeatg1Z7IFDML8igR+FVq1FwQZYIQsB86yv1Kas9EDgKsxPIGTHMukYvwhJBCMhNGk5htvWV+kJ3j/LK3lpunJRutQcCgIgwvyCD18tP0mw1CgZkn+QQUVKQydZjp6lvsr5Sb7xbe8DWFgoYJYWeGgVvlNu6WwPxKhGISLKIrBWRcudnUj/HTBeRt0Vkj4jsFJG/6rPvlyJyWES2O7fp3sRjBvaXeq7WKvCG1R4IPLNHJ5M4LJI11iIekLctgkeAdaqaD6xzHp+vBfgbVS0EFgA/FJG+Y+6+oKrTndt2L+MxA5iUGU9u0jD7z+CF3toD145LJd5qDwSMd2sU7K2jy2oU9MvbRLAYeMq5/xRw1/kHqOoBVS137p8A6gD7OjXEeuu5/rnC+kqv1IFap/aATSILOCWFGZxt7WTzEatR0B9vE0GGqlY792uAC/4PEZHZQBRwsM/mbztdRj8QkegLnPuwiJSKSGl9vfX1XYnevlKr53pl3q09MNkSQaC5fkIa0RFhNp9mABdNBCLyiojs7ue2uO9x6ln4e8AFbUQkC/g18FFV7W2fPQpMAq4CkoEvDXS+qj6uqsWqWpyWZg2KK1Gcl0TScOsrvVIv76lhxqgRpFvtgYAzPCqC6/JTrUbBAC6aCFT1FlUt6ue2HKh1/sD3/qHvd9aGiCQALwFfVtWNfX53tXq0A08Cs33xokz/IsLDmDcpg3V7a61GwWU62tDMnhON3FaU5XYo5gqVFGRSdaaVPSesRsH5vO0aWgEsde4vBZaff4CIRAF/BH6lqsvO29ebRATP9YXdXsZjLmJBUSaNbV28bTUKLsuq3Z5uoQVFNps4UN082VOj4OXdNrnsfN4mgu8A80WkHLjFeYyIFIvIE84xHwKuBz7SzzDR34rILmAXkAp8y8t4zEVcl59KXHQEK3dWX/xg865Vu2uYkpPIyOThbodirlBKXDRXj01h5a5q6x46j1eJQFUbVPVmVc13upBOOdtLVfXjzv3fqGpknyGi7w4TVdV5qjrF6Wr6sKraYjiDLCYynJsnp7O6rIZOG0p3SarOtLKj8gwLp1hrIBDS7joAABaaSURBVNAtnJLFoZPNHKi1PzV92cziELSwKIszLZ1sOmRD6S5Fb1fCQrs+EPAWFGYiAi/tshZxX5YIQtCNE9MYHhXOyt32n+FSrNpVzaTMeMakxrodivFSWnw0s0cns8oSwXtYIghBMZHhzJuUzurdNTbT8iJqG9vYeuw0t02x1kCwuG1KFuV15yivbXI7FL9hiSBE3TYli4bmDptpeRGr99SgCgtttFDQWFDk6R5auctGD/WyRBCibpyYRkxkGKvsP8MFrdpVw/j0OPIz4t0OxfhIRkIMxXlJrLKu0XdZIghRw6MimDcpnZf31NDdY0Pp+tNwrp1NhxusNRCEbpuSxb6aJg5a1T7AEkFIW1iURX1TO6XWPdSvNWW19KiNFgpGvRMD7aKxhyWCEDZvUjrREWHvzpo177VyVzV5KcOZnGXdQsEmK3EYM0eNsOsEDksEISw2OoIbJ6axanc1PdY99B4N59p562ADC4uy8KyAYoLNbVOyKKtu5MjJZrdDcZ0lghB325Qsahvb2XbstNuh+JVVuz3XThZNy3Y7FDNIFjpDgm0+jSWCkDfPKcL+oq099B4v7DjB+PQ46xYKYjkjhjF95AhW2nUCSwShLj4mkpsmpvHSrmobPeSoOdvG5iOnuHNqtnULBbk7pmaxu6qRQyE+esgSgWHRtBzqm9rZaEtTA/DizhOowh3TbLRQsLtjajYisGLHCbdDcZUlAsPNk9OJjQpnxfbQ/s/Q64Wd1RRmJzAuLc7tUMwgy0yMYc6YZFZsPxHSS1NbIjDERIZza2EmK3dX097V7XY4rjrW0MKOyjN2kTiELJ6ew6GTzSFducyrRCAiySKyVkTKnZ9JAxzX3acozYo+28eIyCYRqRCRZ51qZsYFi6Zn09TWxWv7Q7uw/Qs7Pa2i26dat1CoWFiUSWS4sHx7lduhuMbbFsEjwDpVzQfWOY/709qnKM2iPtv/A/iBqo4HTgMPeRmPuUJzx6eSHBvF8hDvK31hxwlm5SWRm2SVyELFiOFR3DAhjRd2hO58Gm8TwWLgKef+U3jqDl8Sp07xPKC3jvFlnW98KzI8jNunZLFuby3n2rvcDscVB2qb2FfTZN1CIWjR9BxqGttCdjVebxNBhqr2DsKtATIGOC5GREpFZKOI9P6xTwHOqGrvX53jQM5ATyQiDzu/o7S+PrS7LwbL4unZtHX2sLYsNKfdr9h+gjDBSlKGoFsmpzM8KpzlITpg4qKJQEReEZHd/dwW9z1OPZfcB2pX5alqMfAA8EMRGXe5garq46parKrFaWlpl3u6uQQzRyWRM2JYSI4e6ulR/vhOFR/ITyM9PsbtcMwQGx4VQUlBBit3VdPRFXrFmi6aCJyi9EX93JYDtSKSBeD8rBvgd1Q5Pw8BG4AZQAMwQkQinMNygdC9WuMHwsKEO6dl83r5SRrOtbsdzpDadPgUVWdauWfmgI1SE+QWTc/mbGsnb5SHXo+Dt11DK4Clzv2lwPLzDxCRJBGJdu6nAnOBMqcFsR6490Lnm6F114xsunuUF0LsovHz244TFx1BSYF1C4Wq6/LTSBoeyfPbQu/7qLeJ4DvAfBEpB25xHiMixSLyhHPMZKBURHbg+cP/HVUtc/Z9CfhHEanAc83g517GY7w0KTOBopwElm077nYoQ6a1o5uVu6q5bUomw6LC3Q7HuCQyPIzF03NYW1bL2ZZOt8MZUl4lAlVtUNWbVTXf6UI65WwvVdWPO/ffUtUpqjrN+fnzPucfUtXZqjpeVe9T1dDqj/BT987MZXdVI3urQ2OCzeo9NTR3dHP3zFy3QzEuu3dWLh3dPazYEVqtAptZbN5n0fQcIsOFZVtDo1Xwh23HyRkxjNmjk90OxbisMDuBSZnxIfPZ72WJwLxPcmwUN0/K4E/vVNHZHdwjKGrOtvFmxUnumZlDWJitNBrqRIT7ikey4/hZDtQ2uR3OkLFEYPp176xcGpo72BDkS04s315Fj8IHrVvIOO6ank1EWOi0iMESgRnADRPTSI2LZtnWSrdDGTSqyrKtx5mVl8SY1Fi3wzF+IiUumnmT0nl+WxVdQd4i7mWJwPQrMjyMD87IZt3euqCdU7Dt2GnK685x3yxrDZj3undWLifPtfPageBuEfeyRGAGdM+sXLp6lD8F6Uzj322qJC46gjttbSFznpsmpZMSG8XvS0Oje8gSgRnQpMwEpuUm8szmY0FXtONsaycv7TrB4unZxEZHXPwEE1I8LeIc1u2rpb4pOFvEfVkiMBf04Jw8yuvOsflwcK3KuHx7FW2dPdw/e5TboRg/df+cUXR2K8+VBu91sl6WCMwF3Tktm/iYCH676ZjbofiMqvK7TceYkpNIUU6i2+EYPzUuLY5rx6Xwu03H6A7yOgWWCMwFDYsK556ZuazaXc3JILlovL3yDPtqmqw1YC7qwTl5VJ1p5bUD/a6nGTQsEZiLetBpIgfLhbOnNx9jeFQ4i6bbRWJzYSWFGaTFR/PbjcHTIu6PJQJzUfkZ8cwZk8zvNh8N+FJ+Z1o6eGFHNYunZxNnF4nNRUSGh7HkqpG8ur+O46db3A5n0FgiMJfkwavzqDzVyhsVJ90OxSvPbKmktbObpdeOdjsUEyCWzB6F4GlJBitLBOaSLCjMJDUuiqfeOuJ2KFesq7uHX711hGvGpjApM8HtcEyAyBkxjHmT0nl2SyXtXd1uhzMoLBGYSxIVEcaDc/J4dV8dB+vPuR3OFVlTVsuJs218dO5ot0MxAeYj147h5LmOoK1pbInAXLK/viaPqIgwfvHnw26HckWefPMwI5OHcfPkDLdDMQFm7vgUJmXG8/M3Dgfd5ErwMhGISLKIrBWRcudnUj/H3CQi2/vc2kTkLmffL0XkcJ99072Jxwyu1Lho7p6Rw7KtxznV3OF2OJdld9VZthw5zdJrRhNuy02byyQifPy6seyvbeKN8sC+TtYfb1sEjwDrVDUfWOc8fg9VXa+q01V1OjAPaAHW9DnkC737VXW7l/GYQfaxD4yhvauH32486nYol+Xnfz7M8Khw7ise6XYoJkAtmpZNenw0//fGIbdD8TlvE8Fi4Cnn/lPAXRc5/l5glaoG7zisIDchI54bJqTx1NtHaesMjAtnladaWLHjBEuuGkXisEi3wzEBKioijKXXjuaN8pPsqwmuMq7eJoIMVa127tcAF+t8XQI8fd62b4vIThH5gYhED3SiiDwsIqUiUlpfHxpLw/qrT1w3lpPn2vnTO4FR1/Xx1w8RJvCJ68e4HYoJcA/OGcWwyHD+7/XAvE42kIsmAhF5RUR293Nb3Pc49VxBGfAqiohkAVOA1X02PwpMAq4CkoEvDXS+qj6uqsWqWpyWlnaxsM0gmjs+ham5iTy2ocLvS1nWNbXxbGkl98zMJStxmNvhmAA3YngU988exZ+2V3GsIXg6Ni6aCFT1FlUt6ue2HKh1/sD3/qG/0IIcHwL+qKqdfX53tXq0A08Cs717OWYoiAifm5dP5alWvx9O9/M/H6aru4dP3jDO7VBMkPjkDWMJDxP+d0OF26H4jLddQyuApc79pcDyCxx7P+d1C/VJIoLn+sJuL+MxQ+TmyekUZCXw2PoKvy3nd6alg99uPMZtU7KsFKXxmYyEGO6/aiTLth6n8lRwtAq8TQTfAeaLSDlwi/MYESkWkSd6DxKR0cBI4LXzzv+tiOwCdgGpwLe8jMcMERHhczeP5/DJZl7cWX3xE1zwk9cO0tzRxWfnjXc7FBNkPnXjOMJE+N8NB90OxSe8SgSq2qCqN6tqvtOFdMrZXqqqH+9z3BFVzVHVnvPOn6eqU5yupg+ramBOWQ1RJQWZTMyI50fryv3uWkFtYxu/fPMId03PseUkjM9lJQ7jQ1flsmxrZVC0CmxmsbliYWHCF26dyKGTzTyzxb+qOP1oXTndPcrnb8l3OxQTpD5z03jCw4Tvrt7vdihes0RgvHLz5HRmj0nmv185wLn2LrfDAeBoQzPPbqlkyeyR5KXYtQEzOLISh/HQB8awYscJdh4/43Y4XrFEYLwiIvy/2yZz8lwHP3vNP/pL/+PlfUSEe0Y2GTOYPnXDOFJio/j2S3sDeg0iSwTGa9NHjuCOqVn83xuHqD7b6mosb1WcZOWuGv72hvGkJ8S4GosJfvExkXz+lnw2HT7Fur2BW87SEoHxiS8tmIQqfPPFMtdi6Ozu4Wsv7CE3aRifvGGsa3GY0LJk9ijGpcXy9Rf30NoRGMuunM8SgfGJkcnD+bt541m5q4b1+9z5ZvSrt49yoPYc/3pHATGR4a7EYEJPZHgY37prCpWnWvnxq+Vuh3NFLBEYn/nE9WMZlxbLV1bsHvJvRscaWvje6v3cMCGNkgKrN2CG1jXjUrhnZi6Pv36IA7VNbodz2SwRGJ+Jjgh/95vRf67eN2TP29OjfPEPO4gIE/797il4JqobM7S+fPtk4mIi+OKynX47234glgiMT10zLoWl1+Tx5JtHeP3A0KwS+5tNR9l46BT/csdkskfYwnLGHcmxUXzrriK2V57hx68G1jpElgiMzz1622Ty0+P4p9/vGPRKZmUnGvn2S3u5YUIaH7KiM8Zld0zN5p6Zufz41XK2Hj3ldjiXzBKB8bmYyHB+uGQ6Z1s6+ftn3hm0ZnJjWyef/u1WRgyP5L8+NM26hIxf+NqiAnKThvN3v3uHk+fa3Q7nklgiMIOiMDuRbywu5I3yk3xnle+vF3R19/APz2yn8nQrjz0wk9S4AWsaGTOk4mMi+d8HZ3KqpYNP/Xor7V3+P6TUEoEZNEtmj+Ij147miT8f5tdvH/HZ71VV/nX5Htbtq+PriwopHp3ss99tjC8U5STyvfumUXr0NF9ctpPuHv+edRzhdgAmuH359skcP93Cvy7fQ0yk98XjVZXvvLyPpzcf49M3juPDV+f5KFJjfOuOqdkcbWjhu6v3ExMRzr/fPYWwMO+6L1s6uhge5fs/29YiMIMqMjyM/3lgJtflp/LFP+zk538+fMVrsvT0KF9ZvoefvXaIB+eM4gu3TvRxtMb41mduGs/n5o3n2dJK/un3O7zqJlq+vYrr/3MDFXW+X63fWgRm0MVEhvP4Xxfz+Wff4ZsvlnGw/hxfuczZv6eaO/j8s9t5/UA9n7xhLI8smGQXh01A+If5E4iKCON7aw5w/HQLjz0w87LWwerq7uE/V+/n8dcPMWdMMmnxvr8e5lWLQETuE5E9ItIjIsUXOG6BiOwXkQoReaTP9jEissnZ/qyIRHkTj/Ffw6LC+cmDs/jkDWP53aZj3P6jN3j7YMNFz1NVlm+v4tYfvs7Ggw382wenWBIwAUVE+Oy8fP7ngRnsqjrLLd9/jee2VF7SdYPtlWdY/NibPP76If766jx+9dBsEodF+j5Gb5ZOFZHJQA/wM+CfVbW0n2PCgQPAfOA4sAW4X1XLROQ54HlVfUZEfgrsUNWfXOx5i4uLtbT0fU9lAsTrB+p55A87OXG2jWvGpvBXV43k+glpJMf+5XtA9dlW1u2t49dvH2V/bRNTcxP597unUJid6GLkxnjnUP05vrBsJ1uPnmZsWiwPzB7FrYWZ5CYNe/fLTWNbJ68fqOe50uO8fqCe9Phovr6okIVTsrx+fhHZqqrv+9LuVSLo88s3MHAiuAb4mqre6jx+1Nn1HaAeyFTVrvOPuxBLBIGvrbOb32w8ypNvHqHqjGfp6tS4aGKjwznd3EFjm6fIzaTMeD5x3VjumpFDuJcX2ozxBz09ypqyGh5bf5BdVWcBSIiJIHF4JG2dPdQ3eeYepMZF89G5o/mba/KIj/FNK2CgRDAU1whygL51DI8Dc4AU4IyqdvXZnjPQLxGRh4GHAUaNGjU4kZohExMZzsevG8vH5o5h27HTbDt2mkP1zbR2dpMQE8mY1Fiuy09lfHqcdQOZoBIWJiwoymJBURYH68/x1sEG9tc00tLeTWR4GKNShjN7TDIzRyUN2ZefiyYCEXkFyOxn15dVdbnvQ+qfqj4OPA6eFsFQPa8ZXGFhQvHoZJsLYELSuLQ4xqXFuR3GxROBqt7i5XNUAX0Hj+c62xqAESIS4bQKercbY4wZQkMxj2ALkO+MEIoClgAr1HNxYj1wr3PcUmDIWhjGGGM8vB0++kEROQ5cA7wkIqud7dkishLA+bb/WWA1sBd4TlX3OL/iS8A/ikgFnmsGP/cmHmOMMZfPJ6OGhpqNGjLGmMs30KghW2LCGGNCnCUCY4wJcZYIjDEmxFkiMMaYEBeQF4tFpB44eoWnpwInfRhOILDXHBrsNYcGb15znqqmnb8xIBOBN0SktL+r5sHMXnNosNccGgbjNVvXkDHGhDhLBMYYE+JCMRE87nYALrDXHBrsNYcGn7/mkLtGYIwx5r1CsUVgjDGmD0sExhgT4kIqEYjIAhHZLyIVIvKI2/H4goiMFJH1IlImIntE5O+d7ckislZEyp2fSc52EZEfOf8GO0Vkpruv4MqJSLiIvCMiLzqPx4jIJue1Pesse46IRDuPK5z9o92M+0qJyAgRWSYi+0Rkr4hcE+zvs4j8g/O53i0iT4tITLC9zyLyCxGpE5HdfbZd9vsqIkud48tFZOnlxBAyiUBEwoHHgIVAAXC/iBS4G5VPdAH/pKoFwNXAZ5zX9QiwTlXzgXXOY/C8/nzn9jDwk6EP2Wf+Hs/S5r3+A/iBqo4HTgMPOdsfAk4723/gHBeI/ht4WVUnAdPwvPagfZ9FJAf4HFCsqkVAOJ56JsH2Pv8SWHDetst6X0UkGfgqnjLAs4Gv9iaPS6KqIXHDUzNhdZ/HjwKPuh3XILzO5cB8YD+Q5WzLAvY7938G3N/n+HePC6Qbnop264B5wIuA4JltGXH++42nFsY1zv0I5zhx+zVc5utNBA6fH3cwv8/8pd55svO+vQjcGozvMzAa2H2l7ytwP/CzPtvfc9zFbiHTIuAvH6pex51tQcNpCs8ANgEZqlrt7KoBMpz7wfLv8EPgi0CP8zgFOKOeQkjw3tf17mt29p91jg8kY4B64EmnO+wJEYkliN9nVa0CvgccA6rxvG9bCe73udflvq9evd+hlAiCmojEAX8APq+qjX33qecrQtCMExaRO4A6Vd3qdixDKAKYCfxEVWcAzfyluwAIyvc5CViMJwlmA7G8vwsl6A3F+xpKiaAKGNnnca6zLeCJSCSeJPBbVX3e2VwrIlnO/iygztkeDP8Oc4FFInIEeAZP99B/AyNEJMI5pu/revc1O/sTgYahDNgHjgPHVXWT83gZnsQQzO/zLcBhVa1X1U7geTzvfTC/z70u93316v0OpUSwBch3RhxE4bnotMLlmLwmIoKn1vNeVf1+n10rgN6RA0vxXDvo3f43zuiDq4GzfZqgAUFVH1XVXFUdjed9fFVVHwTWA/c6h53/mnv/Le51jg+ob86qWgNUishEZ9PNQBlB/D7j6RK6WkSGO5/z3tcctO9zH5f7vq4GSkQkyWlJlTjbLo3bF0mG+ILMbcAB4CDwZbfj8dFr+gCeZuNOYLtzuw1P3+g6oBx4BUh2jhc8o6cOArvwjMhw/XV48fpvBF507o8FNgMVwO+BaGd7jPO4wtk/1u24r/C1TgdKnff6T0BSsL/PwNeBfcBu4NdAdLC9z8DTeK6BdOJp+T10Je8r8DHntVcAH72cGGyJCWOMCXGh1DVkjDGmH5YIjDEmxFkiMMaYEGeJwBhjQpwlAmOMCXGWCIwxJsRZIjDGmBD3/wFSpXvD3aAKBwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = torch.unsqueeze(torch.linspace(-5, 5, 1000), dim=1)  #1000 points, so 900 new points\n",
        "\n",
        "y = torch.sin(x)\n",
        "x, y = Variable(x), Variable(y)\n",
        "plt.plot(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyfT1taiPWE7",
        "outputId": "1cbe9689-8433-4082-ec1b-047d7b3228fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0003, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "pred = net2(x)\n",
        "loss = loss_func(pred, y)\n",
        "loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BYtX0lD9PWE7",
        "outputId": "ebfeeb70-1d1a-4b12-c604-f20281ab360f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f80866b03d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x.data.numpy(),y.data.numpy(), color = \"orange\")\n",
        "ax.plot(x.data.numpy(), pred.data.numpy(), 'g-', lw=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALWI1tkZPWE8"
      },
      "source": [
        "We can see that we trained the model in 100 points with t in T=(-3,3) and it works very good also for 1000 points in T. We have now an approximator of time series P(t). Although, if we try the model out of T, we see that it works good for data in T, but it's very bad for data out of T! So, it is not reliable for future predictions of time t:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "716YBDOrPWE9",
        "outputId": "bb4425e6-1b0e-4a35-cc44-f2d9f322ac60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1691, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f808661a750>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = torch.unsqueeze(torch.linspace(-4, 7, 800), dim=1) #OUT OF T\n",
        "y = torch.sin(x)\n",
        "pred = net2(x)\n",
        "loss = loss_func(pred, y)\n",
        "print(loss)\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x.data.numpy(),y.data.numpy(), color = \"orange\")\n",
        "ax.plot(x.data.numpy(), pred.data.numpy(), 'g-', lw=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov2TYlmEPWE-",
        "outputId": "71f4d745-63c5-4e5f-d506-314d8e33ae14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28168342"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "d= net2(x)-y \n",
        "d=d.detach().numpy()\n",
        "abs(np.mean(d)) #out of T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn6v6V7jPWE-"
      },
      "source": [
        "# Second approach:\n",
        "One second approach is to use the approximation of P(t) that we found(i.e the avove Neural Network), so P(t) = N(t). Also,\n",
        "1. As we said, Neural Network is a continues approximator, so we can have the derivative $\\frac{dN}{dt}$\n",
        "2. P(t) = N(t) is the solution of a diff. eq. $$\\frac{dP}{dt} = f(t,P(t))$$ which we don't know.\n",
        "3. suppose $$\\frac{dP}{dt} = N1(t) * N(t)$$ where N1(t) is an other Neural Network that we have to train.\n",
        "4. We want to minimize the loss function $$ E= \\frac{1}{2}[\\frac{dN}{dt} - N1(t)N(t)]^{2} $$ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sho5ToU7PWE_"
      },
      "outputs": [],
      "source": [
        "net1 = torch.nn.Sequential(\n",
        "        torch.nn.Linear(1, 10),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(10, 1),\n",
        "    )\n",
        "#net1 = net1.float() \n",
        "#net1 is the network that is trained to find the O.D.E ----> N1(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dvyy0e9APWE_"
      },
      "outputs": [],
      "source": [
        "def loss(x):\n",
        "\n",
        "    x.requires_grad = True\n",
        "    N = net2(x)\n",
        "    dN_dx = torch.autograd.grad(N, x, grad_outputs=torch.ones_like(N),\n",
        "                        create_graph=True)[0]\n",
        "\n",
        "    return  torch.mean( ( dN_dx - net1(x)*net2(x) )  ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9k_JrbUZPWE_"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net1.parameters(), lr=0.001)\n",
        "\n",
        "x = torch.Tensor(np.linspace(-5, 5, 100)[:, None]) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tJp5X75PPWFA"
      },
      "outputs": [],
      "source": [
        "losses=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8xLFtzpPWFA",
        "outputId": "58cb7ef7-eda9-4769-9430-852c38f66288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mΗ έξοδος ροής περικόπηκε στις τελευταίες 5000 γραμμές.\u001b[0m\n",
            "loss: 0.008873244747519493\n",
            "loss: 0.008873241022229195\n",
            "loss: 0.008873182348906994\n",
            "loss: 0.008873078972101212\n",
            "loss: 0.008873026818037033\n",
            "loss: 0.00887303426861763\n",
            "loss: 0.008872989565134048\n",
            "loss: 0.00887293741106987\n",
            "loss: 0.00887283869087696\n",
            "loss: 0.0088728042319417\n",
            "loss: 0.008872770704329014\n",
            "loss: 0.00887263473123312\n",
            "loss: 0.008872621692717075\n",
            "loss: 0.008872544392943382\n",
            "loss: 0.008872484788298607\n",
            "loss: 0.008872469887137413\n",
            "loss: 0.008872345089912415\n",
            "loss: 0.008872389793395996\n",
            "loss: 0.008872291073203087\n",
            "loss: 0.008872210048139095\n",
            "loss: 0.008872158825397491\n",
            "loss: 0.008872131817042828\n",
            "loss: 0.008872035890817642\n",
            "loss: 0.008871972560882568\n",
            "loss: 0.008871946483850479\n",
            "loss: 0.008871925994753838\n",
            "loss: 0.008871820755302906\n",
            "loss: 0.008871782571077347\n",
            "loss: 0.008871760219335556\n",
            "loss: 0.00887166429311037\n",
            "loss: 0.008871638216078281\n",
            "loss: 0.008871503174304962\n",
            "loss: 0.00887148454785347\n",
            "loss: 0.008871444500982761\n",
            "loss: 0.008871377445757389\n",
            "loss: 0.008871334604918957\n",
            "loss: 0.008871285244822502\n",
            "loss: 0.008871186524629593\n",
            "loss: 0.008871208876371384\n",
            "loss: 0.008871067315340042\n",
            "loss: 0.008871064521372318\n",
            "loss: 0.008871004916727543\n",
            "loss: 0.008870982564985752\n",
            "loss: 0.008870900608599186\n",
            "loss: 0.008870845660567284\n",
            "loss: 0.00887075811624527\n",
            "loss: 0.008870715275406837\n",
            "loss: 0.008870698511600494\n",
            "loss: 0.00887063704431057\n",
            "loss: 0.008870539255440235\n",
            "loss: 0.00887051597237587\n",
            "loss: 0.008870461024343967\n",
            "loss: 0.008870413526892662\n",
            "loss: 0.008870329707860947\n",
            "loss: 0.008870291523635387\n",
            "loss: 0.008870232850313187\n",
            "loss: 0.00887020118534565\n",
            "loss: 0.008870143443346024\n",
            "loss: 0.008870098739862442\n",
            "loss: 0.008870049379765987\n",
            "loss: 0.008870013989508152\n",
            "loss: 0.008869985118508339\n",
            "loss: 0.008869925513863564\n",
            "loss: 0.008869906887412071\n",
            "loss: 0.008869869634509087\n",
            "loss: 0.008869870565831661\n",
            "loss: 0.008869864977896214\n",
            "loss: 0.008869829587638378\n",
            "loss: 0.008869857527315617\n",
            "loss: 0.00886975321918726\n",
            "loss: 0.00886975135654211\n",
            "loss: 0.008869627490639687\n",
            "loss: 0.008869597688317299\n",
            "loss: 0.008869417943060398\n",
            "loss: 0.008869370445609093\n",
            "loss: 0.008869195356965065\n",
            "loss: 0.00886907335370779\n",
            "loss: 0.008869006298482418\n",
            "loss: 0.008868983015418053\n",
            "loss: 0.008868951350450516\n",
            "loss: 0.008868884295225143\n",
            "loss: 0.008868872188031673\n",
            "loss: 0.00886881910264492\n",
            "loss: 0.008868804201483727\n",
            "loss: 0.00886873621493578\n",
            "loss: 0.008868592791259289\n",
            "loss: 0.008868565782904625\n",
            "loss: 0.00886855274438858\n",
            "loss: 0.00886843353509903\n",
            "loss: 0.008868400938808918\n",
            "loss: 0.008868278004229069\n",
            "loss: 0.008868263103067875\n",
            "loss: 0.008868221193552017\n",
            "loss: 0.008868175558745861\n",
            "loss: 0.008868125267326832\n",
            "loss: 0.008868027478456497\n",
            "loss: 0.00886793527752161\n",
            "loss: 0.008867974393069744\n",
            "loss: 0.008867897093296051\n",
            "loss: 0.008867800235748291\n",
            "loss: 0.008867762982845306\n",
            "loss: 0.008867674507200718\n",
            "loss: 0.008867653086781502\n",
            "loss: 0.008867607451975346\n",
            "loss: 0.0088675357401371\n",
            "loss: 0.00886751152575016\n",
            "loss: 0.008867383003234863\n",
            "loss: 0.008867387659847736\n",
            "loss: 0.008867279626429081\n",
            "loss: 0.00886725727468729\n",
            "loss: 0.008867189288139343\n",
            "loss: 0.008867139928042889\n",
            "loss: 0.008867082186043262\n",
            "loss: 0.008867049589753151\n",
            "loss: 0.008866952732205391\n",
            "loss: 0.008866982534527779\n",
            "loss: 0.008866852149367332\n",
            "loss: 0.008866832591593266\n",
            "loss: 0.008866719901561737\n",
            "loss: 0.008866685442626476\n",
            "loss: 0.008866675198078156\n",
            "loss: 0.008866622112691402\n",
            "loss: 0.00886652059853077\n",
            "loss: 0.008866477757692337\n",
            "loss: 0.008866439573466778\n",
            "loss: 0.008866332471370697\n",
            "loss: 0.008866327814757824\n",
            "loss: 0.008866291493177414\n",
            "loss: 0.008866232819855213\n",
            "loss: 0.008866148069500923\n",
            "loss: 0.0088660828769207\n",
            "loss: 0.00886608473956585\n",
            "loss: 0.00886605679988861\n",
            "loss: 0.008865966461598873\n",
            "loss: 0.008865881711244583\n",
            "loss: 0.00886587891727686\n",
            "loss: 0.00886581651866436\n",
            "loss: 0.008865738287568092\n",
            "loss: 0.008865677751600742\n",
            "loss: 0.008865606039762497\n",
            "loss: 0.008865565992891788\n",
            "loss: 0.008865517564117908\n",
            "loss: 0.00886545144021511\n",
            "loss: 0.008865419775247574\n",
            "loss: 0.008865433745086193\n",
            "loss: 0.008865333162248135\n",
            "loss: 0.008865281008183956\n",
            "loss: 0.00886528380215168\n",
            "loss: 0.008865161798894405\n",
            "loss: 0.008865229785442352\n",
            "loss: 0.008865146897733212\n",
            "loss: 0.008865058422088623\n",
            "loss: 0.008864987641572952\n",
            "loss: 0.008864971809089184\n",
            "loss: 0.008864883333444595\n",
            "loss: 0.008864832110702991\n",
            "loss: 0.008864684961736202\n",
            "loss: 0.008864683099091053\n",
            "loss: 0.008864556439220905\n",
            "loss: 0.008864527568221092\n",
            "loss: 0.008864481933414936\n",
            "loss: 0.008864457719027996\n",
            "loss: 0.00886441394686699\n",
            "loss: 0.008864391595125198\n",
            "loss: 0.008864328265190125\n",
            "loss: 0.00886425469070673\n",
            "loss: 0.008864224888384342\n",
            "loss: 0.008864178322255611\n",
            "loss: 0.008864174596965313\n",
            "loss: 0.008864082396030426\n",
            "loss: 0.008864033967256546\n",
            "loss: 0.008864019997417927\n",
            "loss: 0.008863916620612144\n",
            "loss: 0.008863971568644047\n",
            "loss: 0.008863854221999645\n",
            "loss: 0.008863801136612892\n",
            "loss: 0.008863738738000393\n",
            "loss: 0.008863626979291439\n",
            "loss: 0.008863561786711216\n",
            "loss: 0.008863484486937523\n",
            "loss: 0.008863383904099464\n",
            "loss: 0.008863366208970547\n",
            "loss: 0.008863253518939018\n",
            "loss: 0.008863167837262154\n",
            "loss: 0.008863113820552826\n",
            "loss: 0.008863109163939953\n",
            "loss: 0.008863001130521297\n",
            "loss: 0.008863013237714767\n",
            "loss: 0.00886296946555376\n",
            "loss: 0.008862885646522045\n",
            "loss: 0.008862871676683426\n",
            "loss: 0.008862839080393314\n",
            "loss: 0.0088626928627491\n",
            "loss: 0.00886266864836216\n",
            "loss: 0.008862610906362534\n",
            "loss: 0.008862554095685482\n",
            "loss: 0.008862525224685669\n",
            "loss: 0.008862440474331379\n",
            "loss: 0.008862401358783245\n",
            "loss: 0.008862319402396679\n",
            "loss: 0.008862297981977463\n",
            "loss: 0.008862263523042202\n",
            "loss: 0.008862130343914032\n",
            "loss: 0.008862053044140339\n",
            "loss: 0.008862047456204891\n",
            "loss: 0.00886202696710825\n",
            "loss: 0.008861897513270378\n",
            "loss: 0.008861890062689781\n",
            "loss: 0.008861809968948364\n",
            "loss: 0.008861838839948177\n",
            "loss: 0.008861715905368328\n",
            "loss: 0.008861683309078217\n",
            "loss: 0.00886162742972374\n",
            "loss: 0.008861602284014225\n",
            "loss: 0.008861527778208256\n",
            "loss: 0.008861437439918518\n",
            "loss: 0.008861425332725048\n",
            "loss: 0.008861316367983818\n",
            "loss: 0.008861311711370945\n",
            "loss: 0.008861221373081207\n",
            "loss: 0.008861161768436432\n",
            "loss: 0.008861107751727104\n",
            "loss: 0.008861093781888485\n",
            "loss: 0.008861052803695202\n",
            "loss: 0.008860989473760128\n",
            "loss: 0.00886090099811554\n",
            "loss: 0.008860885165631771\n",
            "loss: 0.008860865607857704\n",
            "loss: 0.008860763162374496\n",
            "loss: 0.008860733360052109\n",
            "loss: 0.008860712870955467\n",
            "loss: 0.008860629051923752\n",
            "loss: 0.008860563859343529\n",
            "loss: 0.008860542438924313\n",
            "loss: 0.008860496804118156\n",
            "loss: 0.008860451169312\n",
            "loss: 0.008860423229634762\n",
            "loss: 0.008860442787408829\n",
            "loss: 0.00886028353124857\n",
            "loss: 0.008860226720571518\n",
            "loss: 0.008860180154442787\n",
            "loss: 0.008860123343765736\n",
            "loss: 0.008860056288540363\n",
            "loss: 0.008860005997121334\n",
            "loss: 0.008859848603606224\n",
            "loss: 0.008859816007316113\n",
            "loss: 0.008859742432832718\n",
            "loss: 0.00885967630892992\n",
            "loss: 0.008859631605446339\n",
            "loss: 0.008859566412866116\n",
            "loss: 0.008859559893608093\n",
            "loss: 0.00885944627225399\n",
            "loss: 0.008859412744641304\n",
            "loss: 0.00885933730751276\n",
            "loss: 0.008859316818416119\n",
            "loss: 0.00885926652699709\n",
            "loss: 0.008859229274094105\n",
            "loss: 0.008859162218868732\n",
            "loss: 0.00885910913348198\n",
            "loss: 0.008859063498675823\n",
            "loss: 0.008858997374773026\n",
            "loss: 0.00885892752557993\n",
            "loss: 0.008858954533934593\n",
            "loss: 0.008858820423483849\n",
            "loss: 0.008858777582645416\n",
            "loss: 0.008858718909323215\n",
            "loss: 0.008858658373355865\n",
            "loss: 0.008858607150614262\n",
            "loss: 0.008858587592840195\n",
            "loss: 0.008858472108840942\n",
            "loss: 0.00885843113064766\n",
            "loss: 0.008858375251293182\n",
            "loss: 0.008858319371938705\n",
            "loss: 0.008858232758939266\n",
            "loss: 0.00885816477239132\n",
            "loss: 0.008858098648488522\n",
            "loss: 0.008858098648488522\n",
            "loss: 0.008858025074005127\n",
            "loss: 0.008857985958456993\n",
            "loss: 0.00885793473571539\n",
            "loss: 0.008857873268425465\n",
            "loss: 0.008857819251716137\n",
            "loss: 0.008857791312038898\n",
            "loss: 0.008857755921781063\n",
            "loss: 0.008857612498104572\n",
            "loss: 0.00885763205587864\n",
            "loss: 0.008857601322233677\n",
            "loss: 0.008857541717588902\n",
            "loss: 0.008857411332428455\n",
            "loss: 0.008857381530106068\n",
            "loss: 0.008857319131493568\n",
            "loss: 0.008857257664203644\n",
            "loss: 0.008857201784849167\n",
            "loss: 0.008857143111526966\n",
            "loss: 0.008857146836817265\n",
            "loss: 0.008857074193656445\n",
            "loss: 0.008857057429850101\n",
            "loss: 0.00885702669620514\n",
            "loss: 0.008856957778334618\n",
            "loss: 0.008856908418238163\n",
            "loss: 0.008856931701302528\n",
            "loss: 0.008856892585754395\n",
            "loss: 0.008856791071593761\n",
            "loss: 0.008856827393174171\n",
            "loss: 0.008856827393174171\n",
            "loss: 0.008856822736561298\n",
            "loss: 0.008856773376464844\n",
            "loss: 0.008856757543981075\n",
            "loss: 0.008856591768562794\n",
            "loss: 0.008856534026563168\n",
            "loss: 0.008856396190822124\n",
            "loss: 0.0088562723249197\n",
            "loss: 0.008856191299855709\n",
            "loss: 0.00885607860982418\n",
            "loss: 0.008855998516082764\n",
            "loss: 0.008855960331857204\n",
            "loss: 0.008855956606566906\n",
            "loss: 0.008855869993567467\n",
            "loss: 0.008855867199599743\n",
            "loss: 0.008855818770825863\n",
            "loss: 0.008855722844600677\n",
            "loss: 0.00885565485805273\n",
            "loss: 0.008855616673827171\n",
            "loss: 0.008855478838086128\n",
            "loss: 0.00885546114295721\n",
            "loss: 0.008855433203279972\n",
            "loss: 0.008855347521603107\n",
            "loss: 0.008855278603732586\n",
            "loss: 0.00885532982647419\n",
            "loss: 0.00885525532066822\n",
            "loss: 0.008855175226926804\n",
            "loss: 0.008855174295604229\n",
            "loss: 0.008855030871927738\n",
            "loss: 0.008854997344315052\n",
            "loss: 0.00885491631925106\n",
            "loss: 0.008854839019477367\n",
            "loss: 0.008854814805090427\n",
            "loss: 0.008854730986058712\n",
            "loss: 0.008854668587446213\n",
            "loss: 0.008854643441736698\n",
            "loss: 0.00885456521064043\n",
            "loss: 0.008854507468640804\n",
            "loss: 0.008854459971189499\n",
            "loss: 0.008854469284415245\n",
            "loss: 0.00885434728115797\n",
            "loss: 0.008854364044964314\n",
            "loss: 0.008854236453771591\n",
            "loss: 0.008854307234287262\n",
            "loss: 0.008854147046804428\n",
            "loss: 0.008854087442159653\n",
            "loss: 0.008854052051901817\n",
            "loss: 0.008853967301547527\n",
            "loss: 0.008853924460709095\n",
            "loss: 0.008853859268128872\n",
            "loss: 0.00885382667183876\n",
            "loss: 0.008853794075548649\n",
            "loss: 0.008853751234710217\n",
            "loss: 0.008853664621710777\n",
            "loss: 0.008853625506162643\n",
            "loss: 0.008853546343743801\n",
            "loss: 0.008853476494550705\n",
            "loss: 0.008853435516357422\n",
            "loss: 0.008853414095938206\n",
            "loss: 0.008853350766003132\n",
            "loss: 0.008853253908455372\n",
            "loss: 0.008853243663907051\n",
            "loss: 0.008853184059262276\n",
            "loss: 0.008853134699165821\n",
            "loss: 0.008853069506585598\n",
            "loss: 0.008853010833263397\n",
            "loss: 0.008852927945554256\n",
            "loss: 0.008852889761328697\n",
            "loss: 0.008852875791490078\n",
            "loss: 0.008852774277329445\n",
            "loss: 0.00885273702442646\n",
            "loss: 0.008852682076394558\n",
            "loss: 0.008852596394717693\n",
            "loss: 0.008852552622556686\n",
            "loss: 0.008852530270814896\n",
            "loss: 0.008852495811879635\n",
            "loss: 0.008852466009557247\n",
            "loss: 0.008852372877299786\n",
            "loss: 0.008852334693074226\n",
            "loss: 0.008852309547364712\n",
            "loss: 0.008852285332977772\n",
            "loss: 0.008852234110236168\n",
            "loss: 0.008852179162204266\n",
            "loss: 0.008852147497236729\n",
            "loss: 0.008852077648043633\n",
            "loss: 0.00885204691439867\n",
            "loss: 0.008851933293044567\n",
            "loss: 0.008851906284689903\n",
            "loss: 0.008851805701851845\n",
            "loss: 0.00885178055614233\n",
            "loss: 0.008851690217852592\n",
            "loss: 0.008851629681885242\n",
            "loss: 0.008851580321788788\n",
            "loss: 0.008851573802530766\n",
            "loss: 0.008851481601595879\n",
            "loss: 0.008851413615047932\n",
            "loss: 0.008851335383951664\n",
            "loss: 0.008851390331983566\n",
            "loss: 0.008851269260048866\n",
            "loss: 0.008851240389049053\n",
            "loss: 0.008851184509694576\n",
            "loss: 0.00885110255330801\n",
            "loss: 0.008851048536598682\n",
            "loss: 0.0088510075584054\n",
            "loss: 0.008850939571857452\n",
            "loss: 0.008850881829857826\n",
            "loss: 0.008850837126374245\n",
            "loss: 0.008850818499922752\n",
            "loss: 0.008850747719407082\n",
            "loss: 0.008850714191794395\n",
            "loss: 0.008850659243762493\n",
            "loss: 0.00885059218853712\n",
            "loss: 0.008850537240505219\n",
            "loss: 0.008850525133311749\n",
            "loss: 0.008850383572280407\n",
            "loss: 0.008850345388054848\n",
            "loss: 0.008850318379700184\n",
            "loss: 0.008850238285958767\n",
            "loss: 0.008850138634443283\n",
            "loss: 0.008850116282701492\n",
            "loss: 0.008850030601024628\n",
            "loss: 0.008849970065057278\n",
            "loss: 0.008849899284541607\n",
            "loss: 0.008849840611219406\n",
            "loss: 0.008849753066897392\n",
            "loss: 0.008849740959703922\n",
            "loss: 0.008849702775478363\n",
            "loss: 0.008849664591252804\n",
            "loss: 0.008849593810737133\n",
            "loss: 0.008849517442286015\n",
            "loss: 0.008849444799125195\n",
            "loss: 0.008849379606544971\n",
            "loss: 0.008849365636706352\n",
            "loss: 0.008849287405610085\n",
            "loss: 0.008849259465932846\n",
            "loss: 0.008849217556416988\n",
            "loss: 0.008849186822772026\n",
            "loss: 0.008849081583321095\n",
            "loss: 0.008849023841321468\n",
            "loss: 0.008849003352224827\n",
            "loss: 0.008848924189805984\n",
            "loss: 0.008848915807902813\n",
            "loss: 0.008848830126225948\n",
            "loss: 0.008848712779581547\n",
            "loss: 0.008848714642226696\n",
            "loss: 0.008848682977259159\n",
            "loss: 0.008848610334098339\n",
            "loss: 0.008848563767969608\n",
            "loss: 0.00884849764406681\n",
            "loss: 0.008848506957292557\n",
            "loss: 0.008848430588841438\n",
            "loss: 0.008848373778164387\n",
            "loss: 0.008848315104842186\n",
            "loss: 0.008848320692777634\n",
            "loss: 0.00884819496423006\n",
            "loss: 0.008848225697875023\n",
            "loss: 0.008848188444972038\n",
            "loss: 0.008848141878843307\n",
            "loss: 0.00884813629090786\n",
            "loss: 0.008848159573972225\n",
            "loss: 0.00884807389229536\n",
            "loss: 0.008848072029650211\n",
            "loss: 0.008848057128489017\n",
            "loss: 0.008847982622683048\n",
            "loss: 0.008847881108522415\n",
            "loss: 0.008847805671393871\n",
            "loss: 0.008847669698297977\n",
            "loss: 0.008847588673233986\n",
            "loss: 0.008847475051879883\n",
            "loss: 0.008847450837492943\n",
            "loss: 0.008847308345139027\n",
            "loss: 0.008847230114042759\n",
            "loss: 0.008847204968333244\n",
            "loss: 0.008847148157656193\n",
            "loss: 0.008847185410559177\n",
            "loss: 0.008847064338624477\n",
            "loss: 0.008847028017044067\n",
            "loss: 0.00884697213768959\n",
            "loss: 0.008846888318657875\n",
            "loss: 0.008846843615174294\n",
            "loss: 0.008846793323755264\n",
            "loss: 0.008846712298691273\n",
            "loss: 0.008846677839756012\n",
            "loss: 0.008846607990562916\n",
            "loss: 0.008846583776175976\n",
            "loss: 0.008846552111208439\n",
            "loss: 0.008846446871757507\n",
            "loss: 0.008846416138112545\n",
            "loss: 0.008846316486597061\n",
            "loss: 0.008846301585435867\n",
            "loss: 0.008846252225339413\n",
            "loss: 0.008846176788210869\n",
            "loss: 0.008846137672662735\n",
            "loss: 0.008846061304211617\n",
            "loss: 0.008846049197018147\n",
            "loss: 0.008845895528793335\n",
            "loss: 0.008845911361277103\n",
            "loss: 0.008845833130180836\n",
            "loss: 0.008845730684697628\n",
            "loss: 0.00884562823921442\n",
            "loss: 0.008845631964504719\n",
            "loss: 0.008845637552440166\n",
            "loss: 0.008845621719956398\n",
            "loss: 0.008845469914376736\n",
            "loss: 0.008845468983054161\n",
            "loss: 0.008845444768667221\n",
            "loss: 0.008845294825732708\n",
            "loss: 0.008845288306474686\n",
            "loss: 0.008845268748700619\n",
            "loss: 0.00884516816586256\n",
            "loss: 0.008845113217830658\n",
            "loss: 0.008845116943120956\n",
            "loss: 0.008844966068863869\n",
            "loss: 0.008844968862831593\n",
            "loss: 0.008844896219670773\n",
            "loss: 0.00884481891989708\n",
            "loss: 0.008844787254929543\n",
            "loss: 0.008844783529639244\n",
            "loss: 0.008844687603414059\n",
            "loss: 0.008844626136124134\n",
            "loss: 0.008844596333801746\n",
            "loss: 0.0088444659486413\n",
            "loss: 0.008844512514770031\n",
            "loss: 0.00884436909109354\n",
            "loss: 0.00884439330548048\n",
            "loss: 0.00884427223354578\n",
            "loss: 0.00884423777461052\n",
            "loss: 0.008844182826578617\n",
            "loss: 0.008844178169965744\n",
            "loss: 0.008844127878546715\n",
            "loss: 0.008844024501740932\n",
            "loss: 0.008843955583870411\n",
            "loss: 0.008843967691063881\n",
            "loss: 0.00884395744651556\n",
            "loss: 0.008843867108225822\n",
            "loss: 0.008843830786645412\n",
            "loss: 0.008843746967613697\n",
            "loss: 0.008843757212162018\n",
            "loss: 0.008843633346259594\n",
            "loss: 0.008843619376420975\n",
            "loss: 0.008843529038131237\n",
            "loss: 0.008843404240906239\n",
            "loss: 0.0088434386998415\n",
            "loss: 0.00884332973510027\n",
            "loss: 0.008843268267810345\n",
            "loss: 0.008843197487294674\n",
            "loss: 0.008843250572681427\n",
            "loss: 0.008843126706779003\n",
            "loss: 0.008843112736940384\n",
            "loss: 0.00884314812719822\n",
            "loss: 0.008843110874295235\n",
            "loss: 0.008843031711876392\n",
            "loss: 0.008843007497489452\n",
            "loss: 0.008843007497489452\n",
            "loss: 0.00884298700839281\n",
            "loss: 0.008843018673360348\n",
            "loss: 0.008842884562909603\n",
            "loss: 0.008842863142490387\n",
            "loss: 0.008842774666845798\n",
            "loss: 0.008842654526233673\n",
            "loss: 0.00884254090487957\n",
            "loss: 0.008842447772622108\n",
            "loss: 0.008842329494655132\n",
            "loss: 0.008842247538268566\n",
            "loss: 0.008842202834784985\n",
            "loss: 0.008842159062623978\n",
            "loss: 0.00884210504591465\n",
            "loss: 0.00884206872433424\n",
            "loss: 0.008842076174914837\n",
            "loss: 0.008842000737786293\n",
            "loss: 0.008841952309012413\n",
            "loss: 0.00884188897907734\n",
            "loss: 0.008841795846819878\n",
            "loss: 0.00884175207465887\n",
            "loss: 0.008841658011078835\n",
            "loss: 0.00884161051362753\n",
            "loss: 0.00884155835956335\n",
            "loss: 0.008841478265821934\n",
            "loss: 0.008841486647725105\n",
            "loss: 0.008841414004564285\n",
            "loss: 0.008841409347951412\n",
            "loss: 0.008841272443532944\n",
            "loss: 0.008841249160468578\n",
            "loss: 0.008841190487146378\n",
            "loss: 0.008841095492243767\n",
            "loss: 0.008841050788760185\n",
            "loss: 0.008841012604534626\n",
            "loss: 0.008840943686664104\n",
            "loss: 0.008840920403599739\n",
            "loss: 0.008840841241180897\n",
            "loss: 0.008840791881084442\n",
            "loss: 0.00884070061147213\n",
            "loss: 0.008840667083859444\n",
            "loss: 0.008840619586408138\n",
            "loss: 0.008840549737215042\n",
            "loss: 0.00884051714092493\n",
            "loss: 0.008840472437441349\n",
            "loss: 0.00884041003882885\n",
            "loss: 0.008840348571538925\n",
            "loss: 0.008840277791023254\n",
            "loss: 0.008840241469442844\n",
            "loss: 0.008840174414217472\n",
            "loss: 0.008840134367346764\n",
            "loss: 0.008840040303766727\n",
            "loss: 0.008840013295412064\n",
            "loss: 0.008839942514896393\n",
            "loss: 0.008839914575219154\n",
            "loss: 0.008839910849928856\n",
            "loss: 0.008839810267090797\n",
            "loss: 0.008839684538543224\n",
            "loss: 0.008839667774736881\n",
            "loss: 0.008839670568704605\n",
            "loss: 0.008839582093060017\n",
            "loss: 0.008839479647576809\n",
            "loss: 0.00883947592228651\n",
            "loss: 0.008839430287480354\n",
            "loss: 0.00883933063596487\n",
            "loss: 0.00883934460580349\n",
            "loss: 0.008839231915771961\n",
            "loss: 0.008839176036417484\n",
            "loss: 0.00883916113525629\n",
            "loss: 0.008839089423418045\n",
            "loss: 0.008839069865643978\n",
            "loss: 0.008838963694870472\n",
            "loss: 0.008838960900902748\n",
            "loss: 0.008838891051709652\n",
            "loss: 0.00883881188929081\n",
            "loss: 0.00883876159787178\n",
            "loss: 0.008838722482323647\n",
            "loss: 0.008838639594614506\n",
            "loss: 0.008838603273034096\n",
            "loss: 0.008838549256324768\n",
            "loss: 0.008838517591357231\n",
            "loss: 0.008838457986712456\n",
            "loss: 0.008838358335196972\n",
            "loss: 0.008838344365358353\n",
            "loss: 0.008838318288326263\n",
            "loss: 0.008838274516165257\n",
            "loss: 0.008838164620101452\n",
            "loss: 0.008838118053972721\n",
            "loss: 0.008838092908263206\n",
            "loss: 0.008838102221488953\n",
            "loss: 0.008838064968585968\n",
            "loss: 0.00883803702890873\n",
            "loss: 0.008838087320327759\n",
            "loss: 0.008838075213134289\n",
            "loss: 0.008838063105940819\n",
            "loss: 0.00883816834539175\n",
            "loss: 0.008838118053972721\n",
            "loss: 0.008838134817779064\n",
            "loss: 0.008838062174618244\n",
            "loss: 0.008837982080876827\n",
            "loss: 0.008837788365781307\n",
            "loss: 0.008837608620524406\n",
            "loss: 0.008837403729557991\n",
            "loss: 0.00883728452026844\n",
            "loss: 0.0088372016325593\n",
            "loss: 0.008837209083139896\n",
            "loss: 0.008837209083139896\n",
            "loss: 0.008837240748107433\n",
            "loss: 0.008837160654366016\n",
            "loss: 0.008837073110044003\n",
            "loss: 0.008836953900754452\n",
            "loss: 0.008836884051561356\n",
            "loss: 0.008836792781949043\n",
            "loss: 0.008836781606078148\n",
            "loss: 0.008836698718369007\n",
            "loss: 0.008836657740175724\n",
            "loss: 0.008836615830659866\n",
            "loss: 0.00883649941533804\n",
            "loss: 0.008836498484015465\n",
            "loss: 0.008836444467306137\n",
            "loss: 0.008836327120661736\n",
            "loss: 0.008836344815790653\n",
            "loss: 0.008836260996758938\n",
            "loss: 0.008836164139211178\n",
            "loss: 0.00883615855127573\n",
            "loss: 0.008836058899760246\n",
            "loss: 0.008836019784212112\n",
            "loss: 0.008836012333631516\n",
            "loss: 0.008835963904857635\n",
            "loss: 0.008835836313664913\n",
            "loss: 0.00883580558001995\n",
            "loss: 0.008835799060761929\n",
            "loss: 0.008835739456117153\n",
            "loss: 0.008835673332214355\n",
            "loss: 0.008835602551698685\n",
            "loss: 0.008835582062602043\n",
            "loss: 0.008835514076054096\n",
            "loss: 0.008835403248667717\n",
            "loss: 0.008835419081151485\n",
            "loss: 0.008835280314087868\n",
            "loss: 0.008835311979055405\n",
            "loss: 0.00883522629737854\n",
            "loss: 0.008835174143314362\n",
            "loss: 0.008835164830088615\n",
            "loss: 0.00883505865931511\n",
            "loss: 0.008834969252347946\n",
            "loss: 0.008834971114993095\n",
            "loss: 0.008834883570671082\n",
            "loss: 0.008834841661155224\n",
            "loss: 0.00883483700454235\n",
            "loss: 0.00883474387228489\n",
            "loss: 0.008834686130285263\n",
            "loss: 0.008834623731672764\n",
            "loss: 0.008834629319608212\n",
            "loss: 0.008834540843963623\n",
            "loss: 0.008834480307996273\n",
            "loss: 0.008834383450448513\n",
            "loss: 0.008834312669932842\n",
            "loss: 0.008834277279675007\n",
            "loss: 0.00883425585925579\n",
            "loss: 0.008834200911223888\n",
            "loss: 0.008834147825837135\n",
            "loss: 0.00883412268012762\n",
            "loss: 0.008834026753902435\n",
            "loss: 0.008833960629999638\n",
            "loss: 0.008833926171064377\n",
            "loss: 0.00883382186293602\n",
            "loss: 0.008833806030452251\n",
            "loss: 0.00883373524993658\n",
            "loss: 0.008833672851324081\n",
            "loss: 0.008833702653646469\n",
            "loss: 0.008833607658743858\n",
            "loss: 0.008833578787744045\n",
            "loss: 0.008833511732518673\n",
            "loss: 0.008833419531583786\n",
            "loss: 0.00883334968239069\n",
            "loss: 0.008833321742713451\n",
            "loss: 0.00883330125361681\n",
            "loss: 0.008833222091197968\n",
            "loss: 0.008833175525069237\n",
            "loss: 0.008833167143166065\n",
            "loss: 0.008833024650812149\n",
            "loss: 0.008833016268908978\n",
            "loss: 0.008832979016005993\n",
            "loss: 0.008832914754748344\n",
            "loss: 0.008832876570522785\n",
            "loss: 0.008832826279103756\n",
            "loss: 0.008832753635942936\n",
            "loss: 0.008832680992782116\n",
            "loss: 0.00883264746516943\n",
            "loss: 0.008832579478621483\n",
            "loss: 0.008832513354718685\n",
            "loss: 0.008832482621073723\n",
            "loss: 0.008832413703203201\n",
            "loss: 0.008832374587655067\n",
            "loss: 0.008832298219203949\n",
            "loss: 0.008832231163978577\n",
            "loss: 0.00883213896304369\n",
            "loss: 0.008832152001559734\n",
            "loss: 0.008832062594592571\n",
            "loss: 0.008832015097141266\n",
            "loss: 0.00883193127810955\n",
            "loss: 0.008831929415464401\n",
            "loss: 0.008831891231238842\n",
            "loss: 0.008831801824271679\n",
            "loss: 0.008831774815917015\n",
            "loss: 0.008831709623336792\n",
            "loss: 0.008831670507788658\n",
            "loss: 0.00883166491985321\n",
            "loss: 0.008831622079014778\n",
            "loss: 0.00883153360337019\n",
            "loss: 0.008831542916595936\n",
            "loss: 0.008831492625176907\n",
            "loss: 0.008831423707306385\n",
            "loss: 0.00883142277598381\n",
            "loss: 0.008831420913338661\n",
            "loss: 0.008831406943500042\n",
            "loss: 0.008831331506371498\n",
            "loss: 0.008831403218209743\n",
            "loss: 0.008831378072500229\n",
            "loss: 0.008831318467855453\n",
            "loss: 0.008831215091049671\n",
            "loss: 0.008831056766211987\n",
            "loss: 0.00883101113140583\n",
            "loss: 0.008830880746245384\n",
            "loss: 0.008830747567117214\n",
            "loss: 0.008830733597278595\n",
            "loss: 0.008830701000988483\n",
            "loss: 0.008830619044601917\n",
            "loss: 0.008830558508634567\n",
            "loss: 0.008830536156892776\n",
            "loss: 0.008830491453409195\n",
            "loss: 0.008830401115119457\n",
            "loss: 0.008830220438539982\n",
            "loss: 0.008830154314637184\n",
            "loss: 0.008830200880765915\n",
            "loss: 0.00883013941347599\n",
            "loss: 0.008830098435282707\n",
            "loss: 0.00883002020418644\n",
            "loss: 0.008830002509057522\n",
            "loss: 0.008829930797219276\n",
            "loss: 0.008829798549413681\n",
            "loss: 0.008829797618091106\n",
            "loss: 0.008829724974930286\n",
            "loss: 0.008829641155898571\n",
            "loss: 0.008829622529447079\n",
            "loss: 0.008829627186059952\n",
            "loss: 0.008829500526189804\n",
            "loss: 0.008829452097415924\n",
            "loss: 0.00882943905889988\n",
            "loss: 0.008829345926642418\n",
            "loss: 0.008829331025481224\n",
            "loss: 0.008829241618514061\n",
            "loss: 0.008829155005514622\n",
            "loss: 0.008829171769320965\n",
            "loss: 0.008829126134514809\n",
            "loss: 0.008829029276967049\n",
            "loss: 0.008829000405967236\n",
            "loss: 0.008828879334032536\n",
            "loss: 0.008828815072774887\n",
            "loss: 0.00882883183658123\n",
            "loss: 0.008828775025904179\n",
            "loss: 0.008828725665807724\n",
            "loss: 0.008828641846776009\n",
            "loss: 0.008828653953969479\n",
            "loss: 0.00882852915674448\n",
            "loss: 0.008828526362776756\n",
            "loss: 0.008828455582261086\n",
            "loss: 0.00882834754884243\n",
            "loss: 0.00882829912006855\n",
            "loss: 0.008828283287584782\n",
            "loss: 0.00882821623235941\n",
            "loss: 0.008828225545585155\n",
            "loss: 0.008828084915876389\n",
            "loss: 0.008828056044876575\n",
            "loss: 0.00882801041007042\n",
            "loss: 0.00882792379707098\n",
            "loss: 0.008827855810523033\n",
            "loss: 0.008827862329781055\n",
            "loss: 0.008827808313071728\n",
            "loss: 0.008827787823975086\n",
            "loss: 0.008827684447169304\n",
            "loss: 0.008827661164104939\n",
            "loss: 0.008827576413750648\n",
            "loss: 0.00882753450423479\n",
            "loss: 0.008827517740428448\n",
            "loss: 0.008827407844364643\n",
            "loss: 0.0088273286819458\n",
            "loss: 0.008827384561300278\n",
            "loss: 0.008827324025332928\n",
            "loss: 0.008827300742268562\n",
            "loss: 0.008827220648527145\n",
            "loss: 0.008827188983559608\n",
            "loss: 0.008827123790979385\n",
            "loss: 0.008827125653624535\n",
            "loss: 0.008827058598399162\n",
            "loss: 0.00882706418633461\n",
            "loss: 0.008826934732496738\n",
            "loss: 0.008826944045722485\n",
            "loss: 0.0088269067928195\n",
            "loss: 0.008826758712530136\n",
            "loss: 0.00882673915475607\n",
            "loss: 0.008826673030853271\n",
            "loss: 0.008826594799757004\n",
            "loss: 0.0088264811784029\n",
            "loss: 0.008826423436403275\n",
            "loss: 0.008826421573758125\n",
            "loss: 0.008826307952404022\n",
            "loss: 0.008826328441500664\n",
            "loss: 0.00882621482014656\n",
            "loss: 0.008826197125017643\n",
            "loss: 0.008826114237308502\n",
            "loss: 0.008826020173728466\n",
            "loss: 0.008826012723147869\n",
            "loss: 0.00882592424750328\n",
            "loss: 0.00882590189576149\n",
            "loss: 0.008825807832181454\n",
            "loss: 0.008825788274407387\n",
            "loss: 0.008825667202472687\n",
            "loss: 0.00882568210363388\n",
            "loss: 0.008825650438666344\n",
            "loss: 0.00882552657276392\n",
            "loss: 0.008825454860925674\n",
            "loss: 0.008825428783893585\n",
            "loss: 0.008825407363474369\n",
            "loss: 0.008825313299894333\n",
            "loss: 0.008825278840959072\n",
            "loss: 0.008825251832604408\n",
            "loss: 0.008825141936540604\n",
            "loss: 0.008825119584798813\n",
            "loss: 0.008825058117508888\n",
            "loss: 0.008824963122606277\n",
            "loss: 0.008824911899864674\n",
            "loss: 0.008824881166219711\n",
            "loss: 0.008824832737445831\n",
            "loss: 0.008824815973639488\n",
            "loss: 0.008824738673865795\n",
            "loss: 0.008824676275253296\n",
            "loss: 0.008824678137898445\n",
            "loss: 0.008824585936963558\n",
            "loss: 0.00882454589009285\n",
            "loss: 0.008824493736028671\n",
            "loss: 0.008824360556900501\n",
            "loss: 0.008824318647384644\n",
            "loss: 0.00882435031235218\n",
            "loss: 0.008824233897030354\n",
            "loss: 0.008824219927191734\n",
            "loss: 0.00882416870445013\n",
            "loss: 0.008824091404676437\n",
            "loss: 0.008824135176837444\n",
            "loss: 0.008824058808386326\n",
            "loss: 0.008824038319289684\n",
            "loss: 0.008823943324387074\n",
            "loss: 0.008823991753160954\n",
            "loss: 0.008823993615806103\n",
            "loss: 0.008823891170322895\n",
            "loss: 0.008823830634355545\n",
            "loss: 0.008823785930871964\n",
            "loss: 0.008823721669614315\n",
            "loss: 0.008823636919260025\n",
            "loss: 0.00882359966635704\n",
            "loss: 0.00882343202829361\n",
            "loss: 0.008823416195809841\n",
            "loss: 0.00882330909371376\n",
            "loss: 0.008823206648230553\n",
            "loss: 0.008823156356811523\n",
            "loss: 0.008823092095553875\n",
            "loss: 0.008823058567941189\n",
            "loss: 0.00882301852107048\n",
            "loss: 0.008822966367006302\n",
            "loss: 0.008822876960039139\n",
            "loss: 0.008822895586490631\n",
            "loss: 0.008822804316878319\n",
            "loss: 0.008822774514555931\n",
            "loss: 0.008822683244943619\n",
            "loss: 0.00882264506071806\n",
            "loss: 0.008822647854685783\n",
            "loss: 0.008822557516396046\n",
            "loss: 0.008822431787848473\n",
            "loss: 0.008822405710816383\n",
            "loss: 0.008822355419397354\n",
            "loss: 0.008822361007332802\n",
            "loss: 0.008822249248623848\n",
            "loss: 0.008822157047688961\n",
            "loss: 0.008822151459753513\n",
            "loss: 0.00882211048156023\n",
            "loss: 0.008822066709399223\n",
            "loss: 0.00882196705788374\n",
            "loss: 0.008821915835142136\n",
            "loss: 0.008821859955787659\n",
            "loss: 0.008821831084787846\n",
            "loss: 0.008821781724691391\n",
            "loss: 0.008821677416563034\n",
            "loss: 0.008821710012853146\n",
            "loss: 0.008821620605885983\n",
            "loss: 0.008821558207273483\n",
            "loss: 0.008821483701467514\n",
            "loss: 0.008821442723274231\n",
            "loss: 0.00882141012698412\n",
            "loss: 0.008821379393339157\n",
            "loss: 0.008821300230920315\n",
            "loss: 0.00882121454924345\n",
            "loss: 0.00882122851908207\n",
            "loss: 0.00882113166153431\n",
            "loss: 0.008821063674986362\n",
            "loss: 0.008821036666631699\n",
            "loss: 0.008820977993309498\n",
            "loss: 0.008820953778922558\n",
            "loss: 0.008820867165923119\n",
            "loss: 0.008820931427180767\n",
            "loss: 0.008820847608149052\n",
            "loss: 0.008820789866149426\n",
            "loss: 0.008820764720439911\n",
            "loss: 0.008820687420666218\n",
            "loss: 0.008820677176117897\n",
            "loss: 0.008820692077279091\n",
            "loss: 0.008820600807666779\n",
            "loss: 0.008820596151053905\n",
            "loss: 0.008820551447570324\n",
            "loss: 0.008820458315312862\n",
            "loss: 0.008820433169603348\n",
            "loss: 0.008820351213216782\n",
            "loss: 0.00882021989673376\n",
            "loss: 0.00882021989673376\n",
            "loss: 0.00882011279463768\n",
            "loss: 0.008819963783025742\n",
            "loss: 0.00881991721689701\n",
            "loss: 0.008819823153316975\n",
            "loss: 0.008819802664220333\n",
            "loss: 0.008819772861897945\n",
            "loss: 0.00881967879831791\n",
            "loss: 0.008819617331027985\n",
            "loss: 0.00881955586373806\n",
            "loss: 0.008819556795060635\n",
            "loss: 0.008819494396448135\n",
            "loss: 0.008819489739835262\n",
            "loss: 0.008819381706416607\n",
            "loss: 0.008819300681352615\n",
            "loss: 0.008819282054901123\n",
            "loss: 0.00881921872496605\n",
            "loss: 0.008819112554192543\n",
            "loss: 0.008819131180644035\n",
            "loss: 0.008819102309644222\n",
            "loss: 0.008818978443741798\n",
            "loss: 0.008818957023322582\n",
            "loss: 0.008818916976451874\n",
            "loss: 0.008818808943033218\n",
            "loss: 0.008818784728646278\n",
            "loss: 0.008818699978291988\n",
            "loss: 0.008818687871098518\n",
            "loss: 0.008818590082228184\n",
            "loss: 0.008818534202873707\n",
            "loss: 0.008818519301712513\n",
            "loss: 0.008818455040454865\n",
            "loss: 0.008818406611680984\n",
            "loss: 0.008818361908197403\n",
            "loss: 0.008818354457616806\n",
            "loss: 0.008818205446004868\n",
            "loss: 0.008818192407488823\n",
            "loss: 0.008818154223263264\n",
            "loss: 0.008818102069199085\n",
            "loss: 0.008818008005619049\n",
            "loss: 0.008817982859909534\n",
            "loss: 0.00881789717823267\n",
            "loss: 0.0088178850710392\n",
            "loss: 0.008817831054329872\n",
            "loss: 0.008817726746201515\n",
            "loss: 0.008817693218588829\n",
            "loss: 0.008817663416266441\n",
            "loss: 0.008817593567073345\n",
            "loss: 0.008817601948976517\n",
            "loss: 0.008817533031105995\n",
            "loss: 0.008817465044558048\n",
            "loss: 0.00881746131926775\n",
            "loss: 0.008817403577268124\n",
            "loss: 0.008817332796752453\n",
            "loss: 0.008817299269139767\n",
            "loss: 0.008817273192107677\n",
            "loss: 0.00881724338978529\n",
            "loss: 0.008817223832011223\n",
            "loss: 0.008817181922495365\n",
            "loss: 0.008817153982818127\n",
            "loss: 0.008817024528980255\n",
            "loss: 0.00881692860275507\n",
            "loss: 0.00881684385240078\n",
            "loss: 0.008816806599497795\n",
            "loss: 0.008816743269562721\n",
            "loss: 0.008816701360046864\n",
            "loss: 0.008816542103886604\n",
            "loss: 0.008816513232886791\n",
            "loss: 0.008816518820822239\n",
            "loss: 0.008816426619887352\n",
            "loss: 0.00881639588624239\n",
            "loss: 0.008816377259790897\n",
            "loss: 0.008816318586468697\n",
            "loss: 0.008816228248178959\n",
            "loss: 0.008816264569759369\n",
            "loss: 0.008816180750727654\n",
            "loss: 0.008816102519631386\n",
            "loss: 0.008816028013825417\n",
            "loss: 0.008815969340503216\n",
            "loss: 0.008815944194793701\n",
            "loss: 0.008815858513116837\n",
            "loss: 0.00881580263376236\n",
            "loss: 0.008815734647214413\n",
            "loss: 0.008815750479698181\n",
            "loss: 0.008815685287117958\n",
            "loss: 0.008815634995698929\n",
            "loss: 0.008815617300570011\n",
            "loss: 0.00881548598408699\n",
            "loss: 0.00881548598408699\n",
            "loss: 0.008815374225378036\n",
            "loss: 0.008815383538603783\n",
            "loss: 0.008815301582217216\n",
            "loss: 0.008815263397991657\n",
            "loss: 0.008815133944153786\n",
            "loss: 0.008815127424895763\n",
            "loss: 0.008815130218863487\n",
            "loss: 0.008815032429993153\n",
            "loss: 0.008814936503767967\n",
            "loss: 0.008814944885671139\n",
            "loss: 0.00881483219563961\n",
            "loss: 0.00881475955247879\n",
            "loss: 0.008814804255962372\n",
            "loss: 0.008814659900963306\n",
            "loss: 0.008814581669867039\n",
            "loss: 0.008814536035060883\n",
            "loss: 0.008814468048512936\n",
            "loss: 0.008814443834125996\n",
            "loss: 0.008814353495836258\n",
            "loss: 0.008814310654997826\n",
            "loss: 0.00881427526473999\n",
            "loss: 0.00881421472877264\n",
            "loss: 0.008814143016934395\n",
            "loss: 0.00881411787122488\n",
            "loss: 0.008814023807644844\n",
            "loss: 0.008813966065645218\n",
            "loss: 0.00881393812596798\n",
            "loss: 0.008813854306936264\n",
            "loss: 0.008813809603452682\n",
            "loss: 0.008813735097646713\n",
            "loss: 0.008813713677227497\n",
            "loss: 0.00881367176771164\n",
            "loss: 0.008813653141260147\n",
            "loss: 0.008813580498099327\n",
            "loss: 0.008813527412712574\n",
            "loss: 0.008813484571874142\n",
            "loss: 0.008813431486487389\n",
            "loss: 0.008813346736133099\n",
            "loss: 0.008813368156552315\n",
            "loss: 0.008813265711069107\n",
            "loss: 0.008813257329165936\n",
            "loss: 0.008813183754682541\n",
            "loss: 0.008813145570456982\n",
            "loss: 0.008813095279037952\n",
            "loss: 0.008813115768134594\n",
            "loss: 0.008813097141683102\n",
            "loss: 0.008813075721263885\n",
            "loss: 0.008813083171844482\n",
            "loss: 0.008813115768134594\n",
            "loss: 0.008813092485070229\n",
            "loss: 0.008813186548650265\n",
            "loss: 0.008813165128231049\n",
            "loss: 0.00881313905119896\n",
            "loss: 0.008813045918941498\n",
            "loss: 0.008812903426587582\n",
            "loss: 0.00881271157413721\n",
            "loss: 0.00881250761449337\n",
            "loss: 0.00881233811378479\n",
            "loss: 0.00881227571517229\n",
            "loss: 0.008812222629785538\n",
            "loss: 0.008812259882688522\n",
            "loss: 0.008812181651592255\n",
            "loss: 0.008812183514237404\n",
            "loss: 0.00881211832165718\n",
            "loss: 0.008811996318399906\n",
            "loss: 0.008811954408884048\n",
            "loss: 0.008811790496110916\n",
            "loss: 0.008811775594949722\n",
            "loss: 0.008811766281723976\n",
            "loss: 0.00881169456988573\n",
            "loss: 0.008811617270112038\n",
            "loss: 0.008811607025563717\n",
            "loss: 0.0088115856051445\n",
            "loss: 0.00881145615130663\n",
            "loss: 0.008811447769403458\n",
            "loss: 0.008811318315565586\n",
            "loss: 0.00881128292530775\n",
            "loss: 0.008811268024146557\n",
            "loss: 0.008811197243630886\n",
            "loss: 0.00881112553179264\n",
            "loss: 0.008811086416244507\n",
            "loss: 0.008811100386083126\n",
            "loss: 0.00881099421530962\n",
            "loss: 0.0088109215721488\n",
            "loss: 0.008810896426439285\n",
            "loss: 0.008810816332697868\n",
            "loss: 0.008810736238956451\n",
            "loss: 0.008810696192085743\n",
            "loss: 0.008810686878859997\n",
            "loss: 0.008810634724795818\n",
            "loss: 0.008810474537312984\n",
            "loss: 0.008810496889054775\n",
            "loss: 0.008810406550765038\n",
            "loss: 0.00881036464124918\n",
            "loss: 0.008810356259346008\n",
            "loss: 0.00881030410528183\n",
            "loss: 0.008810239844024181\n",
            "loss: 0.008810210973024368\n",
            "loss: 0.008810093626379967\n",
            "loss: 0.00881011039018631\n",
            "loss: 0.008810008876025677\n",
            "loss: 0.008809942752122879\n",
            "loss: 0.008809958584606647\n",
            "loss: 0.00880988035351038\n",
            "loss: 0.00880979560315609\n",
            "loss: 0.00880975741893053\n",
            "loss: 0.008809731341898441\n",
            "loss: 0.00880962423980236\n",
            "loss: 0.008809581398963928\n",
            "loss: 0.008809573017060757\n",
            "loss: 0.008809494785964489\n",
            "loss: 0.008809449151158333\n",
            "loss: 0.008809355087578297\n",
            "loss: 0.008809303864836693\n",
            "loss: 0.00880929734557867\n",
            "loss: 0.008809233084321022\n",
            "loss: 0.008809145539999008\n",
            "loss: 0.008809123188257217\n",
            "loss: 0.008809100836515427\n",
            "loss: 0.008809062652289867\n",
            "loss: 0.008809003047645092\n",
            "loss: 0.008808907121419907\n",
            "loss: 0.008808835409581661\n",
            "loss: 0.008808801881968975\n",
            "loss: 0.008808734826743603\n",
            "loss: 0.008808676153421402\n",
            "loss: 0.008808678947389126\n",
            "loss: 0.008808597922325134\n",
            "loss: 0.008808556012809277\n",
            "loss: 0.008808479644358158\n",
            "loss: 0.00880836695432663\n",
            "loss: 0.008808424696326256\n",
            "loss: 0.008808343671262264\n",
            "loss: 0.008808259852230549\n",
            "loss: 0.008808213286101818\n",
            "loss: 0.008808143436908722\n",
            "loss: 0.008808079175651073\n",
            "loss: 0.008808057755231857\n",
            "loss: 0.00880797766149044\n",
            "loss: 0.008807900361716747\n",
            "loss: 0.00880788080394268\n",
            "loss: 0.008807817474007607\n",
            "loss: 0.008807818405330181\n",
            "loss: 0.00880773551762104\n",
            "loss: 0.008807677775621414\n",
            "loss: 0.008807656355202198\n",
            "loss: 0.008807573467493057\n",
            "loss: 0.008807562291622162\n",
            "loss: 0.008807468228042126\n",
            "loss: 0.008807447738945484\n",
            "loss: 0.008807424455881119\n",
            "loss: 0.008807342499494553\n",
            "loss: 0.00880736205726862\n",
            "loss: 0.008807314559817314\n",
            "loss: 0.008807248435914516\n",
            "loss: 0.008807199075818062\n",
            "loss: 0.008807145059108734\n",
            "loss: 0.008807041682302952\n",
            "loss: 0.008806983008980751\n",
            "loss: 0.008806909434497356\n",
            "loss: 0.008806867524981499\n",
            "loss: 0.008806906640529633\n",
            "loss: 0.008806766010820866\n",
            "loss: 0.008806725963950157\n",
            "loss: 0.008806705474853516\n",
            "loss: 0.008806582540273666\n",
            "loss: 0.00880659930408001\n",
            "loss: 0.00880651269108057\n",
            "loss: 0.00880645215511322\n",
            "loss: 0.008806363679468632\n",
            "loss: 0.008806404657661915\n",
            "loss: 0.008806360885500908\n",
            "loss: 0.00880623608827591\n",
            "loss: 0.008806231431663036\n",
            "loss: 0.008806104771792889\n",
            "loss: 0.008806063793599606\n",
            "loss: 0.008806077763438225\n",
            "loss: 0.008806001394987106\n",
            "loss: 0.008805898018181324\n",
            "loss: 0.008805842138826847\n",
            "loss: 0.008805796504020691\n",
            "loss: 0.008805721998214722\n",
            "loss: 0.00880566705018282\n",
            "loss: 0.008805623278021812\n",
            "loss: 0.008805588819086552\n",
            "loss: 0.008805494755506516\n",
            "loss: 0.008805484510958195\n",
            "loss: 0.008805466815829277\n",
            "loss: 0.008805363439023495\n",
            "loss: 0.00880527775734663\n",
            "loss: 0.00880529172718525\n",
            "loss: 0.008805172517895699\n",
            "loss: 0.008805178105831146\n",
            "loss: 0.008805088698863983\n",
            "loss: 0.008805043064057827\n",
            "loss: 0.008804990909993649\n",
            "loss: 0.008804946206510067\n",
            "loss: 0.008804925717413425\n",
            "loss: 0.008804820477962494\n",
            "loss: 0.008804745972156525\n",
            "loss: 0.008804739452898502\n",
            "loss: 0.008804618380963802\n",
            "loss: 0.008804612793028355\n",
            "loss: 0.008804538287222385\n",
            "loss: 0.008804507553577423\n",
            "loss: 0.008804401382803917\n",
            "loss: 0.008804406970739365\n",
            "loss: 0.008804384618997574\n",
            "loss: 0.00880424864590168\n",
            "loss: 0.008804257959127426\n",
            "loss: 0.008804213255643845\n",
            "loss: 0.008804121986031532\n",
            "loss: 0.008804050274193287\n",
            "loss: 0.008804035373032093\n",
            "loss: 0.008803983218967915\n",
            "loss: 0.00880392361432314\n",
            "loss: 0.008803868666291237\n",
            "loss: 0.008803856559097767\n",
            "loss: 0.008803793229162693\n",
            "loss: 0.00880379881709814\n",
            "loss: 0.008803674951195717\n",
            "loss: 0.008803672157227993\n",
            "loss: 0.008803675882518291\n",
            "loss: 0.00880369171500206\n",
            "loss: 0.008803674951195717\n",
            "loss: 0.008803753182291985\n",
            "loss: 0.008803813718259335\n",
            "loss: 0.00880392175167799\n",
            "loss: 0.00880388356745243\n",
            "loss: 0.008803843520581722\n",
            "loss: 0.00880371406674385\n",
            "loss: 0.008803588338196278\n",
            "loss: 0.008803283795714378\n",
            "loss: 0.008803174830973148\n",
            "loss: 0.008803064003586769\n",
            "loss: 0.008803005330264568\n",
            "loss: 0.008802946656942368\n",
            "loss: 0.008802893571555614\n",
            "loss: 0.008802876807749271\n",
            "loss: 0.008802780881524086\n",
            "loss: 0.008802772499620914\n",
            "loss: 0.00880263652652502\n",
            "loss: 0.008802543394267559\n",
            "loss: 0.008802538737654686\n",
            "loss: 0.008802521042525768\n",
            "loss: 0.008802345022559166\n",
            "loss: 0.008802343159914017\n",
            "loss: 0.008802302181720734\n",
            "loss: 0.008802229538559914\n",
            "loss: 0.008802146650850773\n",
            "loss: 0.008802168071269989\n",
            "loss: 0.008802065625786781\n",
            "loss: 0.008802004158496857\n",
            "loss: 0.00880187377333641\n",
            "loss: 0.00880185142159462\n",
            "loss: 0.00880181323736906\n",
            "loss: 0.008801844902336597\n",
            "loss: 0.008801733143627644\n",
            "loss: 0.008801693096756935\n",
            "loss: 0.008801552467048168\n",
            "loss: 0.008801514282822609\n",
            "loss: 0.008801545947790146\n",
            "loss: 0.00880143977701664\n",
            "loss: 0.008801409974694252\n",
            "loss: 0.008801378309726715\n",
            "loss: 0.008801300078630447\n",
            "loss: 0.008801179938018322\n",
            "loss: 0.00880117155611515\n",
            "loss: 0.008801131509244442\n",
            "loss: 0.008801071904599667\n",
            "loss: 0.00880105048418045\n",
            "loss: 0.008800998330116272\n",
            "loss: 0.008800966665148735\n",
            "loss: 0.008800854906439781\n",
            "loss: 0.008800828829407692\n",
            "loss: 0.008800706826150417\n",
            "loss: 0.008800719864666462\n",
            "loss: 0.008800636976957321\n",
            "loss: 0.008800630457699299\n",
            "loss: 0.008800583891570568\n",
            "loss: 0.008800518698990345\n",
            "loss: 0.008800429292023182\n",
            "loss: 0.008800407871603966\n",
            "loss: 0.008800308220088482\n",
            "loss: 0.008800292387604713\n",
            "loss: 0.008800259791314602\n",
            "loss: 0.00880018062889576\n",
            "loss: 0.008800165727734566\n",
            "loss: 0.008800101466476917\n",
            "loss: 0.00879997294396162\n",
            "loss: 0.008799951523542404\n",
            "loss: 0.008799933828413486\n",
            "loss: 0.008799850940704346\n",
            "loss: 0.008799790404736996\n",
            "loss: 0.008799764327704906\n",
            "loss: 0.008799728937447071\n",
            "loss: 0.008799671195447445\n",
            "loss: 0.00879957340657711\n",
            "loss: 0.008799532428383827\n",
            "loss: 0.008799495175480843\n",
            "loss: 0.008799475617706776\n",
            "loss: 0.008799463510513306\n",
            "loss: 0.008799371309578419\n",
            "loss: 0.008799293078482151\n",
            "loss: 0.008799285627901554\n",
            "loss: 0.008799253962934017\n",
            "loss: 0.008799114264547825\n",
            "loss: 0.008799071423709393\n",
            "loss: 0.008799020200967789\n",
            "loss: 0.008798986673355103\n",
            "loss: 0.008798914961516857\n",
            "loss: 0.008798903785645962\n",
            "loss: 0.008798805065453053\n",
            "loss: 0.008798819966614246\n",
            "loss: 0.008798720315098763\n",
            "loss: 0.008798661641776562\n",
            "loss: 0.008798566646873951\n",
            "loss: 0.00879857037216425\n",
            "loss: 0.00879848375916481\n",
            "loss: 0.00879845954477787\n",
            "loss: 0.008798442780971527\n",
            "loss: 0.008798344060778618\n",
            "loss: 0.00879830401390791\n",
            "loss: 0.008798238821327686\n",
            "loss: 0.008798188529908657\n",
            "loss: 0.008798187598586082\n",
            "loss: 0.008798050694167614\n",
            "loss: 0.008798006922006607\n",
            "loss: 0.008797970600426197\n",
            "loss: 0.008797895163297653\n",
            "loss: 0.008797864429652691\n",
            "loss: 0.008797853253781796\n",
            "loss: 0.00879781972616911\n",
            "loss: 0.008797656744718552\n",
            "loss: 0.008797629736363888\n",
            "loss: 0.008797599002718925\n",
            "loss: 0.00879756547510624\n",
            "loss: 0.008797483518719673\n",
            "loss: 0.008797425776720047\n",
            "loss: 0.008797436021268368\n",
            "loss: 0.008797328919172287\n",
            "loss: 0.00879730749875307\n",
            "loss: 0.008797249756753445\n",
            "loss: 0.008797169663012028\n",
            "loss: 0.008797131478786469\n",
            "loss: 0.008797099813818932\n",
            "loss: 0.00879698246717453\n",
            "loss: 0.00879696849733591\n",
            "loss: 0.008796945214271545\n",
            "loss: 0.008796877227723598\n",
            "loss: 0.008796820417046547\n",
            "loss: 0.00879673007875681\n",
            "loss: 0.008796719834208488\n",
            "loss: 0.008796583861112595\n",
            "loss: 0.008796587586402893\n",
            "loss: 0.008796554058790207\n",
            "loss: 0.008796509355306625\n",
            "loss: 0.008796477690339088\n",
            "loss: 0.008796432986855507\n",
            "loss: 0.008796371519565582\n",
            "loss: 0.008796312846243382\n",
            "loss: 0.00879627000540495\n",
            "loss: 0.008796208538115025\n",
            "loss: 0.008796127513051033\n",
            "loss: 0.008796061389148235\n",
            "loss: 0.008796046487987041\n",
            "loss: 0.008795990608632565\n",
            "loss: 0.008795924484729767\n",
            "loss: 0.008795916102826595\n",
            "loss: 0.00879587046802044\n",
            "loss: 0.008795888163149357\n",
            "loss: 0.008795901201665401\n",
            "loss: 0.008795890025794506\n",
            "loss: 0.00879595149308443\n",
            "loss: 0.008795914240181446\n",
            "loss: 0.008795969188213348\n",
            "loss: 0.008795907720923424\n",
            "loss: 0.008795970119535923\n",
            "loss: 0.00879580806940794\n",
            "loss: 0.008795653469860554\n",
            "loss: 0.008795425295829773\n",
            "loss: 0.008795298635959625\n",
            "loss: 0.008795171044766903\n",
            "loss: 0.00879505556076765\n",
            "loss: 0.008795114234089851\n",
            "loss: 0.008795087225735188\n",
            "loss: 0.00879509188234806\n",
            "loss: 0.008794987574219704\n",
            "loss: 0.008794979192316532\n",
            "loss: 0.008794866502285004\n",
            "loss: 0.008794737048447132\n",
            "loss: 0.008794686757028103\n",
            "loss: 0.008794617839157581\n",
            "loss: 0.008794594556093216\n",
            "loss: 0.00879452470690012\n",
            "loss: 0.008794499561190605\n",
            "loss: 0.008794445544481277\n",
            "loss: 0.008794346824288368\n",
            "loss: 0.008794281631708145\n",
            "loss: 0.008794219233095646\n",
            "loss: 0.008794136345386505\n",
            "loss: 0.008794182911515236\n",
            "loss: 0.008794061839580536\n",
            "loss: 0.008794035762548447\n",
            "loss: 0.008793998509645462\n",
            "loss: 0.008793897926807404\n",
            "loss: 0.008793916553258896\n",
            "loss: 0.008793842978775501\n",
            "loss: 0.008793751709163189\n",
            "loss: 0.008793727494776249\n",
            "loss: 0.008793644607067108\n",
            "loss: 0.0087936045601964\n",
            "loss: 0.008793593384325504\n",
            "loss: 0.008793514221906662\n",
            "loss: 0.008793463930487633\n",
            "loss: 0.008793407119810581\n",
            "loss: 0.008793317712843418\n",
            "loss: 0.008793261833488941\n",
            "loss: 0.008793246001005173\n",
            "loss: 0.008793218992650509\n",
            "loss: 0.008793149143457413\n",
            "loss: 0.008793053217232227\n",
            "loss: 0.008793012239038944\n",
            "loss: 0.008792947046458721\n",
            "loss: 0.008792976848781109\n",
            "loss: 0.008792798966169357\n",
            "loss: 0.00879284180700779\n",
            "loss: 0.008792784065008163\n",
            "loss: 0.008792687207460403\n",
            "loss: 0.008792637847363949\n",
            "loss: 0.008792608045041561\n",
            "loss: 0.008792546577751637\n",
            "loss: 0.00879249069839716\n",
            "loss: 0.008792446926236153\n",
            "loss: 0.008792351931333542\n",
            "loss: 0.008792366832494736\n",
            "loss: 0.00879224855452776\n",
            "loss: 0.008792237378656864\n",
            "loss: 0.008792172186076641\n",
            "loss: 0.00879211537539959\n",
            "loss: 0.00879205483943224\n",
            "loss: 0.008792075328528881\n",
            "loss: 0.008792010135948658\n",
            "loss: 0.008791935630142689\n",
            "loss: 0.008791876956820488\n",
            "loss: 0.008791820146143436\n",
            "loss: 0.008791781961917877\n",
            "loss: 0.008791722357273102\n",
            "loss: 0.008791690692305565\n",
            "loss: 0.008791595697402954\n",
            "loss: 0.008791614323854446\n",
            "loss: 0.008791541680693626\n",
            "loss: 0.008791415020823479\n",
            "loss: 0.008791384287178516\n",
            "loss: 0.008791382424533367\n",
            "loss: 0.008791285566985607\n",
            "loss: 0.008791256695985794\n",
            "loss: 0.008791221305727959\n",
            "loss: 0.008791141211986542\n",
            "loss: 0.008791104890406132\n",
            "loss: 0.008791024796664715\n",
            "loss: 0.008791016414761543\n",
            "loss: 0.008790886029601097\n",
            "loss: 0.008790846914052963\n",
            "loss: 0.008790825493633747\n",
            "loss: 0.008790762163698673\n",
            "loss: 0.008790754713118076\n",
            "loss: 0.00879068486392498\n",
            "loss: 0.00879061222076416\n",
            "loss: 0.008790535852313042\n",
            "loss: 0.008790533989667892\n",
            "loss: 0.008790513500571251\n",
            "loss: 0.008790429681539536\n",
            "loss: 0.008790315128862858\n",
            "loss: 0.008790317922830582\n",
            "loss: 0.00879021268337965\n",
            "loss: 0.00879021268337965\n",
            "loss: 0.008790118619799614\n",
            "loss: 0.00879006739705801\n",
            "loss: 0.00879003293812275\n",
            "loss: 0.00879000872373581\n",
            "loss: 0.008789986371994019\n",
            "loss: 0.008789930492639542\n",
            "loss: 0.00878979079425335\n",
            "loss: 0.008789789862930775\n",
            "loss: 0.008789719082415104\n",
            "loss: 0.008789665065705776\n",
            "loss: 0.008789614774286747\n",
            "loss: 0.008789642713963985\n",
            "loss: 0.008789601735770702\n",
            "loss: 0.008789591491222382\n",
            "loss: 0.008789525367319584\n",
            "loss: 0.008789611048996449\n",
            "loss: 0.008789568208158016\n",
            "loss: 0.008789562620222569\n",
            "loss: 0.008789506740868092\n",
            "loss: 0.008789511397480965\n",
            "loss: 0.008789444342255592\n",
            "loss: 0.008789357729256153\n",
            "loss: 0.008789288811385632\n",
            "loss: 0.008789206854999065\n",
            "loss: 0.0087891211733222\n",
            "loss: 0.008788962848484516\n",
            "loss: 0.008788947016000748\n",
            "loss: 0.008788867853581905\n",
            "loss: 0.008788706734776497\n",
            "loss: 0.008788663893938065\n",
            "loss: 0.008788558654487133\n",
            "loss: 0.008788532577455044\n",
            "loss: 0.008788533508777618\n",
            "loss: 0.008788513951003551\n",
            "loss: 0.008788513951003551\n",
            "loss: 0.008788391016423702\n",
            "loss: 0.008788324892520905\n",
            "loss: 0.008788232691586018\n",
            "loss: 0.008788112550973892\n",
            "loss: 0.008788102306425571\n",
            "loss: 0.008788022212684155\n",
            "loss: 0.008787996135652065\n",
            "loss: 0.00878796074539423\n",
            "loss: 0.008787967264652252\n",
            "loss: 0.008787834085524082\n",
            "loss: 0.008787818253040314\n",
            "loss: 0.008787701837718487\n",
            "loss: 0.008787726983428001\n",
            "loss: 0.008787648752331734\n",
            "loss: 0.00878756120800972\n",
            "loss: 0.008787544444203377\n",
            "loss: 0.008787485770881176\n",
            "loss: 0.008787410333752632\n",
            "loss: 0.008787402883172035\n",
            "loss: 0.008787316270172596\n",
            "loss: 0.008787240833044052\n",
            "loss: 0.008787186816334724\n",
            "loss: 0.008787157945334911\n",
            "loss: 0.008787157945334911\n",
            "loss: 0.00878703873604536\n",
            "loss: 0.008786964230239391\n",
            "loss: 0.008786918595433235\n",
            "loss: 0.008786899037659168\n",
            "loss: 0.008786874823272228\n",
            "loss: 0.00878685712814331\n",
            "loss: 0.008786726742982864\n",
            "loss: 0.008786654099822044\n",
            "loss: 0.008786670863628387\n",
            "loss: 0.008786588907241821\n",
            "loss: 0.00878653209656477\n",
            "loss: 0.00878642126917839\n",
            "loss: 0.008786406368017197\n",
            "loss: 0.008786359801888466\n",
            "loss: 0.008786290884017944\n",
            "loss: 0.008786258287727833\n",
            "loss: 0.008786261081695557\n",
            "loss: 0.008786175400018692\n",
            "loss: 0.008786104619503021\n",
            "loss: 0.008786045014858246\n",
            "loss: 0.008786019869148731\n",
            "loss: 0.008785932324826717\n",
            "loss: 0.008785885758697987\n",
            "loss: 0.008785834535956383\n",
            "loss: 0.008785798214375973\n",
            "loss: 0.0087857311591506\n",
            "loss: 0.008785695768892765\n",
            "loss: 0.008785608224570751\n",
            "loss: 0.008785504847764969\n",
            "loss: 0.008785543031990528\n",
            "loss: 0.00878547877073288\n",
            "loss: 0.008785453625023365\n",
            "loss: 0.00878533162176609\n",
            "loss: 0.008785329759120941\n",
            "loss: 0.008785303682088852\n",
            "loss: 0.008785226382315159\n",
            "loss: 0.008785148151218891\n",
            "loss: 0.0087851257994771\n",
            "loss: 0.008785051293671131\n",
            "loss: 0.008784986101090908\n",
            "loss: 0.008784939534962177\n",
            "loss: 0.008784920908510685\n",
            "loss: 0.008784865960478783\n",
            "loss: 0.00878479890525341\n",
            "loss: 0.008784712292253971\n",
            "loss: 0.00878467969596386\n",
            "loss: 0.008784657344222069\n",
            "loss: 0.008784602396190166\n",
            "loss: 0.0087845204398036\n",
            "loss: 0.00878443755209446\n",
            "loss: 0.008784431032836437\n",
            "loss: 0.008784396573901176\n",
            "loss: 0.008784327656030655\n",
            "loss: 0.008784277364611626\n",
            "loss: 0.008784276433289051\n",
            "loss: 0.008784228004515171\n",
            "loss: 0.008784208446741104\n",
            "loss: 0.008784118108451366\n",
            "loss: 0.008784038946032524\n",
            "loss: 0.008784088306128979\n",
            "loss: 0.008784002624452114\n",
            "loss: 0.008784003555774689\n",
            "loss: 0.008784028701484203\n",
            "loss: 0.008783901110291481\n",
            "loss: 0.008783958852291107\n",
            "loss: 0.008783896453678608\n",
            "loss: 0.008783821016550064\n",
            "loss: 0.008783799596130848\n",
            "loss: 0.00878370925784111\n",
            "loss: 0.008783665485680103\n",
            "loss: 0.00878349132835865\n",
            "loss: 0.008783392608165741\n",
            "loss: 0.008783352561295033\n",
            "loss: 0.008783224038779736\n",
            "loss: 0.008783132769167423\n",
            "loss: 0.008783051744103432\n",
            "loss: 0.00878305546939373\n",
            "loss: 0.008783021941781044\n",
            "loss: 0.00878300704061985\n",
            "loss: 0.008782976306974888\n",
            "loss: 0.008782886900007725\n",
            "loss: 0.008782892487943172\n",
            "loss: 0.008782749064266682\n",
            "loss: 0.008782770484685898\n",
            "loss: 0.008782677352428436\n",
            "loss: 0.008782599121332169\n",
            "loss: 0.008782532997429371\n",
            "loss: 0.00878249853849411\n",
            "loss: 0.008782475255429745\n",
            "loss: 0.008782366290688515\n",
            "loss: 0.008782383054494858\n",
            "loss: 0.008782334625720978\n",
            "loss: 0.0087822787463665\n",
            "loss: 0.008782160468399525\n",
            "loss: 0.008782153017818928\n",
            "loss: 0.008782039396464825\n",
            "loss: 0.008782032877206802\n",
            "loss: 0.008781936019659042\n",
            "loss: 0.008781942538917065\n",
            "loss: 0.008781883865594864\n",
            "loss: 0.00878180842846632\n",
            "loss: 0.008781783282756805\n",
            "loss: 0.00878170970827341\n",
            "loss: 0.008781631477177143\n",
            "loss: 0.008781621232628822\n",
            "loss: 0.008781572803854942\n",
            "loss: 0.0087814936414361\n",
            "loss: 0.00878144707530737\n",
            "loss: 0.008781327866017818\n",
            "loss: 0.00878133624792099\n",
            "loss: 0.008781339973211288\n",
            "loss: 0.008781209588050842\n",
            "loss: 0.008781238459050655\n",
            "loss: 0.008781085722148418\n",
            "loss: 0.00878109224140644\n",
            "loss: 0.008781015872955322\n",
            "loss: 0.0087809469550848\n",
            "loss: 0.008780919015407562\n",
            "loss: 0.008780854754149914\n",
            "loss: 0.008780849166214466\n",
            "loss: 0.008780783042311668\n",
            "loss: 0.00878067035228014\n",
            "loss: 0.008780700154602528\n",
            "loss: 0.008780565112829208\n",
            "loss: 0.008780556730926037\n",
            "loss: 0.008780491538345814\n",
            "loss: 0.008780503645539284\n",
            "loss: 0.00878036580979824\n",
            "loss: 0.008780323900282383\n",
            "loss: 0.008780346252024174\n",
            "loss: 0.00878024660050869\n",
            "loss: 0.008780273608863354\n",
            "loss: 0.008780118077993393\n",
            "loss: 0.00878012552857399\n",
            "loss: 0.008780070580542088\n",
            "loss: 0.008779962547123432\n",
            "loss: 0.008779903873801231\n",
            "loss: 0.008779961615800858\n",
            "loss: 0.008779824711382389\n",
            "loss: 0.008779793046414852\n",
            "loss: 0.008779718540608883\n",
            "loss: 0.008779702708125114\n",
            "loss: 0.008779648691415787\n",
            "loss: 0.00877962727099657\n",
            "loss: 0.008779607713222504\n",
            "loss: 0.008779531344771385\n",
            "loss: 0.008779436349868774\n",
            "loss: 0.00877941120415926\n",
            "loss: 0.008779428899288177\n",
            "loss: 0.008779353462159634\n",
            "loss: 0.008779293857514858\n",
            "loss: 0.008779351599514484\n",
            "loss: 0.00877928826957941\n",
            "loss: 0.008779238909482956\n",
            "loss: 0.008779218420386314\n",
            "loss: 0.008779145777225494\n",
            "loss: 0.008779109455645084\n",
            "loss: 0.008778966963291168\n",
            "loss: 0.008778898045420647\n",
            "loss: 0.008778773248195648\n",
            "loss: 0.008778718300163746\n",
            "loss: 0.008778640069067478\n",
            "loss: 0.00877853762358427\n",
            "loss: 0.008778509683907032\n",
            "loss: 0.00877849105745554\n",
            "loss: 0.008778419345617294\n",
            "loss: 0.008778379298746586\n",
            "loss: 0.008778304792940617\n",
            "loss: 0.008778322488069534\n",
            "loss: 0.008778237737715244\n",
            "loss: 0.008778184652328491\n",
            "loss: 0.00877808965742588\n",
            "loss: 0.008778047747910023\n",
            "loss: 0.008778017945587635\n",
            "loss: 0.008777996525168419\n",
            "loss: 0.008777888491749763\n",
            "loss: 0.008777836337685585\n",
            "loss: 0.008777833543717861\n",
            "loss: 0.008777736686170101\n",
            "loss: 0.008777610957622528\n",
            "loss: 0.008777669630944729\n",
            "loss: 0.008777609094977379\n",
            "loss: 0.008777563460171223\n",
            "loss: 0.008777536451816559\n",
            "loss: 0.008777424693107605\n",
            "loss: 0.008777338080108166\n",
            "loss: 0.008777315728366375\n",
            "loss: 0.008777288720011711\n",
            "loss: 0.008777271956205368\n",
            "loss: 0.008777172304689884\n",
            "loss: 0.008777114562690258\n",
            "loss: 0.008777023293077946\n",
            "loss: 0.008777020499110222\n",
            "loss: 0.00877698976546526\n",
            "loss: 0.0087768929079175\n",
            "loss: 0.00877684447914362\n",
            "loss: 0.008776828646659851\n",
            "loss: 0.008776748552918434\n",
            "loss: 0.008776718750596046\n",
            "loss: 0.008776663802564144\n",
            "loss: 0.008776584640145302\n",
            "loss: 0.008776557631790638\n",
            "loss: 0.008776459842920303\n",
            "loss: 0.008776390925049782\n",
            "loss: 0.008776383474469185\n",
            "loss: 0.008776307106018066\n",
            "loss: 0.00877632200717926\n",
            "loss: 0.008776267990469933\n",
            "loss: 0.00877621490508318\n",
            "loss: 0.00877615250647068\n",
            "loss: 0.008776037953794003\n",
            "loss: 0.008776027709245682\n",
            "loss: 0.008776044473052025\n",
            "loss: 0.008775937370955944\n",
            "loss: 0.008775866590440273\n",
            "loss: 0.008775817230343819\n",
            "loss: 0.008775826543569565\n",
            "loss: 0.008775697089731693\n",
            "loss: 0.008775655180215836\n",
            "loss: 0.008775610476732254\n",
            "loss: 0.00877551268786192\n",
            "loss: 0.008775518275797367\n",
            "loss: 0.008775493130087852\n",
            "loss: 0.008775424212217331\n",
            "loss: 0.008775335736572742\n",
            "loss: 0.008775349706411362\n",
            "loss: 0.008775309659540653\n",
            "loss: 0.008775255642831326\n",
            "loss: 0.008775249123573303\n",
            "loss: 0.008775120601058006\n",
            "loss: 0.008775097317993641\n",
            "loss: 0.008775069378316402\n",
            "loss: 0.008775054477155209\n",
            "loss: 0.008775042369961739\n",
            "loss: 0.008775047957897186\n",
            "loss: 0.008774932473897934\n",
            "loss: 0.008774899877607822\n",
            "loss: 0.008774777874350548\n",
            "loss: 0.00877474993467331\n",
            "loss: 0.008774623274803162\n",
            "loss: 0.008774572983384132\n",
            "loss: 0.008774513378739357\n",
            "loss: 0.00877438299357891\n",
            "loss: 0.008774344809353352\n",
            "loss: 0.008774369955062866\n",
            "loss: 0.008774297311902046\n",
            "loss: 0.008774222806096077\n",
            "loss: 0.008774175308644772\n",
            "loss: 0.00877409242093563\n",
            "loss: 0.00877407193183899\n",
            "loss: 0.008773921988904476\n",
            "loss: 0.008773937821388245\n",
            "loss: 0.00877385213971138\n",
            "loss: 0.008773881010711193\n",
            "loss: 0.008773816749453545\n",
            "loss: 0.008773748762905598\n",
            "loss: 0.00877365842461586\n",
            "loss: 0.008773619309067726\n",
            "loss: 0.008773625828325748\n",
            "loss: 0.008773574605584145\n",
            "loss: 0.008773481473326683\n",
            "loss: 0.008773411624133587\n",
            "loss: 0.008773395791649818\n",
            "loss: 0.008773327805101871\n",
            "loss: 0.008773253299295902\n",
            "loss: 0.008773228153586388\n",
            "loss: 0.008773162961006165\n",
            "loss: 0.008773104287683964\n",
            "loss: 0.008773035369813442\n",
            "loss: 0.008773015812039375\n",
            "loss: 0.008772947825491428\n",
            "loss: 0.008772891014814377\n",
            "loss: 0.008772809989750385\n",
            "loss: 0.008772829547524452\n",
            "loss: 0.008772703818976879\n",
            "loss: 0.008772648870944977\n",
            "loss: 0.008772667497396469\n",
            "loss: 0.00877261534333229\n",
            "loss: 0.008772514760494232\n",
            "loss: 0.008772456087172031\n",
            "loss: 0.008772440254688263\n",
            "loss: 0.008772431872785091\n",
            "loss: 0.008772372268140316\n",
            "loss: 0.008772293105721474\n",
            "loss: 0.00877221766859293\n",
            "loss: 0.008772223256528378\n",
            "loss: 0.008772127330303192\n",
            "loss: 0.008772086352109909\n",
            "loss: 0.008772014640271664\n",
            "loss: 0.00877201184630394\n",
            "loss: 0.008771935477852821\n",
            "loss: 0.008771914057433605\n",
            "loss: 0.008771861903369427\n",
            "loss: 0.008771792985498905\n",
            "loss: 0.008771836757659912\n",
            "loss: 0.008771807886660099\n",
            "loss: 0.008771673776209354\n",
            "loss: 0.008771663531661034\n",
            "loss: 0.008771666325628757\n",
            "loss: 0.008771616034209728\n",
            "loss: 0.008771579712629318\n",
            "loss: 0.008771508000791073\n",
            "loss: 0.008771505206823349\n",
            "loss: 0.008771425113081932\n",
            "loss: 0.00877135619521141\n",
            "loss: 0.008771216496825218\n",
            "loss: 0.008771168068051338\n",
            "loss: 0.008771066553890705\n",
            "loss: 0.008770965971052647\n",
            "loss: 0.008770949207246304\n",
            "loss: 0.00877086166292429\n",
            "loss: 0.00877077691257\n",
            "loss: 0.008770790882408619\n",
            "loss: 0.008770754560828209\n",
            "loss: 0.008770640008151531\n",
            "loss: 0.008770647458732128\n",
            "loss: 0.008770599029958248\n",
            "loss: 0.008770562708377838\n",
            "loss: 0.008770513348281384\n",
            "loss: 0.008770409040153027\n",
            "loss: 0.008770356886088848\n",
            "loss: 0.008770342916250229\n",
            "loss: 0.008770282380282879\n",
            "loss: 0.008770149201154709\n",
            "loss: 0.008770124055445194\n",
            "loss: 0.008770099841058254\n",
            "loss: 0.008770045824348927\n",
            "loss: 0.008770009502768517\n",
            "loss: 0.00876991543918848\n",
            "loss: 0.008769858628511429\n",
            "loss: 0.008769907057285309\n",
            "loss: 0.008769746869802475\n",
            "loss: 0.008769717067480087\n",
            "loss: 0.008769655600190163\n",
            "loss: 0.008769613690674305\n",
            "loss: 0.008769598789513111\n",
            "loss: 0.008769523352384567\n",
            "loss: 0.008769434876739979\n",
            "loss: 0.008769395761191845\n",
            "loss: 0.00876939482986927\n",
            "loss: 0.008769311010837555\n",
            "loss: 0.008769259788095951\n",
            "loss: 0.008769160136580467\n",
            "loss: 0.008769168518483639\n",
            "loss: 0.008769072592258453\n",
            "loss: 0.008769051171839237\n",
            "loss: 0.008768949657678604\n",
            "loss: 0.008769014850258827\n",
            "loss: 0.008768917061388493\n",
            "loss: 0.008768855594098568\n",
            "loss: 0.00876879133284092\n",
            "loss: 0.008768705651164055\n",
            "loss: 0.008768698200583458\n",
            "loss: 0.008768623694777489\n",
            "loss: 0.008768596686422825\n",
            "loss: 0.00876855943351984\n",
            "loss: 0.00876852311193943\n",
            "loss: 0.008768456988036633\n",
            "loss: 0.008768436498939991\n",
            "loss: 0.008768352679908276\n",
            "loss: 0.008768334053456783\n",
            "loss: 0.008768248371779919\n",
            "loss: 0.008768195286393166\n",
            "loss: 0.00876807514578104\n",
            "loss: 0.008768068626523018\n",
            "loss: 0.008768029510974884\n",
            "loss: 0.008767946623265743\n",
            "loss: 0.008767903782427311\n",
            "loss: 0.00876785907894373\n",
            "loss: 0.008767884224653244\n",
            "loss: 0.008767797611653805\n",
            "loss: 0.008767776191234589\n",
            "loss: 0.00876770168542862\n",
            "loss: 0.008767715655267239\n",
            "loss: 0.008767735213041306\n",
            "loss: 0.008767747320234776\n",
            "loss: 0.008767749182879925\n",
            "loss: 0.008767719380557537\n",
            "loss: 0.008767770603299141\n",
            "loss: 0.008767794817686081\n",
            "loss: 0.00876770168542862\n",
            "loss: 0.008767601102590561\n",
            "loss: 0.008767475374042988\n",
            "loss: 0.00876724161207676\n",
            "loss: 0.008767081424593925\n",
            "loss: 0.00876691285520792\n",
            "loss: 0.008766925893723965\n",
            "loss: 0.008766936138272285\n",
            "loss: 0.008766925893723965\n",
            "loss: 0.008766897954046726\n",
            "loss: 0.00876689050346613\n",
            "loss: 0.008766801096498966\n",
            "loss: 0.008766683749854565\n",
            "loss: 0.008766626939177513\n",
            "loss: 0.00876646675169468\n",
            "loss: 0.00876643043011427\n",
            "loss: 0.008766410872340202\n",
            "loss: 0.008766371756792068\n",
            "loss: 0.008766322396695614\n",
            "loss: 0.00876630563288927\n",
            "loss: 0.008766225539147854\n",
            "loss: 0.0087661724537611\n",
            "loss: 0.008766116574406624\n",
            "loss: 0.008766019716858864\n",
            "loss: 0.008765977807343006\n",
            "loss: 0.008765902370214462\n",
            "loss: 0.008765860460698605\n",
            "loss: 0.008765804581344128\n",
            "loss: 0.008765822276473045\n",
            "loss: 0.008765696547925472\n",
            "loss: 0.008765681646764278\n",
            "loss: 0.008765670470893383\n",
            "loss: 0.008765608072280884\n",
            "loss: 0.008765513077378273\n",
            "loss: 0.008765468373894691\n",
            "loss: 0.008765380829572678\n",
            "loss: 0.008765412494540215\n",
            "loss: 0.008765344507992268\n",
            "loss: 0.00876525603234768\n",
            "loss: 0.008765262551605701\n",
            "loss: 0.008765180595219135\n",
            "loss: 0.008765112608671188\n",
            "loss: 0.00876507069915533\n",
            "loss: 0.008764982223510742\n",
            "loss: 0.00876495148986578\n",
            "loss: 0.00876487698405981\n",
            "loss: 0.008764844387769699\n",
            "loss: 0.008764799684286118\n",
            "loss: 0.008764734491705894\n",
            "loss: 0.008764651603996754\n",
            "loss: 0.008764658123254776\n",
            "loss: 0.008764617145061493\n",
            "loss: 0.008764567784965038\n",
            "loss: 0.00876449141651392\n",
            "loss: 0.008764434605836868\n",
            "loss: 0.008764374069869518\n",
            "loss: 0.008764355443418026\n",
            "loss: 0.008764219470322132\n",
            "loss: 0.008764225989580154\n",
            "loss: 0.008764170110225677\n",
            "loss: 0.0087641142308712\n",
            "loss: 0.008764061145484447\n",
            "loss: 0.008764039725065231\n",
            "loss: 0.00876398105174303\n",
            "loss: 0.008763941936194897\n",
            "loss: 0.00876384973526001\n",
            "loss: 0.008763815276324749\n",
            "loss: 0.008763761259615421\n",
            "loss: 0.00876370444893837\n",
            "loss: 0.008763671852648258\n",
            "loss: 0.008763540536165237\n",
            "loss: 0.008763582445681095\n",
            "loss: 0.008763529360294342\n",
            "loss: 0.00876341387629509\n",
            "loss: 0.008763385005295277\n",
            "loss: 0.008763364516198635\n",
            "loss: 0.008763301186263561\n",
            "loss: 0.008763216435909271\n",
            "loss: 0.00876322016119957\n",
            "loss: 0.008763182908296585\n",
            "loss: 0.008763083256781101\n",
            "loss: 0.00876297801733017\n",
            "loss: 0.008763018995523453\n",
            "loss: 0.008762966841459274\n",
            "loss: 0.008762865327298641\n",
            "loss: 0.008762824349105358\n",
            "loss: 0.008762862533330917\n",
            "loss: 0.008762716315686703\n",
            "loss: 0.008762749843299389\n",
            "loss: 0.008762627840042114\n",
            "loss: 0.008762630634009838\n",
            "loss: 0.008762613870203495\n",
            "loss: 0.008762562647461891\n",
            "loss: 0.00876250583678484\n",
            "loss: 0.008762460201978683\n",
            "loss: 0.008762490004301071\n",
            "loss: 0.008762393146753311\n",
            "loss: 0.008762424811720848\n",
            "loss: 0.008762408047914505\n",
            "loss: 0.008762326091527939\n",
            "loss: 0.008762313984334469\n",
            "loss: 0.008762188255786896\n",
            "loss: 0.008762035518884659\n",
            "loss: 0.00876203179359436\n",
            "loss: 0.008761873468756676\n",
            "loss: 0.008761834353208542\n",
            "loss: 0.008761726319789886\n",
            "loss: 0.00876169465482235\n",
            "loss: 0.00876171700656414\n",
            "loss: 0.008761686272919178\n",
            "loss: 0.008761631324887276\n",
            "loss: 0.008761522360146046\n",
            "loss: 0.008761519566178322\n",
            "loss: 0.008761399425566196\n",
            "loss: 0.008761316537857056\n",
            "loss: 0.008761320263147354\n",
            "loss: 0.008761262521147728\n",
            "loss: 0.008761231787502766\n",
            "loss: 0.00876112375408411\n",
            "loss: 0.008761124685406685\n",
            "loss: 0.008761069737374783\n",
            "loss: 0.008760993368923664\n",
            "loss: 0.008760910481214523\n",
            "loss: 0.008760915137827396\n",
            "loss: 0.00876088347285986\n",
            "loss: 0.008760795928537846\n",
            "loss: 0.008760718628764153\n",
            "loss: 0.008760650642216206\n",
            "loss: 0.008760652504861355\n",
            "loss: 0.008760533295571804\n",
            "loss: 0.008760469034314156\n",
            "loss: 0.00876046996563673\n",
            "loss: 0.008760416880249977\n",
            "loss: 0.008760404773056507\n",
            "loss: 0.00876030046492815\n",
            "loss: 0.008760295808315277\n",
            "loss: 0.008760234341025352\n",
            "loss: 0.00876015704125166\n",
            "loss: 0.008760136552155018\n",
            "loss: 0.008760059252381325\n",
            "loss: 0.00875994935631752\n",
            "loss: 0.008759948424994946\n",
            "loss: 0.008759877644479275\n",
            "loss: 0.008759819902479649\n",
            "loss: 0.008759846910834312\n",
            "loss: 0.008759710006415844\n",
            "loss: 0.008759766817092896\n",
            "loss: 0.00875964667648077\n",
            "loss: 0.008759626187384129\n",
            "loss: 0.008759588934481144\n",
            "loss: 0.00875946320593357\n",
            "loss: 0.008759476244449615\n",
            "loss: 0.0087594548240304\n",
            "loss: 0.008759397082030773\n",
            "loss: 0.008759349584579468\n",
            "loss: 0.008759346790611744\n",
            "loss: 0.008759278804063797\n",
            "loss: 0.008759322576224804\n",
            "loss: 0.008759391494095325\n",
            "loss: 0.008759361691772938\n",
            "loss: 0.00875936821103096\n",
            "loss: 0.00875941663980484\n",
            "loss: 0.008759410120546818\n",
            "loss: 0.008759373798966408\n",
            "loss: 0.008759171701967716\n",
            "loss: 0.008759018033742905\n",
            "loss: 0.00875881128013134\n",
            "loss: 0.008758685551583767\n",
            "loss: 0.008758598938584328\n",
            "loss: 0.008758475072681904\n",
            "loss: 0.008758601732552052\n",
            "loss: 0.008758528158068657\n",
            "loss: 0.00875851884484291\n",
            "loss: 0.00875845830887556\n",
            "loss: 0.008758392184972763\n",
            "loss: 0.00875826645642519\n",
            "loss: 0.008758162148296833\n",
            "loss: 0.008758073672652245\n",
            "loss: 0.00875798612833023\n",
            "loss: 0.008758032694458961\n",
            "loss: 0.0087579982355237\n",
            "loss: 0.008757979609072208\n",
            "loss: 0.008757976815104485\n",
            "loss: 0.008757837116718292\n",
            "loss: 0.008757736533880234\n",
            "loss: 0.008757706731557846\n",
            "loss: 0.00875758659094572\n",
            "loss: 0.008757594972848892\n",
            "loss: 0.008757573552429676\n",
            "loss: 0.00875752605497837\n",
            "loss: 0.008757445029914379\n",
            "loss: 0.008757411502301693\n",
            "loss: 0.008757351897656918\n",
            "loss: 0.008757276460528374\n",
            "loss: 0.008757215924561024\n",
            "loss: 0.008757147006690502\n",
            "loss: 0.008757125586271286\n",
            "loss: 0.008757057599723339\n",
            "loss: 0.008757032454013824\n",
            "loss: 0.008756985887885094\n",
            "loss: 0.008756936527788639\n",
            "loss: 0.00875687226653099\n",
            "loss: 0.008756831288337708\n",
            "loss: 0.008756772615015507\n",
            "loss: 0.008756689727306366\n",
            "loss: 0.008756676688790321\n",
            "loss: 0.008756613358855247\n",
            "loss: 0.008756550028920174\n",
            "loss: 0.00875653326511383\n",
            "loss: 0.008756469003856182\n",
            "loss: 0.008756435476243496\n",
            "loss: 0.008756331168115139\n",
            "loss: 0.00875630509108305\n",
            "loss: 0.008756227791309357\n",
            "loss: 0.008756191469728947\n",
            "loss: 0.008756126277148724\n",
            "loss: 0.008756110444664955\n",
            "loss: 0.008756065741181374\n",
            "loss: 0.008755967952311039\n",
            "loss: 0.008755906485021114\n",
            "loss: 0.008755946531891823\n",
            "loss: 0.008755823597311974\n",
            "loss: 0.008755750954151154\n",
            "loss: 0.008755742572247982\n",
            "loss: 0.0087556978687644\n",
            "loss: 0.008755652233958244\n",
            "loss: 0.008755532093346119\n",
            "loss: 0.008755531162023544\n",
            "loss: 0.008755436167120934\n",
            "loss: 0.008755410090088844\n",
            "loss: 0.008755401708185673\n",
            "loss: 0.008755353279411793\n",
            "loss: 0.008755285292863846\n",
            "loss: 0.00875521544367075\n",
            "loss: 0.00875517912209034\n",
            "loss: 0.008755103684961796\n",
            "loss: 0.008755076676607132\n",
            "loss: 0.008754980750381947\n",
            "loss: 0.008754963055253029\n",
            "loss: 0.008754946291446686\n",
            "loss: 0.00875487457960844\n",
            "loss: 0.008754793554544449\n",
            "loss: 0.008754701353609562\n",
            "loss: 0.008754689246416092\n",
            "loss: 0.008754606358706951\n",
            "loss: 0.008754609152674675\n",
            "loss: 0.008754527196288109\n",
            "loss: 0.008754516020417213\n",
            "loss: 0.008754484355449677\n",
            "loss: 0.008754384703934193\n",
            "loss: 0.008754299022257328\n",
            "loss: 0.00875428132712841\n",
            "loss: 0.008754272945225239\n",
            "loss: 0.008754192851483822\n",
            "loss: 0.00875417236238718\n",
            "loss: 0.008754105307161808\n",
            "loss: 0.008754055947065353\n",
            "loss: 0.008754024282097816\n",
            "loss: 0.008753912523388863\n",
            "loss: 0.008753905072808266\n",
            "loss: 0.008753841742873192\n",
            "loss: 0.008753758855164051\n",
            "loss: 0.008753670379519463\n",
            "loss: 0.008753682486712933\n",
            "loss: 0.008753607049584389\n",
            "loss: 0.00875355489552021\n",
            "loss: 0.008753528818488121\n",
            "loss: 0.008753418922424316\n",
            "loss: 0.008753366768360138\n",
            "loss: 0.008753341622650623\n",
            "loss: 0.008753343485295773\n",
            "loss: 0.008753281086683273\n",
            "loss: 0.008753224276006222\n",
            "loss: 0.008753153495490551\n",
            "loss: 0.008753064088523388\n",
            "loss: 0.008753045462071896\n",
            "loss: 0.008753051050007343\n",
            "loss: 0.008753012865781784\n",
            "loss: 0.008752966299653053\n",
            "loss: 0.008752894587814808\n",
            "loss: 0.008752809837460518\n",
            "loss: 0.008752851746976376\n",
            "loss: 0.00875276979058981\n",
            "loss: 0.008752848953008652\n",
            "loss: 0.00875280611217022\n",
            "loss: 0.008752871304750443\n",
            "loss: 0.00875290296971798\n",
            "loss: 0.008752969093620777\n",
            "loss: 0.008753017522394657\n",
            "loss: 0.008752943016588688\n",
            "loss: 0.008752837777137756\n",
            "loss: 0.00875272136181593\n",
            "loss: 0.008752505294978619\n",
            "loss: 0.008752292022109032\n",
            "loss: 0.008752121590077877\n",
            "loss: 0.008752081543207169\n",
            "loss: 0.00875198096036911\n",
            "loss: 0.00875195860862732\n",
            "loss: 0.00875205360352993\n",
            "loss: 0.008752061985433102\n",
            "loss: 0.008751880377531052\n",
            "loss: 0.008751850575208664\n",
            "loss: 0.008751729503273964\n",
            "loss: 0.00875159353017807\n",
            "loss: 0.00875160377472639\n",
            "loss: 0.008751553483307362\n",
            "loss: 0.008751537650823593\n",
            "loss: 0.00875144824385643\n",
            "loss: 0.008751357905566692\n",
            "loss: 0.008751306682825089\n",
            "loss: 0.008751258254051208\n",
            "loss: 0.008751217275857925\n",
            "loss: 0.008751200512051582\n",
            "loss: 0.00875112134963274\n",
            "loss: 0.008751090615987778\n",
            "loss: 0.008751042187213898\n",
            "loss: 0.008750936016440392\n",
            "loss: 0.008750914596021175\n",
            "loss: 0.008750858716666698\n",
            "loss: 0.008750871755182743\n",
            "loss: 0.00875079445540905\n",
            "loss: 0.00875074788928032\n",
            "loss: 0.008750701323151588\n",
            "loss: 0.008750610053539276\n",
            "loss: 0.008750501088798046\n",
            "loss: 0.008750449866056442\n",
            "loss: 0.008750442415475845\n",
            "loss: 0.008750337176024914\n",
            "loss: 0.008750303648412228\n",
            "loss: 0.008750326931476593\n",
            "loss: 0.008750217966735363\n",
            "loss: 0.008750208653509617\n",
            "loss: 0.00875009223818779\n",
            "loss: 0.008750088512897491\n",
            "loss: 0.00875008013099432\n",
            "loss: 0.008749992586672306\n",
            "loss: 0.00874999351799488\n",
            "loss: 0.008749856613576412\n",
            "loss: 0.008749864064157009\n",
            "loss: 0.008749820291996002\n",
            "loss: 0.008749743923544884\n",
            "loss: 0.008749676868319511\n",
            "loss: 0.00874963216483593\n",
            "loss: 0.008749628439545631\n",
            "loss: 0.008749594911932945\n",
            "loss: 0.008749451488256454\n",
            "loss: 0.00874940026551485\n",
            "loss: 0.008749340660870075\n",
            "loss: 0.0087493397295475\n",
            "loss: 0.008749295957386494\n",
            "loss: 0.008749205619096756\n",
            "loss: 0.008749169297516346\n",
            "loss: 0.008749140426516533\n",
            "loss: 0.008749071508646011\n",
            "loss: 0.00874896626919508\n",
            "loss: 0.008748956955969334\n",
            "loss: 0.00874891597777605\n",
            "loss: 0.008748870342969894\n",
            "loss: 0.008748757652938366\n",
            "loss: 0.008748734369874\n",
            "loss: 0.008748698979616165\n",
            "loss: 0.008748674765229225\n",
            "loss: 0.0087486132979393\n",
            "loss: 0.008748533204197884\n",
            "loss: 0.008748535998165607\n",
            "loss: 0.008748463355004787\n",
            "loss: 0.008748416788876057\n",
            "loss: 0.00874832272529602\n",
            "loss: 0.008748253807425499\n",
            "loss: 0.008748256601393223\n",
            "loss: 0.008748169057071209\n",
            "loss: 0.00874816719442606\n",
            "loss: 0.008748128078877926\n",
            "loss: 0.008748023770749569\n",
            "loss: 0.008747970685362816\n",
            "loss: 0.008747975341975689\n",
            "loss: 0.008747811429202557\n",
            "loss: 0.00874782633036375\n",
            "loss: 0.008747776038944721\n",
            "loss: 0.008747726678848267\n",
            "loss: 0.00874764658510685\n",
            "loss: 0.008747642859816551\n",
            "loss: 0.008747548796236515\n",
            "loss: 0.008747531101107597\n",
            "loss: 0.00874747522175312\n",
            "loss: 0.0087474025785923\n",
            "loss: 0.008747348561882973\n",
            "loss: 0.00874733179807663\n",
            "loss: 0.008747335523366928\n",
            "loss: 0.008747279644012451\n",
            "loss: 0.008747204206883907\n",
            "loss: 0.008747244253754616\n",
            "loss: 0.008747151121497154\n",
            "loss: 0.008747133426368237\n",
            "loss: 0.008747084066271782\n",
            "loss: 0.008747057057917118\n",
            "loss: 0.008746993727982044\n",
            "loss: 0.008747044019401073\n",
            "loss: 0.008746967650949955\n",
            "loss: 0.008746981620788574\n",
            "loss: 0.008746934123337269\n",
            "loss: 0.008746856823563576\n",
            "loss: 0.008746733888983727\n",
            "loss: 0.008746619336307049\n",
            "loss: 0.00874652061611414\n",
            "loss: 0.008746424689888954\n",
            "loss: 0.008746360428631306\n",
            "loss: 0.008746329694986343\n",
            "loss: 0.008746255189180374\n",
            "loss: 0.008746324107050896\n",
            "loss: 0.008746298961341381\n",
            "loss: 0.00874616764485836\n",
            "loss: 0.008746132254600525\n",
            "loss: 0.0087460707873106\n",
            "loss: 0.008746007457375526\n",
            "loss: 0.008745909668505192\n",
            "loss: 0.008745896629989147\n",
            "loss: 0.008745798841118813\n",
            "loss: 0.008745848201215267\n",
            "loss: 0.008745732717216015\n",
            "loss: 0.008745654486119747\n",
            "loss: 0.008745602332055569\n",
            "loss: 0.008745618164539337\n",
            "loss: 0.008745502680540085\n",
            "loss: 0.008745405822992325\n",
            "loss: 0.00874539464712143\n",
            "loss: 0.008745287545025349\n",
            "loss: 0.008745298720896244\n",
            "loss: 0.008745243772864342\n",
            "loss: 0.008745214901864529\n",
            "loss: 0.008745100349187851\n",
            "loss: 0.00874507799744606\n",
            "loss: 0.00874502956867218\n",
            "loss: 0.008744987659156322\n",
            "loss: 0.008744913153350353\n",
            "loss: 0.008744926191866398\n",
            "loss: 0.008744818158447742\n",
            "loss: 0.008744783699512482\n",
            "loss: 0.008744764141738415\n",
            "loss: 0.00874466635286808\n",
            "loss: 0.00874466635286808\n",
            "loss: 0.008744582533836365\n",
            "loss: 0.008744495920836926\n",
            "loss: 0.008744421415030956\n",
            "loss: 0.008744386024773121\n",
            "loss: 0.008744336664676666\n",
            "loss: 0.008744300343096256\n",
            "loss: 0.0087442547082901\n",
            "loss: 0.008744198828935623\n",
            "loss: 0.00874415598809719\n",
            "loss: 0.00874411966651678\n",
            "loss: 0.0087440749630332\n",
            "loss: 0.008744033053517342\n",
            "loss: 0.008743938989937305\n",
            "loss: 0.008743899874389172\n",
            "loss: 0.008743842132389545\n",
            "loss: 0.008743754588067532\n",
            "loss: 0.008743725717067719\n",
            "loss: 0.008743721060454845\n",
            "loss: 0.00874365121126175\n",
            "loss: 0.008743572048842907\n",
            "loss: 0.008743488229811192\n",
            "loss: 0.008743489161133766\n",
            "loss: 0.008743480779230595\n",
            "loss: 0.00874342117458582\n",
            "loss: 0.008743328042328358\n",
            "loss: 0.00874326191842556\n",
            "loss: 0.008743206039071083\n",
            "loss: 0.008743220940232277\n",
            "loss: 0.008743121288716793\n",
            "loss: 0.008743059821426868\n",
            "loss: 0.008743034675717354\n",
            "loss: 0.008742994628846645\n",
            "loss: 0.008742889389395714\n",
            "loss: 0.00874288845807314\n",
            "loss: 0.008742863312363625\n",
            "loss: 0.00874278973788023\n",
            "loss: 0.0087427394464612\n",
            "loss: 0.008742721751332283\n",
            "loss: 0.008742688223719597\n",
            "loss: 0.008742617443203926\n",
            "loss: 0.008742661215364933\n",
            "loss: 0.008742690086364746\n",
            "loss: 0.008742636069655418\n",
            "loss: 0.008742760866880417\n",
            "loss: 0.00874288659542799\n",
            "loss: 0.008742895908653736\n",
            "loss: 0.008743000216782093\n",
            "loss: 0.008742893114686012\n",
            "loss: 0.00874268263578415\n",
            "loss: 0.008742469362914562\n",
            "loss: 0.008742276579141617\n",
            "loss: 0.008742065168917179\n",
            "loss: 0.008742030709981918\n",
            "loss: 0.008742028847336769\n",
            "loss: 0.008741973899304867\n",
            "loss: 0.008742026053369045\n",
            "loss: 0.008741822093725204\n",
            "loss: 0.008741826750338078\n",
            "loss: 0.008741717785596848\n",
            "loss: 0.00874170009046793\n",
            "loss: 0.00874163955450058\n",
            "loss: 0.008741525933146477\n",
            "loss: 0.008741434663534164\n",
            "loss: 0.008741420693695545\n",
            "loss: 0.00874133687466383\n",
            "loss: 0.00874129869043827\n",
            "loss: 0.008741285651922226\n",
            "loss: 0.008741205558180809\n",
            "loss: 0.008741048164665699\n",
            "loss: 0.008741090074181557\n",
            "loss: 0.008740946650505066\n",
            "loss: 0.008740927092730999\n",
            "loss: 0.008740941993892193\n",
            "loss: 0.008740872144699097\n",
            "loss: 0.008740827441215515\n",
            "loss: 0.008740727789700031\n",
            "loss: 0.00874065700918436\n",
            "loss: 0.008740672841668129\n",
            "loss: 0.008740539662539959\n",
            "loss: 0.008740558288991451\n",
            "loss: 0.008740474469959736\n",
            "loss: 0.008740445598959923\n",
            "loss: 0.00874033011496067\n",
            "loss: 0.008740345016121864\n",
            "loss: 0.008740334771573544\n",
            "loss: 0.00874028168618679\n",
            "loss: 0.008740196004509926\n",
            "loss: 0.008740166202187538\n",
            "loss: 0.00874010007828474\n",
            "loss: 0.008740068413317204\n",
            "loss: 0.008739972487092018\n",
            "loss: 0.008739964105188847\n",
            "loss: 0.008739926852285862\n",
            "loss: 0.00873985979706049\n",
            "loss: 0.008739793673157692\n",
            "loss: 0.008739707060158253\n",
            "loss: 0.008739661425352097\n",
            "loss: 0.008739626035094261\n",
            "loss: 0.00873956736177206\n",
            "loss: 0.008739530108869076\n",
            "loss: 0.008739549666643143\n",
            "loss: 0.00873944628983736\n",
            "loss: 0.008739392273128033\n",
            "loss: 0.008739273995161057\n",
            "loss: 0.008739248849451542\n",
            "loss: 0.008739225566387177\n",
            "loss: 0.008739192970097065\n",
            "loss: 0.008739108219742775\n",
            "loss: 0.008739096112549305\n",
            "loss: 0.008739020675420761\n",
            "loss: 0.008739020675420761\n",
            "loss: 0.008738902397453785\n",
            "loss: 0.008738819509744644\n",
            "loss: 0.008738853968679905\n",
            "loss: 0.008738765493035316\n",
            "loss: 0.008738755248486996\n",
            "loss: 0.008738690987229347\n",
            "loss: 0.008738625794649124\n",
            "loss: 0.008738559670746326\n",
            "loss: 0.008738480508327484\n",
            "loss: 0.008738490752875805\n",
            "loss: 0.008738414384424686\n",
            "loss: 0.008738351054489613\n",
            "loss: 0.008738248609006405\n",
            "loss: 0.00873826164752245\n",
            "loss: 0.008738220669329166\n",
            "loss: 0.00873817503452301\n",
            "loss: 0.00873811449855566\n",
            "loss: 0.008738086558878422\n",
            "loss: 0.008737992495298386\n",
            "loss: 0.008737933821976185\n",
            "loss: 0.008737879805266857\n",
            "loss: 0.00873786024749279\n",
            "loss: 0.008737836964428425\n",
            "loss: 0.008737828582525253\n",
            "loss: 0.008737742900848389\n",
            "loss: 0.008737669326364994\n",
            "loss: 0.008737637661397457\n",
            "loss: 0.00873755943030119\n",
            "loss: 0.008737449534237385\n",
            "loss: 0.008737443014979362\n",
            "loss: 0.008737423457205296\n",
            "loss: 0.008737328462302685\n",
            "loss: 0.008737275376915932\n",
            "loss: 0.008737259544432163\n",
            "loss: 0.008737181313335896\n",
            "loss: 0.00873714778572321\n",
            "loss: 0.008737149648368359\n",
            "loss: 0.008737086318433285\n",
            "loss: 0.008737006224691868\n",
            "loss: 0.008736938238143921\n",
            "loss: 0.00873688142746687\n",
            "loss: 0.008736789226531982\n",
            "loss: 0.008736777119338512\n",
            "loss: 0.008736757561564445\n",
            "loss: 0.008736683987081051\n",
            "loss: 0.008736643008887768\n",
            "loss: 0.008736579678952694\n",
            "loss: 0.00873653870075941\n",
            "loss: 0.008736465126276016\n",
            "loss: 0.008736430667340755\n",
            "loss: 0.00873633660376072\n",
            "loss: 0.00873632449656725\n",
            "loss: 0.008736275136470795\n",
            "loss: 0.008736226707696915\n",
            "loss: 0.008736193180084229\n",
            "loss: 0.008736127987504005\n",
            "loss: 0.008736060932278633\n",
            "loss: 0.00873598549515009\n",
            "loss: 0.008735964074730873\n",
            "loss: 0.008735861629247665\n",
            "loss: 0.00873585231602192\n",
            "loss: 0.008735841140151024\n",
            "loss: 0.008735778741538525\n",
            "loss: 0.008735655806958675\n",
            "loss: 0.00873564463108778\n",
            "loss: 0.008735566399991512\n",
            "loss: 0.008735548704862595\n",
            "loss: 0.0087354751303792\n",
            "loss: 0.00873548537492752\n",
            "loss: 0.008735474199056625\n",
            "loss: 0.008735346607863903\n",
            "loss: 0.008735370822250843\n",
            "loss: 0.008735288865864277\n",
            "loss: 0.00873521063476801\n",
            "loss: 0.008735180832445621\n",
            "loss: 0.00873520877212286\n",
            "loss: 0.008735109120607376\n",
            "loss: 0.008735070005059242\n",
            "loss: 0.008735023438930511\n",
            "loss: 0.00873500294983387\n",
            "loss: 0.008735074661672115\n",
            "loss: 0.008735100738704205\n",
            "loss: 0.008735189214348793\n",
            "loss: 0.008735239505767822\n",
            "loss: 0.008735346607863903\n",
            "loss: 0.008735341019928455\n",
            "loss: 0.008735285140573978\n",
            "loss: 0.008735046721994877\n",
            "loss: 0.008734771981835365\n",
            "loss: 0.008734540082514286\n",
            "loss: 0.008734364062547684\n",
            "loss: 0.008734354749321938\n",
            "loss: 0.008734399452805519\n",
            "loss: 0.00873443391174078\n",
            "loss: 0.008734422735869884\n",
            "loss: 0.008734303526580334\n",
            "loss: 0.008734154514968395\n",
            "loss: 0.008734003640711308\n",
            "loss: 0.008733981288969517\n",
            "loss: 0.0087339598685503\n",
            "loss: 0.008733829483389854\n",
            "loss: 0.008733902126550674\n",
            "loss: 0.008733806200325489\n",
            "loss: 0.008733765222132206\n",
            "loss: 0.008733673021197319\n",
            "loss: 0.0087336590513587\n",
            "loss: 0.008733585476875305\n",
            "loss: 0.008733533322811127\n",
            "loss: 0.008733394555747509\n",
            "loss: 0.00873337872326374\n",
            "loss: 0.008733358234167099\n",
            "loss: 0.008733388036489487\n",
            "loss: 0.008733279071748257\n",
            "loss: 0.008733208291232586\n",
            "loss: 0.00873316079378128\n",
            "loss: 0.008733092807233334\n",
            "loss: 0.008733026683330536\n",
            "loss: 0.00873299315571785\n",
            "loss: 0.008732953108847141\n",
            "loss: 0.008732863701879978\n",
            "loss: 0.008732803165912628\n",
            "loss: 0.008732739835977554\n",
            "loss: 0.00873273890465498\n",
            "loss: 0.008732662536203861\n",
            "loss: 0.00873266439884901\n",
            "loss: 0.008732584305107594\n",
            "loss: 0.008732521906495094\n",
            "loss: 0.008732462301850319\n",
            "loss: 0.008732486516237259\n",
            "loss: 0.008732346817851067\n",
            "loss: 0.008732309564948082\n",
            "loss: 0.008732314221560955\n",
            "loss: 0.008732233196496964\n",
            "loss: 0.008732147514820099\n",
            "loss: 0.008732123300433159\n",
            "loss: 0.008732038550078869\n",
            "loss: 0.008732015267014503\n",
            "loss: 0.008731994777917862\n",
            "loss: 0.008731917478144169\n",
            "loss: 0.008731847628951073\n",
            "loss: 0.008731805719435215\n",
            "loss: 0.008731755428016186\n",
            "loss: 0.008731736801564693\n",
            "loss: 0.00873168371617794\n",
            "loss: 0.008731617592275143\n",
            "loss: 0.008731592446565628\n",
            "loss: 0.008731551468372345\n",
            "loss: 0.008731503039598465\n",
            "loss: 0.008731469511985779\n",
            "loss: 0.008731385692954063\n",
            "loss: 0.008731324225664139\n",
            "loss: 0.00873127207159996\n",
            "loss: 0.00873126182705164\n",
            "loss: 0.008731198497116566\n",
            "loss: 0.008731165900826454\n",
            "loss: 0.008731076493859291\n",
            "loss: 0.00873102992773056\n",
            "loss: 0.00873097125440836\n",
            "loss: 0.008730930276215076\n",
            "loss: 0.008730815723538399\n",
            "loss: 0.008730833418667316\n",
            "loss: 0.008730826899409294\n",
            "loss: 0.008730738423764706\n",
            "loss: 0.00873067881911993\n",
            "loss: 0.008730580098927021\n",
            "loss: 0.008730567991733551\n",
            "loss: 0.008730482310056686\n",
            "loss: 0.008730494417250156\n",
            "loss: 0.008730350993573666\n",
            "loss: 0.008730362169444561\n",
            "loss: 0.008730319328606129\n",
            "loss: 0.008730307221412659\n",
            "loss: 0.008730213157832623\n",
            "loss: 0.008730118162930012\n",
            "loss: 0.008730067871510983\n",
            "loss: 0.00873003900051117\n",
            "loss: 0.008730029687285423\n",
            "loss: 0.008729933761060238\n",
            "loss: 0.008729905821383\n",
            "loss: 0.008729844354093075\n",
            "loss: 0.008729829452931881\n",
            "loss: 0.008729740977287292\n",
            "loss: 0.008729702793061733\n",
            "loss: 0.008729668334126472\n",
            "loss: 0.008729638531804085\n",
            "loss: 0.00872957706451416\n",
            "loss: 0.008729510009288788\n",
            "loss: 0.008729454129934311\n",
            "loss: 0.008729417808353901\n",
            "loss: 0.008729349821805954\n",
            "loss: 0.008729330264031887\n",
            "loss: 0.008729235269129276\n",
            "loss: 0.008729218505322933\n",
            "loss: 0.00872913096100092\n",
            "loss: 0.008729154244065285\n",
            "loss: 0.00872909463942051\n",
            "loss: 0.008729047141969204\n",
            "loss: 0.008728999644517899\n",
            "loss: 0.008728883229196072\n",
            "loss: 0.008728869259357452\n",
            "loss: 0.008728780783712864\n",
            "loss: 0.008728737011551857\n",
            "loss: 0.008728700689971447\n",
            "loss: 0.008728629909455776\n",
            "loss: 0.008728590793907642\n",
            "loss: 0.008728542365133762\n",
            "loss: 0.00872846320271492\n",
            "loss: 0.008728398941457272\n",
            "loss: 0.00872835610061884\n",
            "loss: 0.008728348650038242\n",
            "loss: 0.00872829370200634\n",
            "loss: 0.008728289045393467\n",
            "loss: 0.008728193119168282\n",
            "loss: 0.008728139102458954\n",
            "loss: 0.008728135377168655\n",
            "loss: 0.008728060871362686\n",
            "loss: 0.008727997541427612\n",
            "loss: 0.008727959357202053\n",
            "loss: 0.008727854117751122\n",
            "loss: 0.00872793048620224\n",
            "loss: 0.008727778680622578\n",
            "loss: 0.008727768436074257\n",
            "loss: 0.008727753534913063\n",
            "loss: 0.0087277265265584\n",
            "loss: 0.00872763805091381\n",
            "loss: 0.008727696724236012\n",
            "loss: 0.008727682754397392\n",
            "loss: 0.00872766226530075\n",
            "loss: 0.008727695792913437\n",
            "loss: 0.008727693930268288\n",
            "loss: 0.008727607317268848\n",
            "loss: 0.00872761383652687\n",
            "loss: 0.008727630600333214\n",
            "loss: 0.00872748252004385\n",
            "loss: 0.008727298118174076\n",
            "loss: 0.008727261796593666\n",
            "loss: 0.00872710719704628\n",
            "loss: 0.008726993575692177\n",
            "loss: 0.00872700847685337\n",
            "loss: 0.008726831525564194\n",
            "loss: 0.008726829662919044\n",
            "loss: 0.008726797066628933\n",
            "loss: 0.00872674211859703\n",
            "loss: 0.008726660162210464\n",
            "loss: 0.008726599626243114\n",
            "loss: 0.008726583793759346\n",
            "loss: 0.008726506493985653\n",
            "loss: 0.008726468309760094\n",
            "loss: 0.008726420812308788\n",
            "loss: 0.008726345375180244\n",
            "loss: 0.008726281113922596\n",
            "loss: 0.008726268075406551\n",
            "loss: 0.008726141415536404\n",
            "loss: 0.008726155385375023\n",
            "loss: 0.00872607622295618\n",
            "loss: 0.008726068772375584\n",
            "loss: 0.008726018480956554\n",
            "loss: 0.00872589647769928\n",
            "loss: 0.008725869469344616\n",
            "loss: 0.008725804276764393\n",
            "loss: 0.008725767955183983\n",
            "loss: 0.008725776337087154\n",
            "loss: 0.00872570276260376\n",
            "loss: 0.008725634776055813\n",
            "loss: 0.008725631050765514\n",
            "loss: 0.008725560270249844\n",
            "loss: 0.008725430816411972\n",
            "loss: 0.00872538611292839\n",
            "loss: 0.008725360035896301\n",
            "loss: 0.008725372143089771\n",
            "loss: 0.008725253865122795\n",
            "loss: 0.008725231513381004\n",
            "loss: 0.008725197054445744\n",
            "loss: 0.008725148625671864\n",
            "loss: 0.008725046180188656\n",
            "loss: 0.00872502289712429\n",
            "loss: 0.008724987506866455\n",
            "loss: 0.008724887855350971\n",
            "loss: 0.008724857121706009\n",
            "loss: 0.00872483104467392\n",
            "loss: 0.008724803104996681\n",
            "loss: 0.008724735118448734\n",
            "loss: 0.008724656887352467\n",
            "loss: 0.00872462335973978\n",
            "loss: 0.008724551647901535\n",
            "loss: 0.008724534884095192\n",
            "loss: 0.008724450133740902\n",
            "loss: 0.008724382147192955\n",
            "loss: 0.008724356070160866\n",
            "loss: 0.008724302053451538\n",
            "loss: 0.008724246174097061\n",
            "loss: 0.008724257349967957\n",
            "loss: 0.008724190294742584\n",
            "loss: 0.008724120445549488\n",
            "loss: 0.008724084123969078\n",
            "loss: 0.008724016137421131\n",
            "loss: 0.008723972365260124\n",
            "loss: 0.008723949082195759\n",
            "loss: 0.00872386060655117\n",
            "loss: 0.008723805658519268\n",
            "loss: 0.008723785169422626\n",
            "loss: 0.00872368086129427\n",
            "loss: 0.00872365664690733\n",
            "loss: 0.008723616600036621\n",
            "loss: 0.008723491802811623\n",
            "loss: 0.008723544888198376\n",
            "loss: 0.008723470382392406\n",
            "loss: 0.008723453618586063\n",
            "loss: 0.00872338842600584\n",
            "loss: 0.008723289705812931\n",
            "loss: 0.008723247796297073\n",
            "loss: 0.008723219856619835\n",
            "loss: 0.008723161183297634\n",
            "loss: 0.008723072707653046\n",
            "loss: 0.008723102509975433\n",
            "loss: 0.008723034523427486\n",
            "loss: 0.008722889237105846\n",
            "loss: 0.008722948841750622\n",
            "loss: 0.008722773753106594\n",
            "loss: 0.008722778409719467\n",
            "loss: 0.008722717873752117\n",
            "loss: 0.008722702041268349\n",
            "loss: 0.008722714148461819\n",
            "loss: 0.008722632192075253\n",
            "loss: 0.008722576312720776\n",
            "loss: 0.008722487837076187\n",
            "loss: 0.008722425438463688\n",
            "loss: 0.008722417056560516\n",
            "loss: 0.008722430095076561\n",
            "loss: 0.008722344413399696\n",
            "loss: 0.008722342550754547\n",
            "loss: 0.008722317405045033\n",
            "loss: 0.008722173981368542\n",
            "loss: 0.008722224272787571\n",
            "loss: 0.008722180500626564\n",
            "loss: 0.008722217753529549\n",
            "loss: 0.00872217956930399\n",
            "loss: 0.008722147904336452\n",
            "loss: 0.008722085505723953\n",
            "loss: 0.008722036145627499\n",
            "loss: 0.00872200820595026\n",
            "loss: 0.008721977472305298\n",
            "loss: 0.008721803314983845\n",
            "loss: 0.00872179213911295\n",
            "loss: 0.008721633814275265\n",
            "loss: 0.008721536956727505\n",
            "loss: 0.008721531368792057\n",
            "loss: 0.008721360936760902\n",
            "loss: 0.008721348829567432\n",
            "loss: 0.008721244521439075\n",
            "loss: 0.008721244521439075\n",
            "loss: 0.008721244521439075\n",
            "loss: 0.008721218444406986\n",
            "loss: 0.00872115045785904\n",
            "loss: 0.008721095509827137\n",
            "loss: 0.008721102960407734\n",
            "loss: 0.00872098933905363\n",
            "loss: 0.008720878511667252\n",
            "loss: 0.008720838464796543\n",
            "loss: 0.00872069876641035\n",
            "loss: 0.008720736019313335\n",
            "loss: 0.008720685727894306\n",
            "loss: 0.00872061401605606\n",
            "loss: 0.008720610290765762\n",
            "loss: 0.008720514364540577\n",
            "loss: 0.008720479905605316\n",
            "loss: 0.008720451965928078\n",
            "loss: 0.008720401674509048\n",
            "loss: 0.00872034952044487\n",
            "loss: 0.008720321580767632\n",
            "loss: 0.008720221929252148\n",
            "loss: 0.008720154874026775\n",
            "loss: 0.00872013159096241\n",
            "loss: 0.008720088750123978\n",
            "loss: 0.00872006081044674\n",
            "loss: 0.008719947189092636\n",
            "loss: 0.008719905279576778\n",
            "loss: 0.008719914592802525\n",
            "loss: 0.008719796314835548\n",
            "loss: 0.008719757199287415\n",
            "loss: 0.00871975626796484\n",
            "loss: 0.00871964544057846\n",
            "loss: 0.00871967151761055\n",
            "loss: 0.008719537407159805\n",
            "loss: 0.008719502948224545\n",
            "loss: 0.008719475008547306\n",
            "loss: 0.008719402365386486\n",
            "loss: 0.008719377219676971\n",
            "loss: 0.008719287812709808\n",
            "loss: 0.008719329722225666\n",
            "loss: 0.008719214238226414\n",
            "loss: 0.008719132281839848\n",
            "loss: 0.008719176985323429\n",
            "loss: 0.008719053119421005\n",
            "loss: 0.008719038218259811\n",
            "loss: 0.00871898140758276\n",
            "loss: 0.008718859404325485\n",
            "loss: 0.008718829602003098\n",
            "loss: 0.008718864060938358\n",
            "loss: 0.008718783967196941\n",
            "loss: 0.008718715980648994\n",
            "loss: 0.008718661963939667\n",
            "loss: 0.008718624711036682\n",
            "loss: 0.008718583732843399\n",
            "loss: 0.008718541823327541\n",
            "loss: 0.008718477562069893\n",
            "loss: 0.008718465454876423\n",
            "loss: 0.008718417026102543\n",
            "loss: 0.008718285709619522\n",
            "loss: 0.008718231692910194\n",
            "loss: 0.008718214929103851\n",
            "loss: 0.008718159049749374\n",
            "loss: 0.008718112483620644\n",
            "loss: 0.008718034252524376\n",
            "loss: 0.008718017488718033\n",
            "loss: 0.008717968128621578\n",
            "loss: 0.00871789176017046\n",
            "loss: 0.00871785543859005\n",
            "loss: 0.008717771619558334\n",
            "loss: 0.008717769756913185\n",
            "loss: 0.008717766031622887\n",
            "loss: 0.008717702701687813\n",
            "loss: 0.008717657066881657\n",
            "loss: 0.00871767196804285\n",
            "loss: 0.008717609569430351\n",
            "loss: 0.008717567659914494\n",
            "loss: 0.008717493154108524\n",
            "loss: 0.008717488497495651\n",
            "loss: 0.008717481046915054\n",
            "loss: 0.0087174316868186\n",
            "loss: 0.008717433549463749\n",
            "loss: 0.008717432618141174\n",
            "loss: 0.008717402815818787\n",
            "loss: 0.008717327378690243\n",
            "loss: 0.008717291057109833\n",
            "loss: 0.008717294782400131\n",
            "loss: 0.008717241697013378\n",
            "loss: 0.008717166259884834\n",
            "loss: 0.008717230521142483\n",
            "loss: 0.008717084303498268\n",
            "loss: 0.008717055432498455\n",
            "loss: 0.0087168263271451\n",
            "loss: 0.008716676384210587\n",
            "loss: 0.008716536685824394\n",
            "loss: 0.008716538548469543\n",
            "loss: 0.008716446347534657\n",
            "loss: 0.008716463111341\n",
            "loss: 0.008716483600437641\n",
            "loss: 0.008716409094631672\n",
            "loss: 0.008716307580471039\n",
            "loss: 0.008716249838471413\n",
            "loss: 0.008716185577213764\n",
            "loss: 0.008716094307601452\n",
            "loss: 0.008716091513633728\n",
            "loss: 0.008716076612472534\n",
            "loss: 0.008716026321053505\n",
            "loss: 0.008715958334505558\n",
            "loss: 0.008715859614312649\n",
            "loss: 0.008715796284377575\n",
            "loss: 0.008715726435184479\n",
            "loss: 0.008715743198990822\n",
            "loss: 0.008715707808732986\n",
            "loss: 0.008715616539120674\n",
            "loss: 0.00871556531637907\n",
            "loss: 0.008715486153960228\n",
            "loss: 0.008715426549315453\n",
            "loss: 0.008715392090380192\n",
            "loss: 0.008715353906154633\n",
            "loss: 0.008715342730283737\n",
            "loss: 0.008715249598026276\n",
            "loss: 0.00871521607041359\n",
            "loss: 0.008715201169252396\n",
            "loss: 0.008715086616575718\n",
            "loss: 0.00871505867689848\n",
            "loss: 0.008715009316802025\n",
            "loss: 0.008714941330254078\n",
            "loss: 0.0087149478495121\n",
            "loss: 0.008714849129319191\n",
            "loss: 0.008714809082448483\n",
            "loss: 0.008714837022125721\n",
            "loss: 0.00871468335390091\n",
            "loss: 0.008714711293578148\n",
            "loss: 0.008714604191482067\n",
            "loss: 0.008714589290320873\n",
            "loss: 0.008714502677321434\n",
            "loss: 0.008714476600289345\n",
            "loss: 0.008714410476386547\n",
            "loss: 0.00871437881141901\n",
            "loss: 0.008714322000741959\n",
            "loss: 0.008714240975677967\n",
            "loss: 0.008714214898645878\n",
            "loss: 0.008714109659194946\n",
            "loss: 0.008714078925549984\n",
            "loss: 0.008714046329259872\n",
            "loss: 0.008714010939002037\n",
            "loss: 0.008714009076356888\n",
            "loss: 0.008713931776583195\n",
            "loss: 0.008713863790035248\n",
            "loss: 0.008713818155229092\n",
            "loss: 0.008713783696293831\n",
            "loss: 0.008713727816939354\n",
            "loss: 0.008713660761713982\n",
            "loss: 0.00871361419558525\n",
            "loss: 0.008713584393262863\n",
            "loss: 0.008713495917618275\n",
            "loss: 0.008713429793715477\n",
            "loss: 0.008713346906006336\n",
            "loss: 0.008713314309716225\n",
            "loss: 0.008713304996490479\n",
            "loss: 0.008713320828974247\n",
            "loss: 0.008713181130588055\n",
            "loss: 0.008713127113878727\n",
            "loss: 0.008713090792298317\n",
            "loss: 0.00871303305029869\n",
            "loss: 0.008713025599718094\n",
            "loss: 0.008713007904589176\n",
            "loss: 0.008712893351912498\n",
            "loss: 0.008712884970009327\n",
            "loss: 0.008712849579751492\n",
            "loss: 0.008712765760719776\n",
            "loss: 0.00871274247765541\n",
            "loss: 0.008712748065590858\n",
            "loss: 0.008712676353752613\n",
            "loss: 0.008712624199688435\n",
            "loss: 0.0087125888094306\n",
            "loss: 0.008712684735655785\n",
            "loss: 0.008712681010365486\n",
            "loss: 0.008712636306881905\n",
            "loss: 0.008712583221495152\n",
            "loss: 0.008712626993656158\n",
            "loss: 0.00871253665536642\n",
            "loss: 0.008712478913366795\n",
            "loss: 0.008712355978786945\n",
            "loss: 0.00871232058852911\n",
            "loss: 0.008712153881788254\n",
            "loss: 0.008712022565305233\n",
            "loss: 0.008711929433047771\n",
            "loss: 0.008711853995919228\n",
            "loss: 0.008711837232112885\n",
            "loss: 0.008711754344403744\n",
            "loss: 0.008711718022823334\n",
            "loss: 0.008711692877113819\n",
            "loss: 0.008711691945791245\n",
            "loss: 0.008711647242307663\n",
            "loss: 0.00871154386550188\n",
            "loss: 0.008711482398211956\n",
            "loss: 0.008711370639503002\n",
            "loss: 0.008711348287761211\n",
            "loss: 0.008711302652955055\n",
            "loss: 0.008711262606084347\n",
            "loss: 0.008711189031600952\n",
            "loss: 0.008711171336472034\n",
            "loss: 0.008711183443665504\n",
            "loss: 0.008711092174053192\n",
            "loss: 0.008711030706763268\n",
            "loss: 0.008710939437150955\n",
            "loss: 0.008710930123925209\n",
            "loss: 0.008710832335054874\n",
            "loss: 0.008710838854312897\n",
            "loss: 0.008710741996765137\n",
            "loss: 0.008710716851055622\n",
            "loss: 0.008710628375411034\n",
            "loss: 0.008710630238056183\n",
            "loss: 0.00871058739721775\n",
            "loss: 0.008710507303476334\n",
            "loss: 0.008710460737347603\n",
            "loss: 0.008710421621799469\n",
            "loss: 0.0087103471159935\n",
            "loss: 0.008710329420864582\n",
            "loss: 0.008710348978638649\n",
            "loss: 0.008710232563316822\n",
            "loss: 0.008710170164704323\n",
            "loss: 0.00871006865054369\n",
            "loss: 0.008710128255188465\n",
            "loss: 0.008709989488124847\n",
            "loss: 0.008709982968866825\n",
            "loss: 0.008709863759577274\n",
            "loss: 0.008709806017577648\n",
            "loss: 0.008709822781383991\n",
            "loss: 0.008709671907126904\n",
            "loss: 0.00870969146490097\n",
            "loss: 0.008709708228707314\n",
            "loss: 0.008709603920578957\n",
            "loss: 0.008709642104804516\n",
            "loss: 0.008709538727998734\n",
            "loss: 0.00870942696928978\n",
            "loss: 0.008709393441677094\n",
            "loss: 0.008709345012903214\n",
            "loss: 0.008709329180419445\n",
            "loss: 0.008709321729838848\n",
            "loss: 0.008709208108484745\n",
            "loss: 0.00870920717716217\n",
            "loss: 0.008709157817065716\n",
            "loss: 0.008709103800356388\n",
            "loss: 0.008709043264389038\n",
            "loss: 0.008708926849067211\n",
            "loss: 0.008708905428647995\n",
            "loss: 0.008708840236067772\n",
            "loss: 0.008708848617970943\n",
            "loss: 0.008708780631422997\n",
            "loss: 0.008708682842552662\n",
            "loss: 0.008708647452294827\n",
            "loss: 0.008708599954843521\n",
            "loss: 0.008708598092198372\n",
            "loss: 0.008708486333489418\n",
            "loss: 0.008708453737199306\n",
            "loss: 0.008708421140909195\n",
            "loss: 0.008708318695425987\n",
            "loss: 0.008708328008651733\n",
            "loss: 0.008708282373845577\n",
            "loss: 0.008708230219781399\n",
            "loss: 0.008708165027201176\n",
            "loss: 0.008708128705620766\n",
            "loss: 0.008708063513040543\n",
            "loss: 0.008708007633686066\n",
            "loss: 0.008707957342267036\n",
            "loss: 0.00870796013623476\n",
            "loss: 0.008707918226718903\n",
            "loss: 0.008707898668944836\n",
            "loss: 0.008707845583558083\n",
            "loss: 0.008707823231816292\n",
            "loss: 0.008707758039236069\n",
            "loss: 0.00870775617659092\n",
            "loss: 0.008707729168236256\n",
            "loss: 0.008707713335752487\n",
            "loss: 0.008707650005817413\n",
            "loss: 0.008707724511623383\n",
            "loss: 0.008707623928785324\n",
            "loss: 0.008707570843398571\n",
            "loss: 0.008707539178431034\n",
            "loss: 0.008707479573786259\n",
            "loss: 0.008707360364496708\n",
            "loss: 0.008707273751497269\n",
            "loss: 0.008707163855433464\n",
            "loss: 0.008707038126885891\n",
            "loss: 0.008707009255886078\n",
            "loss: 0.008706859312951565\n",
            "loss: 0.008706886321306229\n",
            "loss: 0.008706828579306602\n",
            "loss: 0.008706827647984028\n",
            "loss: 0.008706760592758656\n",
            "loss: 0.00870670285075903\n",
            "loss: 0.008706638589501381\n",
            "loss: 0.008706638589501381\n",
            "loss: 0.008706506341695786\n",
            "loss: 0.008706490509212017\n",
            "loss: 0.00870642252266407\n",
            "loss: 0.008706405758857727\n",
            "loss: 0.008706224150955677\n",
            "loss: 0.008706276305019855\n",
            "loss: 0.008706219494342804\n",
            "loss: 0.008706126362085342\n",
            "loss: 0.008706075139343739\n",
            "loss: 0.00870604533702135\n",
            "loss: 0.00870602484792471\n",
            "loss: 0.00870597641915083\n",
            "loss: 0.008705899119377136\n",
            "loss: 0.008705838583409786\n",
            "loss: 0.008705777116119862\n",
            "loss: 0.008705761283636093\n",
            "loss: 0.00870572030544281\n",
            "loss: 0.008705632761120796\n",
            "loss: 0.008705582469701767\n",
            "loss: 0.00870554894208908\n",
            "loss: 0.008705511689186096\n",
            "loss: 0.008705454878509045\n",
            "loss: 0.00870535708963871\n",
            "loss: 0.00870535708963871\n",
            "loss: 0.008705329149961472\n",
            "loss: 0.008705251850187778\n",
            "loss: 0.008705202490091324\n",
            "loss: 0.008705181069672108\n",
            "loss: 0.008705046959221363\n",
            "loss: 0.008705057203769684\n",
            "loss: 0.00870499573647976\n",
            "loss: 0.008704918436706066\n",
            "loss: 0.008704929612576962\n",
            "loss: 0.008704871870577335\n",
            "loss: 0.008704818785190582\n",
            "loss: 0.008704807609319687\n",
            "loss: 0.008704678155481815\n",
            "loss: 0.008704663254320621\n",
            "loss: 0.008704631589353085\n",
            "loss: 0.008704578503966331\n",
            "loss: 0.008704516105353832\n",
            "loss: 0.008704460225999355\n",
            "loss: 0.008704409934580326\n",
            "loss: 0.008704397827386856\n",
            "loss: 0.008704330772161484\n",
            "loss: 0.008704280480742455\n",
            "loss: 0.008704210631549358\n",
            "loss: 0.008704240433871746\n",
            "loss: 0.008704151026904583\n",
            "loss: 0.008704150095582008\n",
            "loss: 0.008704042993485928\n",
            "loss: 0.0087039889767766\n",
            "loss: 0.008703932166099548\n",
            "loss: 0.008703863248229027\n",
            "loss: 0.008703852072358131\n",
            "loss: 0.008703786879777908\n",
            "loss: 0.008703775703907013\n",
            "loss: 0.008703743107616901\n",
            "loss: 0.008703695610165596\n",
            "loss: 0.008703628554940224\n",
            "loss: 0.008703567087650299\n",
            "loss: 0.008703532628715038\n",
            "loss: 0.008703459054231644\n",
            "loss: 0.008703391999006271\n",
            "loss: 0.008703315630555153\n",
            "loss: 0.00870322622358799\n",
            "loss: 0.008703235536813736\n",
            "loss: 0.008703134953975677\n",
            "loss: 0.008703130297362804\n",
            "loss: 0.008703045547008514\n",
            "loss: 0.008703045547008514\n",
            "loss: 0.008702979423105717\n",
            "loss: 0.008702924475073814\n",
            "loss: 0.008702936582267284\n",
            "loss: 0.008702868595719337\n",
            "loss: 0.008702794089913368\n",
            "loss: 0.008702767081558704\n",
            "loss: 0.008702775463461876\n",
            "loss: 0.00870275404304266\n",
            "loss: 0.008702664636075497\n",
            "loss: 0.008702614344656467\n",
            "loss: 0.008702609688043594\n",
            "loss: 0.008702605962753296\n",
            "loss: 0.008702659979462624\n",
            "loss: 0.008702567778527737\n",
            "loss: 0.008702617138624191\n",
            "loss: 0.008702579885721207\n",
            "loss: 0.008702533319592476\n",
            "loss: 0.008702537976205349\n",
            "loss: 0.008702483028173447\n",
            "loss: 0.008702391758561134\n",
            "loss: 0.008702208288013935\n",
            "loss: 0.008702069520950317\n",
            "loss: 0.008701898157596588\n",
            "loss: 0.008701867423951626\n",
            "loss: 0.008701822720468044\n",
            "loss: 0.008701808750629425\n",
            "loss: 0.0087017472833395\n",
            "loss: 0.008701798506081104\n",
            "loss: 0.00870173517614603\n",
            "loss: 0.008701618760824203\n",
            "loss: 0.008701544255018234\n",
            "loss: 0.00870145857334137\n",
            "loss: 0.00870140828192234\n",
            "loss: 0.008701306767761707\n",
            "loss: 0.008701291866600513\n",
            "loss: 0.008701271377503872\n",
            "loss: 0.0087012043222785\n",
            "loss: 0.008701170794665813\n",
            "loss: 0.008701113052666187\n",
            "loss: 0.008701104670763016\n",
            "loss: 0.008701106533408165\n",
            "loss: 0.0087009621784091\n",
            "loss: 0.008700924925506115\n",
            "loss: 0.008700850419700146\n",
            "loss: 0.008700822480022907\n",
            "loss: 0.008700735867023468\n",
            "loss: 0.008700706996023655\n",
            "loss: 0.008700618520379066\n",
            "loss: 0.008700587786734104\n",
            "loss: 0.008700590580701828\n",
            "loss: 0.008700544014573097\n",
            "loss: 0.00870046578347683\n",
            "loss: 0.008700450882315636\n",
            "loss: 0.008700357750058174\n",
            "loss: 0.008700283244252205\n",
            "loss: 0.00870030838996172\n",
            "loss: 0.008700179867446423\n",
            "loss: 0.00870015099644661\n",
            "loss: 0.008700156584382057\n",
            "loss: 0.008700046688318253\n",
            "loss: 0.008699950762093067\n",
            "loss: 0.008699902333319187\n",
            "loss: 0.008699852041900158\n",
            "loss: 0.008699845522642136\n",
            "loss: 0.00869978778064251\n",
            "loss: 0.008699733763933182\n",
            "loss: 0.008699626661837101\n",
            "loss: 0.00869964249432087\n",
            "loss: 0.00869954563677311\n",
            "loss: 0.008699537254869938\n",
            "loss: 0.008699484169483185\n",
            "loss: 0.008699462749063969\n",
            "loss: 0.008699366822838783\n",
            "loss: 0.00869937613606453\n",
            "loss: 0.008699305355548859\n",
            "loss: 0.008699295111000538\n",
            "loss: 0.008699151687324047\n",
            "loss: 0.008699154481291771\n",
            "loss: 0.008699080906808376\n",
            "loss: 0.00869905948638916\n",
            "loss: 0.00869897473603487\n",
            "loss: 0.008698951452970505\n",
            "loss: 0.008698878809809685\n",
            "loss: 0.008698866702616215\n",
            "loss: 0.008698802441358566\n",
            "loss: 0.008698755875229836\n",
            "loss: 0.008698700927197933\n",
            "loss: 0.008698655292391777\n",
            "loss: 0.00869857706129551\n",
            "loss: 0.008698546327650547\n",
            "loss: 0.008698569610714912\n",
            "loss: 0.008698520250618458\n",
            "loss: 0.00869839545339346\n",
            "loss: 0.008698321878910065\n",
            "loss: 0.008698327466845512\n",
            "loss: 0.008698317222297192\n",
            "loss: 0.008698237128555775\n",
            "loss: 0.008698146790266037\n",
            "loss: 0.008698108606040478\n",
            "loss: 0.00869801826775074\n",
            "loss: 0.008697986602783203\n",
            "loss: 0.008698037825524807\n",
            "loss: 0.008697924204170704\n",
            "loss: 0.00869783852249384\n",
            "loss: 0.00869781244546175\n",
            "loss: 0.008697793819010258\n",
            "loss: 0.008697748184204102\n",
            "loss: 0.008697669953107834\n",
            "loss: 0.00869768112897873\n",
            "loss: 0.008697601035237312\n",
            "loss: 0.008697517216205597\n",
            "loss: 0.008697536773979664\n",
            "loss: 0.00869743525981903\n",
            "loss: 0.00869735423475504\n",
            "loss: 0.00869741104543209\n",
            "loss: 0.00869735423475504\n",
            "loss: 0.008697311393916607\n",
            "loss: 0.008697343990206718\n",
            "loss: 0.00869732815772295\n",
            "loss: 0.008697261102497578\n",
            "loss: 0.008697334676980972\n",
            "loss: 0.008697319775819778\n",
            "loss: 0.008697377517819405\n",
            "loss: 0.008697384968400002\n",
            "loss: 0.008697227574884892\n",
            "loss: 0.008697143755853176\n",
            "loss: 0.008696947246789932\n",
            "loss: 0.00869678147137165\n",
            "loss: 0.00869668461382389\n",
            "loss: 0.00869665015488863\n",
            "loss: 0.008696643635630608\n",
            "loss: 0.008696619421243668\n",
            "loss: 0.008696470409631729\n",
            "loss: 0.008696440607309341\n",
            "loss: 0.008696356788277626\n",
            "loss: 0.008696330711245537\n",
            "loss: 0.008696280419826508\n",
            "loss: 0.008696266449987888\n",
            "loss: 0.008696199394762516\n",
            "loss: 0.00869613979011774\n",
            "loss: 0.008696084842085838\n",
            "loss: 0.00869600661098957\n",
            "loss: 0.008695934899151325\n",
            "loss: 0.008695889264345169\n",
            "loss: 0.008695833384990692\n",
            "loss: 0.00869586132466793\n",
            "loss: 0.008695792406797409\n",
            "loss: 0.008695730939507484\n",
            "loss: 0.008695644326508045\n",
            "loss: 0.008695565164089203\n",
            "loss: 0.008695499040186405\n",
            "loss: 0.008695474825799465\n",
            "loss: 0.008695422671735287\n",
            "loss: 0.008695424534380436\n",
            "loss: 0.00869540311396122\n",
            "loss: 0.008695296011865139\n",
            "loss: 0.008695212192833424\n",
            "loss: 0.00869519542902708\n",
            "loss: 0.008695156313478947\n",
            "loss: 0.008695133961737156\n",
            "loss: 0.008695043623447418\n",
            "loss: 0.008694984018802643\n",
            "loss: 0.0086949672549963\n",
            "loss: 0.008694956079125404\n",
            "loss: 0.008694848045706749\n",
            "loss: 0.008694791235029697\n",
            "loss: 0.00869470089673996\n",
            "loss: 0.008694712072610855\n",
            "loss: 0.008694627322256565\n",
            "loss: 0.008694583550095558\n",
            "loss: 0.008694547228515148\n",
            "loss: 0.008694500662386417\n",
            "loss: 0.008694437332451344\n",
            "loss: 0.008694460615515709\n",
            "loss: 0.008694369345903397\n",
            "loss: 0.008694283664226532\n",
            "loss: 0.008694259449839592\n",
            "loss: 0.008694249205291271\n",
            "loss: 0.008694106712937355\n",
            "loss: 0.008694126270711422\n",
            "loss: 0.00869402289390564\n",
            "loss: 0.008694002404808998\n",
            "loss: 0.008693963289260864\n",
            "loss: 0.008693942800164223\n",
            "loss: 0.008693885989487171\n",
            "loss: 0.008693805895745754\n",
            "loss: 0.008693752810359001\n",
            "loss: 0.00869369599968195\n",
            "loss: 0.0086936354637146\n",
            "loss: 0.008693638257682323\n",
            "loss: 0.00869356282055378\n",
            "loss: 0.008693549782037735\n",
            "loss: 0.008693472482264042\n",
            "loss: 0.008693431504070759\n",
            "loss: 0.00869341567158699\n",
            "loss: 0.008693325333297253\n",
            "loss: 0.008693262934684753\n",
            "loss: 0.008693276904523373\n",
            "loss: 0.008693157695233822\n",
            "loss: 0.00869312509894371\n",
            "loss: 0.008693031966686249\n",
            "loss: 0.008692997507750988\n",
            "loss: 0.008692961186170578\n",
            "loss: 0.008692835457623005\n",
            "loss: 0.008692853152751923\n",
            "loss: 0.008692818693816662\n",
            "loss: 0.008692757226526737\n",
            "loss: 0.008692790754139423\n",
            "loss: 0.008692656643688679\n",
            "loss: 0.00869263056665659\n",
            "loss: 0.008692636154592037\n",
            "loss: 0.008692494593560696\n",
            "loss: 0.008692461997270584\n",
            "loss: 0.008692439645528793\n",
            "loss: 0.00869236420840025\n",
            "loss: 0.008692278526723385\n",
            "loss: 0.00869223102927208\n",
            "loss: 0.008692245930433273\n",
            "loss: 0.008692172355949879\n",
            "loss: 0.008692154660820961\n",
            "loss: 0.008692119270563126\n",
            "loss: 0.008692050352692604\n",
            "loss: 0.008692080155014992\n",
            "loss: 0.008692093193531036\n",
            "loss: 0.008692100644111633\n",
            "loss: 0.008692118339240551\n",
            "loss: 0.008692163974046707\n",
            "loss: 0.00869226735085249\n",
            "loss: 0.008692273870110512\n",
            "loss: 0.008692244067788124\n",
            "loss: 0.008692165836691856\n",
            "loss: 0.008691994473338127\n",
            "loss: 0.008691770024597645\n",
            "loss: 0.008691590279340744\n",
            "loss: 0.008691418915987015\n",
            "loss: 0.008691392838954926\n",
            "loss: 0.008691362105309963\n",
            "loss: 0.008691404014825821\n",
            "loss: 0.008691389113664627\n",
            "loss: 0.008691389113664627\n",
            "loss: 0.008691276423633099\n",
            "loss: 0.008691102266311646\n",
            "loss: 0.008691028691828251\n",
            "loss: 0.008690984919667244\n",
            "loss: 0.008690908551216125\n",
            "loss: 0.00869089737534523\n",
            "loss: 0.008690859191119671\n",
            "loss: 0.008690886199474335\n",
            "loss: 0.008690734393894672\n",
            "loss: 0.008690747432410717\n",
            "loss: 0.008690591901540756\n",
            "loss: 0.00869056861847639\n",
            "loss: 0.008690488524734974\n",
            "loss: 0.008690434508025646\n",
            "loss: 0.008690391667187214\n",
            "loss: 0.008690429851412773\n",
            "loss: 0.008690296672284603\n",
            "loss: 0.008690277114510536\n",
            "loss: 0.008690236136317253\n",
            "loss: 0.008690161630511284\n",
            "loss: 0.00869017094373703\n",
            "loss: 0.008690062910318375\n",
            "loss: 0.00869004987180233\n",
            "loss: 0.00868997909128666\n",
            "loss: 0.00868991855531931\n",
            "loss: 0.008689891546964645\n",
            "loss: 0.008689798414707184\n",
            "loss: 0.00868971273303032\n",
            "loss: 0.008689717389643192\n",
            "loss: 0.008689719252288342\n",
            "loss: 0.008689633570611477\n",
            "loss: 0.008689577691257\n",
            "loss: 0.00868952926248312\n",
            "loss: 0.00868947897106409\n",
            "loss: 0.008689445443451405\n",
            "loss: 0.00868934765458107\n",
            "loss: 0.00868932157754898\n",
            "loss: 0.008689298294484615\n",
            "loss: 0.00868920050561428\n",
            "loss: 0.00868916790932417\n",
            "loss: 0.008689151145517826\n",
            "loss: 0.008689028210937977\n",
            "loss: 0.008689023554325104\n",
            "loss: 0.008689005859196186\n",
            "loss: 0.008688912726938725\n",
            "loss: 0.008688912726938725\n",
            "loss: 0.008688821457326412\n",
            "loss: 0.00868877861648798\n",
            "loss: 0.008688800036907196\n",
            "loss: 0.008688705042004585\n",
            "loss: 0.008688653819262981\n",
            "loss: 0.00868864543735981\n",
            "loss: 0.008688580244779587\n",
            "loss: 0.008688509464263916\n",
            "loss: 0.008688418194651604\n",
            "loss: 0.008688338100910187\n",
            "loss: 0.008688307367265224\n",
            "loss: 0.008688278496265411\n",
            "loss: 0.008688193745911121\n",
            "loss: 0.008688191883265972\n",
            "loss: 0.00868814717978239\n",
            "loss: 0.008688097819685936\n",
            "loss: 0.008688083849847317\n",
            "loss: 0.008687995374202728\n",
            "loss: 0.008687908761203289\n",
            "loss: 0.008687891066074371\n",
            "loss: 0.008687898516654968\n",
            "loss: 0.008687740191817284\n",
            "loss: 0.008687728084623814\n",
            "loss: 0.008687674067914486\n",
            "loss: 0.0086876405403018\n",
            "loss: 0.008687619119882584\n",
            "loss: 0.008687545545399189\n",
            "loss: 0.008687485940754414\n",
            "loss: 0.0086874570697546\n",
            "loss: 0.008687395602464676\n",
            "loss: 0.008687318302690983\n",
            "loss: 0.008687320165336132\n",
            "loss: 0.008687270805239677\n",
            "loss: 0.008687219582498074\n",
            "loss: 0.008687184192240238\n",
            "loss: 0.008687146939337254\n",
            "loss: 0.008687100373208523\n",
            "loss: 0.008687010034918785\n",
            "loss: 0.00868691224604845\n",
            "loss: 0.00868690200150013\n",
            "loss: 0.008686847984790802\n",
            "loss: 0.008686844259500504\n",
            "loss: 0.008686753921210766\n",
            "loss: 0.008686745539307594\n",
            "loss: 0.008686664514243603\n",
            "loss: 0.00868659745901823\n",
            "loss: 0.008686582557857037\n",
            "loss: 0.008686523884534836\n",
            "loss: 0.008686470799148083\n",
            "loss: 0.008686422370374203\n",
            "loss: 0.008686361834406853\n",
            "loss: 0.008686305955052376\n",
            "loss: 0.008686241693794727\n",
            "loss: 0.008686202578246593\n",
            "loss: 0.008686152286827564\n",
            "loss: 0.00868617370724678\n",
            "loss: 0.008686086162924767\n",
            "loss: 0.008686007000505924\n",
            "loss: 0.008686003275215626\n",
            "loss: 0.008685947395861149\n",
            "loss: 0.008685913868248463\n",
            "loss: 0.008685862645506859\n",
            "loss: 0.00868581235408783\n",
            "loss: 0.008685721084475517\n",
            "loss: 0.00868569128215313\n",
            "loss: 0.008685659617185593\n",
            "loss: 0.008685590699315071\n",
            "loss: 0.008685523644089699\n",
            "loss: 0.008685502223670483\n",
            "loss: 0.008685491047799587\n",
            "loss: 0.008685439825057983\n",
            "loss: 0.008685432374477386\n",
            "loss: 0.008685356937348843\n",
            "loss: 0.008685268461704254\n",
            "loss: 0.008685361593961716\n",
            "loss: 0.008685274980962276\n",
            "loss: 0.008685313165187836\n",
            "loss: 0.008685287088155746\n",
            "loss: 0.008685309439897537\n",
            "loss: 0.00868532806634903\n",
            "loss: 0.008685312233865261\n",
            "loss: 0.008685240522027016\n",
            "loss: 0.008685151115059853\n",
            "loss: 0.008684995584189892\n",
            "loss: 0.008684930391609669\n",
            "loss: 0.00868475716561079\n",
            "loss: 0.00868466217070818\n",
            "loss: 0.008684574626386166\n",
            "loss: 0.00868452712893486\n",
            "loss: 0.00868448056280613\n",
            "loss: 0.008684437721967697\n",
            "loss: 0.008684510365128517\n",
            "loss: 0.008684389293193817\n",
            "loss: 0.00868438184261322\n",
            "loss: 0.00868433341383934\n",
            "loss: 0.00868423655629158\n",
            "loss: 0.008684132248163223\n",
            "loss: 0.008684106171131134\n",
            "loss: 0.008683963678777218\n",
            "loss: 0.008683952502906322\n",
            "loss: 0.008683990687131882\n",
            "loss: 0.008683901280164719\n",
            "loss: 0.00868381466716528\n",
            "loss: 0.008683796040713787\n",
            "loss: 0.008683783002197742\n",
            "loss: 0.00868372991681099\n",
            "loss: 0.008683673106133938\n",
            "loss: 0.008683549240231514\n",
            "loss: 0.008683564141392708\n",
            "loss: 0.008683468215167522\n",
            "loss: 0.00868338905274868\n",
            "loss: 0.008683353662490845\n",
            "loss: 0.008683335967361927\n",
            "loss: 0.008683291263878345\n",
            "loss: 0.008683184161782265\n",
            "loss: 0.008683177642524242\n",
            "loss: 0.008683140389621258\n",
            "loss: 0.008683073334395885\n",
            "loss: 0.0086830360814929\n",
            "loss: 0.00868295133113861\n",
            "loss: 0.008682943880558014\n",
            "loss: 0.008682864718139172\n",
            "loss: 0.008682847023010254\n",
            "loss: 0.00868275761604309\n",
            "loss: 0.008682774379849434\n",
            "loss: 0.008682671003043652\n",
            "loss: 0.00868266448378563\n",
            "loss: 0.008682593703269958\n",
            "loss: 0.008682544343173504\n",
            "loss: 0.008682464249432087\n",
            "loss: 0.008682466112077236\n",
            "loss: 0.008682440966367722\n",
            "loss: 0.00868238601833582\n",
            "loss: 0.008682331070303917\n",
            "loss: 0.00868219044059515\n",
            "loss: 0.008682182990014553\n",
            "loss: 0.008682147599756718\n",
            "loss: 0.008682108484208584\n",
            "loss: 0.008682038635015488\n",
            "loss: 0.008682013489305973\n",
            "loss: 0.008681938983500004\n",
            "loss: 0.00868188589811325\n",
            "loss: 0.008681869134306908\n",
            "loss: 0.00868176855146885\n",
            "loss: 0.008681785315275192\n",
            "loss: 0.008681676350533962\n",
            "loss: 0.008681645616889\n",
            "loss: 0.008681667037308216\n",
            "loss: 0.008681543171405792\n",
            "loss: 0.008681520819664001\n",
            "loss: 0.008681513369083405\n",
            "loss: 0.008681412786245346\n",
            "loss: 0.00868136528879404\n",
            "loss: 0.008681314997375011\n",
            "loss: 0.008681315928697586\n",
            "loss: 0.008681193925440311\n",
            "loss: 0.00868114922195673\n",
            "loss: 0.00868110079318285\n",
            "loss: 0.008681033737957478\n",
            "loss: 0.008681004866957664\n",
            "loss: 0.008680957369506359\n",
            "loss: 0.008680948987603188\n",
            "loss: 0.008680898696184158\n",
            "loss: 0.008680859580636024\n",
            "loss: 0.008680783212184906\n",
            "loss: 0.008680743165314198\n",
            "loss: 0.008680633269250393\n",
            "loss: 0.008680627681314945\n",
            "loss: 0.008680541068315506\n",
            "loss: 0.008680551312863827\n",
            "loss: 0.008680490776896477\n",
            "loss: 0.008680441416800022\n",
            "loss: 0.008680352009832859\n",
            "loss: 0.008680370636284351\n",
            "loss: 0.008680278435349464\n",
            "loss: 0.008680248633027077\n",
            "loss: 0.008680177852511406\n",
            "loss: 0.008680177852511406\n",
            "loss: 0.008680121041834354\n",
            "loss: 0.008680104278028011\n",
            "loss: 0.008680051192641258\n",
            "loss: 0.008679995313286781\n",
            "loss: 0.008679982274770737\n",
            "loss: 0.008679942227900028\n",
            "loss: 0.008679874241352081\n",
            "loss: 0.008679873310029507\n",
            "loss: 0.008679799735546112\n",
            "loss: 0.008679830469191074\n",
            "loss: 0.008679788559675217\n",
            "loss: 0.008679762482643127\n",
            "loss: 0.008679788559675217\n",
            "loss: 0.008679740130901337\n",
            "loss: 0.008679751306772232\n",
            "loss: 0.008679719641804695\n",
            "loss: 0.00867964792996645\n",
            "loss: 0.008679553866386414\n",
            "loss: 0.008679471909999847\n",
            "loss: 0.008679356426000595\n",
            "loss: 0.008679170161485672\n",
            "loss: 0.008679107762873173\n",
            "loss: 0.008679008111357689\n",
            "loss: 0.0086790407076478\n",
            "loss: 0.008678995072841644\n",
            "loss: 0.008678903803229332\n",
            "loss: 0.00867890939116478\n",
            "loss: 0.008678874932229519\n",
            "loss: 0.008678779937326908\n",
            "loss: 0.008678753860294819\n",
            "loss: 0.008678622543811798\n",
            "loss: 0.008678589016199112\n",
            "loss: 0.008678550831973553\n",
            "loss: 0.008678465150296688\n",
            "loss: 0.008678378537297249\n",
            "loss: 0.008678409270942211\n",
            "loss: 0.008678349666297436\n",
            "loss: 0.008678313344717026\n",
            "loss: 0.008678301237523556\n",
            "loss: 0.008678226731717587\n",
            "loss: 0.008678164333105087\n",
            "loss: 0.008678097277879715\n",
            "loss: 0.008678087964653969\n",
            "loss: 0.008678033016622066\n",
            "loss: 0.008677957579493523\n",
            "loss: 0.008677851408720016\n",
            "loss: 0.00867783185094595\n",
            "loss: 0.008677779696881771\n",
            "loss: 0.008677791804075241\n",
            "loss: 0.00867769680917263\n",
            "loss: 0.008677677251398563\n",
            "loss: 0.008677610196173191\n",
            "loss: 0.008677566424012184\n",
            "loss: 0.008677547797560692\n",
            "loss: 0.008677441626787186\n",
            "loss: 0.008677407167851925\n",
            "loss: 0.008677349425852299\n",
            "loss: 0.00867728516459465\n",
            "loss: 0.008677287958562374\n",
            "loss: 0.008677213452756405\n",
            "loss: 0.008677152916789055\n",
            "loss: 0.00867715198546648\n",
            "loss: 0.00867705512791872\n",
            "loss: 0.008677002973854542\n",
            "loss: 0.008676973171532154\n",
            "loss: 0.008676894009113312\n",
            "loss: 0.008676835335791111\n",
            "loss: 0.008676820434629917\n",
            "loss: 0.008676758967339993\n",
            "loss: 0.008676664903759956\n",
            "loss: 0.008676641620695591\n",
            "loss: 0.008676611818373203\n",
            "loss: 0.008676562458276749\n",
            "loss: 0.008676507510244846\n",
            "loss: 0.008676489815115929\n",
            "loss: 0.008676380850374699\n",
            "loss: 0.008676336146891117\n",
            "loss: 0.008676314726471901\n",
            "loss: 0.00867626816034317\n",
            "loss: 0.008676248602569103\n",
            "loss: 0.008676174096763134\n",
            "loss: 0.008676127530634403\n",
            "loss: 0.008676094934344292\n",
            "loss: 0.00867603998631239\n",
            "loss: 0.008675905875861645\n",
            "loss: 0.0086759552359581\n",
            "loss: 0.008675887249410152\n",
            "loss: 0.008675845339894295\n",
            "loss: 0.00867584627121687\n",
            "loss: 0.008675778284668922\n",
            "loss: 0.008675673976540565\n",
            "loss: 0.00867566280066967\n",
            "loss: 0.008675601333379745\n",
            "loss: 0.008675534278154373\n",
            "loss: 0.00867548119276762\n",
            "loss: 0.008675442077219486\n",
            "loss: 0.008675415068864822\n",
            "loss: 0.008675381541252136\n",
            "loss: 0.008675333112478256\n",
            "loss: 0.008675353601574898\n",
            "loss: 0.008675283752381802\n",
            "loss: 0.00867526326328516\n",
            "loss: 0.008675213903188705\n",
            "loss: 0.00867515616118908\n",
            "loss: 0.00867516826838255\n",
            "loss: 0.008675132878124714\n",
            "loss: 0.008675088174641132\n",
            "loss: 0.00867499690502882\n",
            "loss: 0.008674957789480686\n",
            "loss: 0.00867482926696539\n",
            "loss: 0.00867475476115942\n",
            "loss: 0.008674684911966324\n",
            "loss: 0.008674584329128265\n",
            "loss: 0.008674580603837967\n",
            "loss: 0.008674546144902706\n",
            "loss: 0.008674533106386662\n",
            "loss: 0.008674516342580318\n",
            "loss: 0.008674469776451588\n",
            "loss: 0.008674376644194126\n",
            "loss: 0.00867435336112976\n",
            "loss: 0.00867429468780756\n",
            "loss: 0.00867428444325924\n",
            "loss: 0.008674198761582375\n",
            "loss: 0.008674194104969501\n",
            "loss: 0.008674180135130882\n",
            "loss: 0.008674158714711666\n",
            "loss: 0.008674130775034428\n",
            "loss: 0.008674106560647488\n",
            "loss: 0.008674059063196182\n",
            "loss: 0.008673998527228832\n",
            "loss: 0.008673930540680885\n",
            "loss: 0.008673857897520065\n",
            "loss: 0.008673801086843014\n",
            "loss: 0.008673694916069508\n",
            "loss: 0.008673601783812046\n",
            "loss: 0.00867351796478033\n",
            "loss: 0.008673456497490406\n",
            "loss: 0.008673341944813728\n",
            "loss: 0.008673345670104027\n",
            "loss: 0.008673317730426788\n",
            "loss: 0.008673258125782013\n",
            "loss: 0.008673254400491714\n",
            "loss: 0.008673173375427723\n",
            "loss: 0.008673149161040783\n",
            "loss: 0.008673076517879963\n",
            "loss: 0.008673077449202538\n",
            "loss: 0.0086729871109128\n",
            "loss: 0.008672928437590599\n",
            "loss: 0.008672882802784443\n",
            "loss: 0.008672792464494705\n",
            "loss: 0.008672762662172318\n",
            "loss: 0.008672688156366348\n",
            "loss: 0.008672649040818214\n",
            "loss: 0.008672608062624931\n",
            "loss: 0.008672558702528477\n",
            "loss: 0.008672533556818962\n",
            "loss: 0.008672527968883514\n",
            "loss: 0.00867247860878706\n",
            "loss: 0.008672370575368404\n",
            "loss: 0.008672329597175121\n",
            "loss: 0.008672318421304226\n",
            "loss: 0.008672261610627174\n",
            "loss: 0.008672165684401989\n",
            "loss: 0.00867210328578949\n",
            "loss: 0.008672068826854229\n",
            "loss: 0.008672058582305908\n",
            "loss: 0.008671966381371021\n",
            "loss: 0.008671973831951618\n",
            "loss: 0.00867186114192009\n",
            "loss: 0.008671811781823635\n",
            "loss: 0.00867181085050106\n",
            "loss: 0.008671725168824196\n",
            "loss: 0.008671729825437069\n",
            "loss: 0.008671605959534645\n",
            "loss: 0.008671612478792667\n",
            "loss: 0.008671540766954422\n",
            "loss: 0.008671490475535393\n",
            "loss: 0.008671476505696774\n",
            "loss: 0.008671422488987446\n",
            "loss: 0.008671324700117111\n",
            "loss: 0.008671308867633343\n",
            "loss: 0.008671220391988754\n",
            "loss: 0.008671256713569164\n",
            "loss: 0.008671101182699203\n",
            "loss: 0.008671182207763195\n",
            "loss: 0.008671099320054054\n",
            "loss: 0.008671004325151443\n",
            "loss: 0.00867102388292551\n",
            "loss: 0.008670917712152004\n",
            "loss: 0.008670860901474953\n",
            "loss: 0.008670855313539505\n",
            "loss: 0.008670732378959656\n",
            "loss: 0.008670755662024021\n",
            "loss: 0.00867068488150835\n",
            "loss: 0.008670629002153873\n",
            "loss: 0.008670606650412083\n",
            "loss: 0.008670534938573837\n",
            "loss: 0.008670472539961338\n",
            "loss: 0.008670463226735592\n",
            "loss: 0.00867040641605854\n",
            "loss: 0.008670317940413952\n",
            "loss: 0.008670290932059288\n",
            "loss: 0.008670288138091564\n",
            "loss: 0.00867021456360817\n",
            "loss: 0.008670096285641193\n",
            "loss: 0.008670154958963394\n",
            "loss: 0.008670047856867313\n",
            "loss: 0.008670035749673843\n",
            "loss: 0.00866995844990015\n",
            "loss: 0.008669988252222538\n",
            "loss: 0.008669947274029255\n",
            "loss: 0.008669941686093807\n",
            "loss: 0.00866987556219101\n",
            "loss: 0.008669835515320301\n",
            "loss: 0.008669879287481308\n",
            "loss: 0.00866983737796545\n",
            "loss: 0.008669797331094742\n",
            "loss: 0.008669703267514706\n",
            "loss: 0.008669746108353138\n",
            "loss: 0.008669600822031498\n",
            "loss: 0.008669585920870304\n",
            "loss: 0.008669513277709484\n",
            "loss: 0.00866941548883915\n",
            "loss: 0.008669357746839523\n",
            "loss: 0.008669300936162472\n",
            "loss: 0.008669158443808556\n",
            "loss: 0.00866905227303505\n",
            "loss: 0.008669049479067326\n",
            "loss: 0.008669004775583744\n",
            "loss: 0.008668986149132252\n",
            "loss: 0.00866885855793953\n",
            "loss: 0.008668945170938969\n",
            "loss: 0.008668852038681507\n",
            "loss: 0.008668805472552776\n",
            "loss: 0.008668757975101471\n",
            "loss: 0.008668696507811546\n",
            "loss: 0.008668587543070316\n",
            "loss: 0.008668548427522182\n",
            "loss: 0.008668476715683937\n",
            "loss: 0.008668430149555206\n",
            "loss: 0.008668417111039162\n",
            "loss: 0.008668284863233566\n",
            "loss: 0.008668283000588417\n",
            "loss: 0.008668296039104462\n",
            "loss: 0.0086682653054595\n",
            "loss: 0.00866821687668562\n",
            "loss: 0.008668140508234501\n",
            "loss: 0.008668073453009129\n",
            "loss: 0.008667983114719391\n",
            "loss: 0.008668004535138607\n",
            "loss: 0.00866791419684887\n",
            "loss: 0.008667883463203907\n",
            "loss: 0.008667822927236557\n",
            "loss: 0.00866774283349514\n",
            "loss: 0.008667800575494766\n",
            "loss: 0.008667659014463425\n",
            "loss: 0.008667642250657082\n",
            "loss: 0.008667615242302418\n",
            "loss: 0.008667577989399433\n",
            "loss: 0.00866745226085186\n",
            "loss: 0.00866736564785242\n",
            "loss: 0.008667395450174809\n",
            "loss: 0.00866731721907854\n",
            "loss: 0.00866726040840149\n",
            "loss: 0.008667226880788803\n",
            "loss: 0.008667177520692348\n",
            "loss: 0.008667154237627983\n",
            "loss: 0.008667105808854103\n",
            "loss: 0.008667067624628544\n",
            "loss: 0.008666994981467724\n",
            "loss: 0.008666908368468285\n",
            "loss: 0.008666861802339554\n",
            "loss: 0.008666875772178173\n",
            "loss: 0.008666791021823883\n",
            "loss: 0.008666782639920712\n",
            "loss: 0.008666634559631348\n",
            "loss: 0.008666684851050377\n",
            "loss: 0.008666552603244781\n",
            "loss: 0.008666491135954857\n",
            "loss: 0.008666504174470901\n",
            "loss: 0.008666486479341984\n",
            "loss: 0.008666418492794037\n",
            "loss: 0.00866635050624609\n",
            "loss: 0.008666301146149635\n",
            "loss: 0.008666235953569412\n",
            "loss: 0.00866624154150486\n",
            "loss: 0.008666138164699078\n",
            "loss: 0.008666065521538258\n",
            "loss: 0.008666065521538258\n",
            "loss: 0.008665994741022587\n",
            "loss: 0.008665932342410088\n",
            "loss: 0.008665927685797215\n",
            "loss: 0.008665883913636208\n",
            "loss: 0.00866579171270132\n",
            "loss: 0.008665792644023895\n",
            "loss: 0.008665727451443672\n",
            "loss: 0.008665712550282478\n",
            "loss: 0.008665688335895538\n",
            "loss: 0.008665607310831547\n",
            "loss: 0.008665641769766808\n",
            "loss: 0.008665556088089943\n",
            "loss: 0.008665567263960838\n",
            "loss: 0.0086655393242836\n",
            "loss: 0.00866551510989666\n",
            "loss: 0.008665517903864384\n",
            "loss: 0.008665488101541996\n",
            "loss: 0.008665511384606361\n",
            "loss: 0.008665473200380802\n",
            "loss: 0.00866540428251028\n",
            "loss: 0.008665349334478378\n",
            "loss: 0.008665220811963081\n",
            "loss: 0.00866510160267353\n",
            "loss: 0.008664979599416256\n",
            "loss: 0.008664960972964764\n",
            "loss: 0.008664854802191257\n",
            "loss: 0.008664797991514206\n",
            "loss: 0.008664743043482304\n",
            "loss: 0.008664718829095364\n",
            "loss: 0.008664609864354134\n",
            "loss: 0.008664594031870365\n",
            "loss: 0.008664594031870365\n",
            "loss: 0.00866448599845171\n",
            "loss: 0.008664431981742382\n",
            "loss: 0.00866441335529089\n",
            "loss: 0.008664348162710667\n",
            "loss: 0.00866430252790451\n",
            "loss: 0.008664287626743317\n",
            "loss: 0.008664228022098541\n",
            "loss: 0.008664130233228207\n",
            "loss: 0.008664070628583431\n",
            "loss: 0.00866398774087429\n",
            "loss: 0.008663981221616268\n",
            "loss: 0.008663881570100784\n",
            "loss: 0.008663874119520187\n",
            "loss: 0.008663853630423546\n",
            "loss: 0.008663753047585487\n",
            "loss: 0.008663693442940712\n",
            "loss: 0.008663663640618324\n",
            "loss: 0.008663620799779892\n",
            "loss: 0.008663574233651161\n",
            "loss: 0.008663523010909557\n",
            "loss: 0.00866352766752243\n",
            "loss: 0.00866343080997467\n",
            "loss: 0.008663392625749111\n",
            "loss: 0.008663306944072247\n",
            "loss: 0.008663308806717396\n",
            "loss: 0.008663203567266464\n",
            "loss: 0.008663193322718143\n",
            "loss: 0.008663156069815159\n",
            "loss: 0.008663092739880085\n",
            "loss: 0.008663046173751354\n",
            "loss: 0.008663052693009377\n",
            "loss: 0.008662978187203407\n",
            "loss: 0.008662935346364975\n",
            "loss: 0.008662868291139603\n",
            "loss: 0.00866280123591423\n",
            "loss: 0.008662755601108074\n",
            "loss: 0.008662733249366283\n",
            "loss: 0.008662656880915165\n",
            "loss: 0.008662640117108822\n",
            "loss: 0.008662568405270576\n",
            "loss: 0.008662555366754532\n",
            "loss: 0.008662456646561623\n",
            "loss: 0.008662417531013489\n",
            "loss: 0.008662371896207333\n",
            "loss: 0.008662309497594833\n",
            "loss: 0.008662312291562557\n",
            "loss: 0.00866224430501461\n",
            "loss: 0.008662215434014797\n",
            "loss: 0.008662143722176552\n",
            "loss: 0.008662020787596703\n",
            "loss: 0.008662053383886814\n",
            "loss: 0.008662019856274128\n",
            "loss: 0.008661896921694279\n",
            "loss: 0.008661946281790733\n",
            "loss: 0.00866185687482357\n",
            "loss: 0.008661825209856033\n",
            "loss: 0.008661775849759579\n",
            "loss: 0.008661769330501556\n",
            "loss: 0.008661656640470028\n",
            "loss: 0.008661636151373386\n",
            "loss: 0.008661612868309021\n",
            "loss: 0.008661635220050812\n",
            "loss: 0.008661585859954357\n",
            "loss: 0.00866154208779335\n",
            "loss: 0.008661497384309769\n",
            "loss: 0.008661472238600254\n",
            "loss: 0.008661455474793911\n",
            "loss: 0.0086614228785038\n",
            "loss: 0.008661400526762009\n",
            "loss: 0.008661258965730667\n",
            "loss: 0.008661228232085705\n",
            "loss: 0.008661082945764065\n",
            "loss: 0.008661105297505856\n",
            "loss: 0.00866097304970026\n",
            "loss: 0.008660928346216679\n",
            "loss: 0.008660865016281605\n",
            "loss: 0.008660771884024143\n",
            "loss: 0.008660754188895226\n",
            "loss: 0.008660688064992428\n",
            "loss: 0.008660638704895973\n",
            "loss: 0.008660618215799332\n",
            "loss: 0.0086605753749609\n",
            "loss: 0.008660477586090565\n",
            "loss: 0.00866041798144579\n",
            "loss: 0.008660377003252506\n",
            "loss: 0.008660363033413887\n",
            "loss: 0.008660291321575642\n",
            "loss: 0.008660253137350082\n",
            "loss: 0.0086602084338665\n",
            "loss: 0.008660132065415382\n",
            "loss: 0.008660062216222286\n",
            "loss: 0.008660039864480495\n",
            "loss: 0.008659989573061466\n",
            "loss: 0.008659940212965012\n",
            "loss: 0.008659900166094303\n",
            "loss: 0.008659841492772102\n",
            "loss: 0.008659821934998035\n",
            "loss: 0.008659793995320797\n",
            "loss: 0.008659681305289268\n",
            "loss: 0.008659670129418373\n",
            "loss: 0.008659609593451023\n",
            "loss: 0.008659543469548225\n",
            "loss: 0.008659525774419308\n",
            "loss: 0.00865949410945177\n",
            "loss: 0.008659419603645802\n",
            "loss: 0.008659416809678078\n",
            "loss: 0.00865932647138834\n",
            "loss: 0.008659260347485542\n",
            "loss: 0.00865920726209879\n",
            "loss: 0.008659194223582745\n",
            "loss: 0.008659138344228268\n",
            "loss: 0.008659052662551403\n",
            "loss: 0.00865898560732603\n",
            "loss: 0.008659006096422672\n",
            "loss: 0.008658932521939278\n",
            "loss: 0.00865884218364954\n",
            "loss: 0.00865884032100439\n",
            "loss: 0.008658796548843384\n",
            "loss: 0.008658705279231071\n",
            "loss: 0.00865866243839264\n",
            "loss: 0.008658649399876595\n",
            "loss: 0.008658603765070438\n",
            "loss: 0.00865856371819973\n",
            "loss: 0.008658520877361298\n",
            "loss: 0.008658427745103836\n",
            "loss: 0.00865843240171671\n",
            "loss: 0.008658358827233315\n",
            "loss: 0.008658326230943203\n",
            "loss: 0.00865831971168518\n",
            "loss: 0.00865818839520216\n",
            "loss: 0.00865824706852436\n",
            "loss: 0.008658181875944138\n",
            "loss: 0.008658153004944324\n",
            "loss: 0.008658143691718578\n",
            "loss: 0.008658133447170258\n",
            "loss: 0.008658108301460743\n",
            "loss: 0.008658133447170258\n",
            "loss: 0.008658244274556637\n",
            "loss: 0.008658290840685368\n",
            "loss: 0.008658289909362793\n",
            "loss: 0.008658348582684994\n",
            "loss: 0.008658276870846748\n",
            "loss: 0.00865807756781578\n",
            "loss: 0.008657803758978844\n",
            "loss: 0.008657651953399181\n",
            "loss: 0.008657515980303288\n",
            "loss: 0.008657403290271759\n",
            "loss: 0.008657470345497131\n",
            "loss: 0.008657456375658512\n",
            "loss: 0.00865743588656187\n",
            "loss: 0.00865737535059452\n",
            "loss: 0.008657291531562805\n",
            "loss: 0.008657247759401798\n",
            "loss: 0.00865708664059639\n",
            "loss: 0.008657035417854786\n",
            "loss: 0.008656998164951801\n",
            "loss: 0.008656937628984451\n",
            "loss: 0.008656899444758892\n",
            "loss: 0.008656864985823631\n",
            "loss: 0.008656798861920834\n",
            "loss: 0.008656715974211693\n",
            "loss: 0.008656686171889305\n",
            "loss: 0.008656640537083149\n",
            "loss: 0.008656566962599754\n",
            "loss: 0.008656546473503113\n",
            "loss: 0.008656498976051807\n",
            "loss: 0.008656460791826248\n",
            "loss: 0.008656373247504234\n",
            "loss: 0.008656313642859459\n",
            "loss: 0.00865628756582737\n",
            "loss: 0.008656274527311325\n",
            "loss: 0.008656272664666176\n",
            "loss: 0.008656115271151066\n",
            "loss: 0.008656065911054611\n",
            "loss: 0.008656010963022709\n",
            "loss: 0.008656002581119537\n",
            "loss: 0.008655980229377747\n",
            "loss: 0.00865592248737812\n",
            "loss: 0.008655864745378494\n",
            "loss: 0.008655810728669167\n",
            "loss: 0.008655766025185585\n",
            "loss: 0.008655719459056854\n",
            "loss: 0.00865570455789566\n",
            "loss: 0.008655626326799393\n",
            "loss: 0.008655602112412453\n",
            "loss: 0.008655532263219357\n",
            "loss: 0.008655453100800514\n",
            "loss: 0.008655416779220104\n",
            "loss: 0.008655370213091373\n",
            "loss: 0.008655320852994919\n",
            "loss: 0.008655291981995106\n",
            "loss: 0.008655225858092308\n",
            "loss: 0.008655183017253876\n",
            "loss: 0.008655102923512459\n",
            "loss: 0.00865506287664175\n",
            "loss: 0.008655067533254623\n",
            "loss: 0.008654997684061527\n",
            "loss: 0.008654908277094364\n",
            "loss: 0.008654865436255932\n",
            "loss: 0.008654844015836716\n",
            "loss: 0.008654818870127201\n",
            "loss: 0.008654750883579254\n",
            "loss: 0.008654691278934479\n",
            "loss: 0.008654654026031494\n",
            "loss: 0.008654595352709293\n",
            "loss: 0.008654576726257801\n",
            "loss: 0.008654532954096794\n",
            "loss: 0.008654482662677765\n",
            "loss: 0.008654437027871609\n",
            "loss: 0.008654340170323849\n",
            "loss: 0.00865428801625967\n",
            "loss: 0.008654250763356686\n",
            "loss: 0.00865419302135706\n",
            "loss: 0.00865415669977665\n",
            "loss: 0.008654140867292881\n",
            "loss: 0.00865410640835762\n",
            "loss: 0.008654052391648293\n",
            "loss: 0.008653992787003517\n",
            "loss: 0.008653935976326466\n",
            "loss: 0.008653893135488033\n",
            "loss: 0.00865382794290781\n",
            "loss: 0.008653795346617699\n",
            "loss: 0.00865370687097311\n",
            "loss: 0.008653661236166954\n",
            "loss: 0.00865364633500576\n",
            "loss: 0.008653603494167328\n",
            "loss: 0.008653522469103336\n",
            "loss: 0.008653479628264904\n",
            "loss: 0.008653473109006882\n",
            "loss: 0.008653394877910614\n",
            "loss: 0.008653352037072182\n",
            "loss: 0.00865330919623375\n",
            "loss: 0.008653214201331139\n",
            "loss: 0.00865318812429905\n",
            "loss: 0.008653145283460617\n",
            "loss: 0.008653128519654274\n",
            "loss: 0.008653069846332073\n",
            "loss: 0.008653045631945133\n",
            "loss: 0.008652950637042522\n",
            "loss: 0.008652918040752411\n",
            "loss: 0.008652896620333195\n",
            "loss: 0.008652808144688606\n",
            "loss: 0.008652758784592152\n",
            "loss: 0.008652730844914913\n",
            "loss: 0.008652662858366966\n",
            "loss: 0.008652662858366966\n",
            "loss: 0.0086525809019804\n",
            "loss: 0.008652529679238796\n",
            "loss: 0.008652503602206707\n",
            "loss: 0.00865238904953003\n",
            "loss: 0.008652407675981522\n",
            "loss: 0.008652281947433949\n",
            "loss: 0.008652321994304657\n",
            "loss: 0.008652318269014359\n",
            "loss: 0.008652196265757084\n",
            "loss: 0.008652186021208763\n",
            "loss: 0.008652068674564362\n",
            "loss: 0.008652093820273876\n",
            "loss: 0.008652000688016415\n",
            "loss: 0.008651910349726677\n",
            "loss: 0.008651906624436378\n",
            "loss: 0.008651871234178543\n",
            "loss: 0.00865175761282444\n",
            "loss: 0.00865175761282444\n",
            "loss: 0.008651725016534328\n",
            "loss: 0.00865168310701847\n",
            "loss: 0.008651625365018845\n",
            "loss: 0.008651573210954666\n",
            "loss: 0.00865151733160019\n",
            "loss: 0.008651451207697392\n",
            "loss: 0.0086514325812459\n",
            "loss: 0.008651411160826683\n",
            "loss: 0.008651398122310638\n",
            "loss: 0.008651294745504856\n",
            "loss: 0.008651241660118103\n",
            "loss: 0.00865120068192482\n",
            "loss: 0.008651257492601871\n",
            "loss: 0.008651160635054111\n",
            "loss: 0.008651074022054672\n",
            "loss: 0.008651136420667171\n",
            "loss: 0.008651189506053925\n",
            "loss: 0.008651184849441051\n",
            "loss: 0.008651227690279484\n",
            "loss: 0.008651282638311386\n",
            "loss: 0.008651458658277988\n",
            "loss: 0.00865150149911642\n",
            "loss: 0.00865146517753601\n",
            "loss: 0.008651315234601498\n",
            "loss: 0.008650979027152061\n",
            "loss: 0.008650627918541431\n",
            "loss: 0.008650427684187889\n",
            "loss: 0.008650482632219791\n",
            "loss: 0.008650660514831543\n",
            "loss: 0.008650615811347961\n",
            "loss: 0.008650613017380238\n",
            "loss: 0.008650372736155987\n",
            "loss: 0.008650275878608227\n",
            "loss: 0.008650165982544422\n",
            "loss: 0.008650222793221474\n",
            "loss: 0.008650229312479496\n",
            "loss: 0.008650101721286774\n",
            "loss: 0.008650003001093864\n",
            "loss: 0.008649852126836777\n",
            "loss: 0.008649847470223904\n",
            "loss: 0.008649885654449463\n",
            "loss: 0.008649882860481739\n",
            "loss: 0.008649801835417747\n",
            "loss: 0.008649643510580063\n",
            "loss: 0.008649666793644428\n",
            "loss: 0.008649575524032116\n",
            "loss: 0.008649587631225586\n",
            "loss: 0.008649528957903385\n",
            "loss: 0.00864950381219387\n",
            "loss: 0.00864938460290432\n",
            "loss: 0.008649318479001522\n",
            "loss: 0.008649218827486038\n",
            "loss: 0.008649306371808052\n",
            "loss: 0.00864920113235712\n",
            "loss: 0.008649188093841076\n",
            "loss: 0.008649109862744808\n",
            "loss: 0.008649018593132496\n",
            "loss: 0.008648945949971676\n",
            "loss: 0.008648975752294064\n",
            "loss: 0.008648868650197983\n",
            "loss: 0.008648890070617199\n",
            "loss: 0.008648774586617947\n",
            "loss: 0.008648738265037537\n",
            "loss: 0.008648687042295933\n",
            "loss: 0.008648665621876717\n",
            "loss: 0.008648631162941456\n",
            "loss: 0.00864853709936142\n",
            "loss: 0.008648520335555077\n",
            "loss: 0.008648506365716457\n",
            "loss: 0.008648436516523361\n",
            "loss: 0.008648404851555824\n",
            "loss: 0.008648299612104893\n",
            "loss: 0.008648309856653214\n",
            "loss: 0.008648192510008812\n",
            "loss: 0.00864823441952467\n",
            "loss: 0.008648126386106014\n",
            "loss: 0.008648094721138477\n",
            "loss: 0.008648053742945194\n",
            "loss: 0.008647985756397247\n",
            "loss: 0.00864796806126833\n",
            "loss: 0.00864795595407486\n",
            "loss: 0.008647889830172062\n",
            "loss: 0.008647873066365719\n",
            "loss: 0.008647767826914787\n",
            "loss: 0.008647737093269825\n",
            "loss: 0.008647716604173183\n",
            "loss: 0.008647628128528595\n",
            "loss: 0.008647583425045013\n",
            "loss: 0.00864750612527132\n",
            "loss: 0.008647482842206955\n",
            "loss: 0.008647366426885128\n",
            "loss: 0.00864742137491703\n",
            "loss: 0.008647391572594643\n",
            "loss: 0.008647264912724495\n",
            "loss: 0.008647238835692406\n",
            "loss: 0.008647213689982891\n",
            "loss: 0.008647136390209198\n",
            "loss: 0.008647100068628788\n",
            "loss: 0.008647040463984013\n",
            "loss: 0.008647016249597073\n",
            "loss: 0.008646932430565357\n",
            "loss: 0.008646913804113865\n",
            "loss: 0.008646897971630096\n",
            "loss: 0.008646773174405098\n",
            "loss: 0.008646734058856964\n",
            "loss: 0.008646747097373009\n",
            "loss: 0.008646712638437748\n",
            "loss: 0.008646613918244839\n",
            "loss: 0.00864656362682581\n",
            "loss: 0.008646569214761257\n",
            "loss: 0.008646514266729355\n",
            "loss: 0.0086464062333107\n",
            "loss: 0.008646367117762566\n",
            "loss: 0.008646316826343536\n",
            "loss: 0.008646264672279358\n",
            "loss: 0.00864622462540865\n",
            "loss: 0.008646165020763874\n",
            "loss: 0.008646144531667233\n",
            "loss: 0.008646124973893166\n",
            "loss: 0.0086461016908288\n",
            "loss: 0.008646000176668167\n",
            "loss: 0.008645954541862011\n",
            "loss: 0.008645887486636639\n",
            "loss: 0.008645839989185333\n",
            "loss: 0.00864587165415287\n",
            "loss: 0.008645815774798393\n",
            "loss: 0.008645778521895409\n",
            "loss: 0.008645717054605484\n",
            "loss: 0.00864571426063776\n",
            "loss: 0.008645694702863693\n",
            "loss: 0.00864575244486332\n",
            "loss: 0.008645730093121529\n",
            "loss: 0.008645746856927872\n",
            "loss: 0.008645748719573021\n",
            "loss: 0.008645704947412014\n",
            "loss: 0.008645604364573956\n",
            "loss: 0.008645459078252316\n",
            "loss: 0.008645300753414631\n",
            "loss: 0.008645202964544296\n",
            "loss: 0.008645088411867619\n",
            "loss: 0.008645091205835342\n",
            "loss: 0.008645073510706425\n",
            "loss: 0.008645002730190754\n",
            "loss: 0.00864501018077135\n",
            "loss: 0.008645014837384224\n",
            "loss: 0.008644907735288143\n",
            "loss: 0.00864485278725624\n",
            "loss: 0.008644742891192436\n",
            "loss: 0.008644727990031242\n",
            "loss: 0.0086446488276124\n",
            "loss: 0.008644644170999527\n",
            "loss: 0.00864455010741949\n",
            "loss: 0.008644522167742252\n",
            "loss: 0.008644483983516693\n",
            "loss: 0.00864439457654953\n",
            "loss: 0.008644388988614082\n",
            "loss: 0.00864427164196968\n",
            "loss: 0.008644230663776398\n",
            "loss: 0.00864416267722845\n",
            "loss: 0.008644182235002518\n",
            "loss: 0.008644124493002892\n",
            "loss: 0.008644036017358303\n",
            "loss: 0.00864402949810028\n",
            "loss: 0.008643942885100842\n",
            "loss: 0.008643927983939648\n",
            "loss: 0.008643840439617634\n",
            "loss: 0.008643780834972858\n",
            "loss: 0.008643772453069687\n",
            "loss: 0.008643725886940956\n",
            "loss: 0.00864361971616745\n",
            "loss: 0.008643644861876965\n",
            "loss: 0.008643611334264278\n",
            "loss: 0.008643549866974354\n",
            "loss: 0.008643442764878273\n",
            "loss: 0.00864341389387846\n",
            "loss: 0.008643411099910736\n",
            "loss: 0.008643346838653088\n",
            "loss: 0.00864330679178238\n",
            "loss: 0.008643236011266708\n",
            "loss: 0.008643139153718948\n",
            "loss: 0.008643146604299545\n",
            "loss: 0.008643078617751598\n",
            "loss: 0.008643052540719509\n",
            "loss: 0.008642978966236115\n",
            "loss: 0.008642932400107384\n",
            "loss: 0.008642932400107384\n",
            "loss: 0.008642845787107944\n",
            "loss: 0.008642799220979214\n",
            "loss: 0.008642751723527908\n",
            "loss: 0.008642731234431267\n",
            "loss: 0.00864268559962511\n",
            "loss: 0.008642645552754402\n",
            "loss: 0.008642608299851418\n",
            "loss: 0.008642525412142277\n",
            "loss: 0.008642468601465225\n",
            "loss: 0.008642483502626419\n",
            "loss: 0.00864235870540142\n",
            "loss: 0.008642362430691719\n",
            "loss: 0.008642292581498623\n",
            "loss: 0.008642254397273064\n",
            "loss: 0.008642244152724743\n",
            "loss: 0.008642138913273811\n",
            "loss: 0.008642066270112991\n",
            "loss: 0.008642066270112991\n",
            "loss: 0.008642026223242283\n",
            "loss: 0.00864195916801691\n",
            "loss: 0.008641887456178665\n",
            "loss: 0.008641872555017471\n",
            "loss: 0.008641778491437435\n",
            "loss: 0.008641785010695457\n",
            "loss: 0.00864168256521225\n",
            "loss: 0.008641708642244339\n",
            "loss: 0.008641631342470646\n",
            "loss: 0.008641500025987625\n",
            "loss: 0.008641569875180721\n",
            "loss: 0.008641473948955536\n",
            "loss: 0.008641397580504417\n",
            "loss: 0.008641387335956097\n",
            "loss: 0.008641364052891731\n",
            "loss: 0.008641215041279793\n",
            "loss: 0.008641251362860203\n",
            "loss: 0.008641192689538002\n",
            "loss: 0.008641134016215801\n",
            "loss: 0.008641094900667667\n",
            "loss: 0.008641069754958153\n",
            "loss: 0.008640964515507221\n",
            "loss: 0.008640963584184647\n",
            "loss: 0.008640870451927185\n",
            "loss: 0.008640799671411514\n",
            "loss: 0.008640853688120842\n",
            "loss: 0.008640753105282784\n",
            "loss: 0.00864068977534771\n",
            "loss: 0.008640622720122337\n",
            "loss: 0.008640583604574203\n",
            "loss: 0.008640569634735584\n",
            "loss: 0.008640515618026257\n",
            "loss: 0.008640500716865063\n",
            "loss: 0.008640414103865623\n",
            "loss: 0.008640422485768795\n",
            "loss: 0.008640321902930737\n",
            "loss: 0.008640269748866558\n",
            "loss: 0.008640240877866745\n",
            "loss: 0.008640200830996037\n",
            "loss: 0.008640188723802567\n",
            "loss: 0.008640211075544357\n",
            "loss: 0.008640152402222157\n",
            "loss: 0.008640177547931671\n",
            "loss: 0.008640107698738575\n",
            "loss: 0.008640188723802567\n",
            "loss: 0.008640202693641186\n",
            "loss: 0.008640161715447903\n",
            "loss: 0.008640165440738201\n",
            "loss: 0.008640092797577381\n",
            "loss: 0.008639996871352196\n",
            "loss: 0.00863991305232048\n",
            "loss: 0.008639834821224213\n",
            "loss: 0.00863961223512888\n",
            "loss: 0.008639502339065075\n",
            "loss: 0.008639425039291382\n",
            "loss: 0.008639412932097912\n",
            "loss: 0.008639401756227016\n",
            "loss: 0.008639320731163025\n",
            "loss: 0.008639328181743622\n",
            "loss: 0.008639328181743622\n",
            "loss: 0.008639272302389145\n",
            "loss: 0.008639197796583176\n",
            "loss: 0.008639105595648289\n",
            "loss: 0.00863900501281023\n",
            "loss: 0.008639000356197357\n",
            "loss: 0.00863889791071415\n",
            "loss: 0.008638879284262657\n",
            "loss: 0.008638797327876091\n",
            "loss: 0.008638788014650345\n",
            "loss: 0.00863875076174736\n",
            "loss: 0.008638698607683182\n",
            "loss: 0.00863865576684475\n",
            "loss: 0.008638566359877586\n",
            "loss: 0.008638586848974228\n",
            "loss: 0.008638434112071991\n",
            "loss: 0.008638421073555946\n",
            "loss: 0.008638408035039902\n",
            "loss: 0.008638310246169567\n",
            "loss: 0.008638311177492142\n",
            "loss: 0.008638177067041397\n",
            "loss: 0.00863819569349289\n",
            "loss: 0.008638114668428898\n",
            "loss: 0.008638144470751286\n",
            "loss: 0.008637998253107071\n",
            "loss: 0.008638021536171436\n",
            "loss: 0.008637972176074982\n",
            "loss: 0.008637904189527035\n",
            "loss: 0.008637839928269386\n",
            "loss: 0.008637777529656887\n",
            "loss: 0.008637790568172932\n",
            "loss: 0.008637731894850731\n",
            "loss: 0.00863766111433506\n",
            "loss: 0.008637611754238605\n",
            "loss: 0.008637565188109875\n",
            "loss: 0.008637528866529465\n",
            "loss: 0.008637475781142712\n",
            "loss: 0.008637397550046444\n",
            "loss: 0.008637390099465847\n",
            "loss: 0.008637329563498497\n",
            "loss: 0.008637306280434132\n",
            "loss: 0.00863727182149887\n",
            "loss: 0.0086371386423707\n",
            "loss: 0.008637112565338612\n",
            "loss: 0.008637129329144955\n",
            "loss: 0.008637073449790478\n",
            "loss: 0.008637010119855404\n",
            "loss: 0.008636962622404099\n",
            "loss: 0.008636927232146263\n",
            "loss: 0.008636861108243465\n",
            "loss: 0.008636871352791786\n",
            "loss: 0.008636715821921825\n",
            "loss: 0.00863672699779272\n",
            "loss: 0.00863669440150261\n",
            "loss: 0.008636591024696827\n",
            "loss: 0.008636592887341976\n",
            "loss: 0.008636517450213432\n",
            "loss: 0.008636497892439365\n",
            "loss: 0.008636435493826866\n",
            "loss: 0.008636344224214554\n",
            "loss: 0.008636354468762875\n",
            "loss: 0.008636243641376495\n",
            "loss: 0.008636202663183212\n",
            "loss: 0.00863615795969963\n",
            "loss: 0.008636154234409332\n",
            "loss: 0.008636112324893475\n",
            "loss: 0.00863603875041008\n",
            "loss: 0.00863595586270094\n",
            "loss: 0.008635969832539558\n",
            "loss: 0.008635900914669037\n",
            "loss: 0.00863587949424982\n",
            "loss: 0.00863584503531456\n",
            "loss: 0.008635814301669598\n",
            "loss: 0.00863572210073471\n",
            "loss: 0.008635718375444412\n",
            "loss: 0.00863567367196083\n",
            "loss: 0.008635684847831726\n",
            "loss: 0.008635601960122585\n",
            "loss: 0.00863562896847725\n",
            "loss: 0.00863563735038042\n",
            "loss: 0.008635628037154675\n",
            "loss: 0.008635596372187138\n",
            "loss: 0.008635543286800385\n",
            "loss: 0.008635468780994415\n",
            "loss: 0.008635438978672028\n",
            "loss: 0.008635271340608597\n",
            "loss: 0.008635296486318111\n",
            "loss: 0.00863516516983509\n",
            "loss: 0.008635105565190315\n",
            "loss: 0.008635047823190689\n",
            "loss: 0.008634894154965878\n",
            "loss: 0.00863487459719181\n",
            "loss: 0.008634834550321102\n",
            "loss: 0.008634776808321476\n",
            "loss: 0.008634724654257298\n",
            "loss: 0.008634727448225021\n",
            "loss: 0.00863463245332241\n",
            "loss: 0.008634619414806366\n",
            "loss: 0.008634572848677635\n",
            "loss: 0.008634478785097599\n",
            "loss: 0.008634468540549278\n",
            "loss: 0.008634412661194801\n",
            "loss: 0.008634363301098347\n",
            "loss: 0.00863425899296999\n",
            "loss: 0.008634243160486221\n",
            "loss: 0.008634177036583424\n",
            "loss: 0.008634188212454319\n",
            "loss: 0.008634120225906372\n",
            "loss: 0.00863410159945488\n",
            "loss: 0.008633988909423351\n",
            "loss: 0.008634018711745739\n",
            "loss: 0.008633933961391449\n",
            "loss: 0.008633927442133427\n",
            "loss: 0.00863382127135992\n",
            "loss: 0.008633796125650406\n",
            "loss: 0.008633742108941078\n",
            "loss: 0.00863366574048996\n",
            "loss: 0.008633619174361229\n",
            "loss: 0.008633592166006565\n",
            "loss: 0.008633531630039215\n",
            "loss: 0.008633509278297424\n",
            "loss: 0.008633446879684925\n",
            "loss: 0.008633379824459553\n",
            "loss: 0.008633339777588844\n",
            "loss: 0.008633321151137352\n",
            "loss: 0.00863322988152504\n",
            "loss: 0.008633214980363846\n",
            "loss: 0.008633159101009369\n",
            "loss: 0.008633125573396683\n",
            "loss: 0.008633015677332878\n",
            "loss: 0.008633004501461983\n",
            "loss: 0.0086329635232687\n",
            "loss: 0.008632882498204708\n",
            "loss: 0.008632905781269073\n",
            "loss: 0.008632801473140717\n",
            "loss: 0.008632802404463291\n",
            "loss: 0.00863271951675415\n",
            "loss: 0.0086326589807868\n",
            "loss: 0.008632678538560867\n",
            "loss: 0.00863257609307766\n",
            "loss: 0.008632495068013668\n",
            "loss: 0.008632531389594078\n",
            "loss: 0.008632379584014416\n",
            "loss: 0.008632407523691654\n",
            "loss: 0.008632440119981766\n",
            "loss: 0.008632304146885872\n",
            "loss: 0.00863226130604744\n",
            "loss: 0.00863225944340229\n",
            "loss: 0.008632129989564419\n",
            "loss: 0.008632101118564606\n",
            "loss: 0.008632070384919643\n",
            "loss: 0.008632052689790726\n",
            "loss: 0.00863196887075901\n",
            "loss: 0.008632020093500614\n",
            "loss: 0.008631940931081772\n",
            "loss: 0.008631850592792034\n",
            "loss: 0.008631733246147633\n",
            "loss: 0.008631786331534386\n",
            "loss: 0.008631783537566662\n",
            "loss: 0.008631624281406403\n",
            "loss: 0.008631628006696701\n",
            "loss: 0.008631695993244648\n",
            "loss: 0.008631602860987186\n",
            "loss: 0.008631592616438866\n",
            "loss: 0.008631614968180656\n",
            "loss: 0.008631641045212746\n",
            "loss: 0.008631533943116665\n",
            "loss: 0.008631625212728977\n",
            "loss: 0.008631560951471329\n",
            "loss: 0.008631490170955658\n",
            "loss: 0.008631483651697636\n",
            "loss: 0.008631352335214615\n",
            "loss: 0.008631174452602863\n",
            "loss: 0.00863109901547432\n",
            "loss: 0.008630935102701187\n",
            "loss: 0.008630853146314621\n",
            "loss: 0.008630848489701748\n",
            "loss: 0.00863074790686369\n",
            "loss: 0.008630800060927868\n",
            "loss: 0.008630804717540741\n",
            "loss: 0.008630727417767048\n",
            "loss: 0.008630644530057907\n",
            "loss: 0.00863067526370287\n",
            "loss: 0.008630536496639252\n",
            "loss: 0.008630453608930111\n",
            "loss: 0.008630353957414627\n",
            "loss: 0.008630303665995598\n",
            "loss: 0.008630296215415001\n",
            "loss: 0.00863027572631836\n",
            "loss: 0.00863026175647974\n",
            "loss: 0.008630113676190376\n",
            "loss: 0.008630161173641682\n",
            "loss: 0.008630097843706608\n",
            "loss: 0.00863003358244896\n",
            "loss: 0.008629929274320602\n",
            "loss: 0.00862991064786911\n",
            "loss: 0.008629846386611462\n",
            "loss: 0.008629847317934036\n",
            "loss: 0.00862978771328926\n",
            "loss: 0.008629737421870232\n",
            "loss: 0.00862971507012844\n",
            "loss: 0.0086296321824193\n",
            "loss: 0.008629578165709972\n",
            "loss: 0.008629567921161652\n",
            "loss: 0.008629495278000832\n",
            "loss: 0.008629473857581615\n",
            "loss: 0.008629333227872849\n",
            "loss: 0.008629374206066132\n",
            "loss: 0.008629272691905499\n",
            "loss: 0.008629269897937775\n",
            "loss: 0.00862922053784132\n",
            "loss: 0.008629195392131805\n",
            "loss: 0.008629140444099903\n",
            "loss: 0.008629066869616508\n",
            "loss: 0.008629102259874344\n",
            "loss: 0.008628960698843002\n",
            "loss: 0.008628929033875465\n",
            "loss: 0.008628776296973228\n",
            "loss: 0.008628856390714645\n",
            "loss: 0.008628780022263527\n",
            "loss: 0.008628765121102333\n",
            "loss: 0.00862871389836073\n",
            "loss: 0.008628619834780693\n",
            "loss: 0.008628609590232372\n",
            "loss: 0.008628472685813904\n",
            "loss: 0.008628476411104202\n",
            "loss: 0.008628448471426964\n",
            "loss: 0.008628404699265957\n",
            "loss: 0.0086283627897501\n",
            "loss: 0.00862832646816969\n",
            "loss: 0.008628316223621368\n",
            "loss: 0.008628192357718945\n",
            "loss: 0.00862816721200943\n",
            "loss: 0.008628156036138535\n",
            "loss: 0.00862809643149376\n",
            "loss: 0.008627988398075104\n",
            "loss: 0.008627958595752716\n",
            "loss: 0.008628004230558872\n",
            "loss: 0.008627889677882195\n",
            "loss: 0.008627868257462978\n",
            "loss: 0.00862781424075365\n",
            "loss: 0.008627776056528091\n",
            "loss: 0.008627639152109623\n",
            "loss: 0.008627643808722496\n",
            "loss: 0.008627663366496563\n",
            "loss: 0.00862758606672287\n",
            "loss: 0.008627539500594139\n",
            "loss: 0.008627515286207199\n",
            "loss: 0.008627488277852535\n",
            "loss: 0.008627411909401417\n",
            "loss: 0.008627375587821007\n",
            "loss: 0.00862735603004694\n",
            "loss: 0.008627291768789291\n",
            "loss: 0.008627256378531456\n",
            "loss: 0.008627209812402725\n",
            "loss: 0.008627158589661121\n",
            "loss: 0.008627140894532204\n",
            "loss: 0.008627086877822876\n",
            "loss: 0.0086269685998559\n",
            "loss: 0.008626941591501236\n",
            "loss: 0.00862689595669508\n",
            "loss: 0.008626860566437244\n",
            "loss: 0.008626783266663551\n",
            "loss: 0.008626749739050865\n",
            "loss: 0.008626648224890232\n",
            "loss: 0.008626663126051426\n",
            "loss: 0.008626683615148067\n",
            "loss: 0.00862659141421318\n",
            "loss: 0.008626557886600494\n",
            "loss: 0.00862656719982624\n",
            "loss: 0.008626500144600868\n",
            "loss: 0.008626489900052547\n",
            "loss: 0.008626440539956093\n",
            "loss: 0.008626333437860012\n",
            "loss: 0.008626371622085571\n",
            "loss: 0.008626330643892288\n",
            "loss: 0.008626137860119343\n",
            "loss: 0.008626149035990238\n",
            "loss: 0.008626103401184082\n",
            "loss: 0.008625981397926807\n",
            "loss: 0.008626021444797516\n",
            "loss: 0.008625890128314495\n",
            "loss: 0.008625856600701809\n",
            "loss: 0.008625723421573639\n",
            "loss: 0.00862573366612196\n",
            "loss: 0.008625668473541737\n",
            "loss: 0.008625607937574387\n",
            "loss: 0.00862556416541338\n",
            "loss: 0.008625534363090992\n",
            "loss: 0.008625498041510582\n",
            "loss: 0.008625440299510956\n",
            "loss: 0.0086253946647048\n",
            "loss: 0.00862541701644659\n",
            "loss: 0.008625360205769539\n",
            "loss: 0.00862518697977066\n",
            "loss: 0.008625204674899578\n",
            "loss: 0.008625137619674206\n",
            "loss: 0.008625142276287079\n",
            "loss: 0.00862500537186861\n",
            "loss: 0.008624976500868797\n",
            "loss: 0.008624903857707977\n",
            "loss: 0.008624933660030365\n",
            "loss: 0.00862486008554697\n",
            "loss: 0.008624868467450142\n",
            "loss: 0.008624738082289696\n",
            "loss: 0.008624759502708912\n",
            "loss: 0.008624625392258167\n",
            "loss: 0.00862463191151619\n",
            "loss: 0.008624584414064884\n",
            "loss: 0.008624589070677757\n",
            "loss: 0.00862444844096899\n",
            "loss: 0.008624461479485035\n",
            "loss: 0.00862438790500164\n",
            "loss: 0.008624320849776268\n",
            "loss: 0.008624239824712276\n",
            "loss: 0.008624203503131866\n",
            "loss: 0.008624190464615822\n",
            "loss: 0.008624192327260971\n",
            "loss: 0.008624095469713211\n",
            "loss: 0.00862399023026228\n",
            "loss: 0.008624058216810226\n",
            "loss: 0.008623938076198101\n",
            "loss: 0.008623959496617317\n",
            "loss: 0.008623837493360043\n",
            "loss: 0.008623900823295116\n",
            "loss: 0.008623774163424969\n",
            "loss: 0.008623745292425156\n",
            "loss: 0.008623667061328888\n",
            "loss: 0.008623703382909298\n",
            "loss: 0.008623581379652023\n",
            "loss: 0.008623560890555382\n",
            "loss: 0.008623524568974972\n",
            "loss: 0.008623499423265457\n",
            "loss: 0.00862341932952404\n",
            "loss: 0.00862336065620184\n",
            "loss: 0.008623302914202213\n",
            "loss: 0.008623380213975906\n",
            "loss: 0.008623305708169937\n",
            "loss: 0.008623305708169937\n",
            "loss: 0.008623276837170124\n",
            "loss: 0.008623247966170311\n",
            "loss: 0.008623188361525536\n",
            "loss: 0.008623273111879826\n",
            "loss: 0.008623254485428333\n",
            "loss: 0.0086232740432024\n",
            "loss: 0.008623290807008743\n",
            "loss: 0.008623162284493446\n",
            "loss: 0.008623105473816395\n",
            "loss: 0.00862298347055912\n",
            "loss: 0.008622732944786549\n",
            "loss: 0.008622702211141586\n",
            "loss: 0.008622564375400543\n",
            "loss: 0.008622466586530209\n",
            "loss: 0.008622474037110806\n",
            "loss: 0.00862249918282032\n",
            "loss: 0.008622483350336552\n",
            "loss: 0.008622447028756142\n",
            "loss: 0.008622372522950172\n",
            "loss: 0.008622315712273121\n",
            "loss: 0.008622238412499428\n",
            "loss: 0.008622168563306332\n",
            "loss: 0.008622071705758572\n",
            "loss: 0.008622046560049057\n",
            "loss: 0.008621995337307453\n",
            "loss: 0.008621945045888424\n",
            "loss: 0.008621933870017529\n",
            "loss: 0.008621800690889359\n",
            "loss: 0.008621837943792343\n",
            "loss: 0.008621815592050552\n",
            "loss: 0.008621693588793278\n",
            "loss: 0.008621635846793652\n",
            "loss: 0.008621588349342346\n",
            "loss: 0.00862161722034216\n",
            "loss: 0.008621517568826675\n",
            "loss: 0.00862149614840746\n",
            "loss: 0.008621471002697945\n",
            "loss: 0.008621402084827423\n",
            "loss: 0.008621306158602238\n",
            "loss: 0.008621301501989365\n",
            "loss: 0.008621221408247948\n",
            "loss: 0.008621159009635448\n",
            "loss: 0.00862115528434515\n",
            "loss: 0.008621109649538994\n",
            "loss: 0.008621115237474442\n",
            "loss: 0.008621026761829853\n",
            "loss: 0.008620981127023697\n",
            "loss: 0.008620893582701683\n",
            "loss: 0.008620832115411758\n",
            "loss: 0.008620798587799072\n",
            "loss: 0.00862066075205803\n",
            "loss: 0.008620684035122395\n",
            "loss: 0.008620694279670715\n",
            "loss: 0.008620675653219223\n",
            "loss: 0.00862058438360691\n",
            "loss: 0.00862053595483303\n",
            "loss: 0.00862050335854292\n",
            "loss: 0.008620431646704674\n",
            "loss: 0.00862042885273695\n",
            "loss: 0.0086203096434474\n",
            "loss: 0.008620324544608593\n",
            "loss: 0.008620254695415497\n",
            "loss: 0.008620248176157475\n",
            "loss: 0.008620131760835648\n",
            "loss: 0.008620092645287514\n",
            "loss: 0.008620038628578186\n",
            "loss: 0.008620074018836021\n",
            "loss: 0.008619971573352814\n",
            "loss: 0.008620008826255798\n",
            "loss: 0.00861987005919218\n",
            "loss: 0.008619807660579681\n",
            "loss: 0.008619767613708973\n",
            "loss: 0.008619751781225204\n",
            "loss: 0.008619692176580429\n",
            "loss: 0.008619624190032482\n",
            "loss: 0.008619648404419422\n",
            "loss: 0.008619523607194424\n",
            "loss: 0.008619477041065693\n",
            "loss: 0.008619390428066254\n",
            "loss: 0.00861940998584032\n",
            "loss: 0.008619343861937523\n",
            "loss: 0.008619331754744053\n",
            "loss: 0.008619277738034725\n",
            "loss: 0.008619206957519054\n",
            "loss: 0.008619142696261406\n",
            "loss: 0.00861913152039051\n",
            "loss: 0.008619021624326706\n",
            "loss: 0.008619038388133049\n",
            "loss: 0.008618989959359169\n",
            "loss: 0.008618921041488647\n",
            "loss: 0.008618902415037155\n",
            "loss: 0.008618858642876148\n",
            "loss: 0.008618796244263649\n",
            "loss: 0.008618731051683426\n",
            "loss: 0.008618779480457306\n",
            "loss: 0.008618643507361412\n",
            "loss: 0.008618682622909546\n",
            "loss: 0.008618595078587532\n",
            "loss: 0.00861852616071701\n"
          ]
        }
      ],
      "source": [
        "def closure():\n",
        "    \n",
        "    l = loss(x)\n",
        "    losses.append(l)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    l.backward()\n",
        "    print(f\"loss: {l}\")\n",
        "    return l\n",
        "\n",
        "for i in range(6000):\n",
        "    optimizer.step(closure)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if cos is the same with O.D.E\n",
        "x = torch.unsqueeze(torch.linspace(-4,4, 2000), dim=1) \n",
        "\n",
        "dy = torch.cos(x)\n",
        "method_dy = net1(x)*net2(x)\n",
        "method_dy = method_dy.detach().numpy()\n",
        "plt.plot(x,dy, label = 'the ode')\n",
        "plt.plot(x,method_dy, label ='numerical ode')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RcafhZuWFQFQ",
        "outputId": "2cb75466-893d-4a02-e3e2-fbc64369d3b1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hU1dbA4d+emfSEAEmAQICE3ltC7x1EQCkqNtCr2EWuBbwWvCj2BoJyEQHbByooIEUR6Z0gnQQCIUCoSSghvcz+/jiTBgmkzOTMTPb7PDxTcmbOGiArK2vvs7eQUqIoiqI4P4PeASiKoijlQyV8RVGUCkIlfEVRlApCJXxFUZQKQiV8RVGUCsKkdwC34u/vL4ODg/UOQ1EUxWHs2bMnXkoZUNjX7DrhBwcHEx4erncYiqIoDkMIcaqor6mWjqIoSgWhEr6iKEoFoRK+oihKBWHXPXxFUcpfZmYmsbGxpKWl6R2Kcgvu7u4EBQXh4uJS7NeohK8oSgGxsbH4+PgQHByMEELvcJRCSClJSEggNjaWkJCQYr9OtXQURSkgLS0NPz8/leztmBACPz+/Ev8WphK+oig3Ucne/pXm30glfEWxhoxk2PU1xB/XOxJFKZJK+IpiDX+9Categu+Ga8lfKbWrV6/y5Zdf5j7esGEDd955p83P6+3tbfNz6E0lfEUpq6wMOPgL+ARCYiwcXqp3RA7txoSvWI9K+IpSVhcOQNo1GPQ+VK0PBxbpHZFDmzx5MidOnKBNmza8/PLLACQlJTFq1CiaNGnCAw88QM5OfXv27KFnz56EhoYycOBAzp8/f9P7xcTE0KdPH1q1akXfvn05ffo0ACdPnqRz5860bNmS119/vcBrPvroI9q3b0+rVq2YMmWKjT9x+VHTMhWlKFLC+X3g1wDcfIo+7vx+7bZWO2g6FLbPgvQkcHP8FsF/fz/MkXOJVn3PZjUrMWVo8yK//v7773Po0CH27dsHaC2dvXv3cvjwYWrWrEnXrl3ZunUrHTt25LnnnmPZsmUEBATw008/8dprrzFv3rwC7/fcc88xduxYxo4dy7x583j++edZunQpEyZM4KmnnuLhhx9m1qxZucevWbOGqKgodu3ahZSSYcOGsWnTJnr06GHVvwc9qApfUYqy6WOY0wsWDAFzdtHHXTwE7r7gWxvq9wFzJpzaWm5hVgQdOnQgKCgIg8FAmzZtiImJ4ejRoxw6dIj+/fvTpk0b3nnnHWJjY2967fbt27n//vsBeOihh9iyZQsAW7duZcyYMbnP51izZg1r1qyhbdu2tGvXjsjISKKiosrhU9qeqvAVpTApl2HLp2AwaRX8mZ1Qt0vhx145BVXrgRBQpxOYPCB6AzQaWK4h28KtKvHy5ObmlnvfaDSSlZWFlJLmzZuzffv2Ur9vYVMbpZS8+uqrPPHEE6V+X3ulKnxFKcyhJZCZAuNWgtEVjq4u+thrZ7TqHsDkBrVCtR8QSqn4+Phw/fr12x7XuHFj4uLichN+ZmYmhw8fvum4Ll26sGiRNq7y448/0r17dwC6du1a4PkcAwcOZN68eSQlJQFw9uxZLl26VLYPZSdUwleUwpxYD5XrahV79eZaL78wUsLV01C5Tt5ztTtovxVkppZPrE7Gz8+Prl270qJFi9xB28K4urqyePFiJk2aROvWrWnTpg3btm276bgvvviC+fPn06pVK77//numT58OwPTp05k1axYtW7bk7NmzuccPGDCA+++/P3dAd9SoUcX6AeQIRM5otz0KCwuTagMUpdxlZ8GHIdBiBAydDr9PgMO/waRTWtsmv6RL8HFDGPwhdLS0AI7+AQvvhUdWF90GsmMRERE0bdpU7zCUYijs30oIsUdKGVbY8arCV5Qbnd0D6YlQr7f2OKCJNu0yJeHmY69ZBgl9g/KeC2qv3aq2jmJnVMJXlBtFrwcEhFim4VUJ1m6vxNx8bHK8dutVLe85Lz/wawhndtkwSEUpOZXwFeVG0RugZhvwrKo9rmJZfrbQhB+n3Xr5F3y+dketwrfjlqlS8aiEryj5pV+H2N157RzIG5C9evrm41NyKvwbE34HrQWUcMI2cSpKKVgl4Qsh5gkhLgkhDhXxdSGEmCGEOC6EOCCEaGeN8yqK1cVsAXMW1OuV95yrJ7j6aAO0N0qOA5M7uN5wVW2dTtrtmR22ilRRSsxaFf4CYNAtvj4YaGj5Mx74ykrnVRTrOrFeu3AqJ2Hn8K4GSRdvPj45ATz9b56949cQPKrA6dJfFKQo1maVK22llJuEEMG3OGQ48J3U5oDuEEJUFkIESilvXulIUfQUvV6bSmnKu7LzYmIaroYqpJ07zfxVEaRmaMsseLoZeSj2FJWMlUm/nk6AT95rMBigdic4rWbqOKLly5dz5MgRJk+eXOLXBgcHEx4ejr+//+0PvsGCBQsIDw9n5syZJX5tcZTX0gq1gDP5Hsdanrsp4QshxqP9FkCdOnVu/LKi2M61sxB/DHPbh9gVncAfhy7w15GLnL2aykwXI03EGRbExeDlagQgOT2bO4znOS59GDdtLXWqetK/WXUGtahBWN0qiDod4dhqbSbPjT1+xW5lZWUxbNgwhg0bpncoVmd3g7ZSyjlSyjApZVhAQIDe4SgVSPqxvwEYv8WH++bsYOGu0zSrWYk37mxGhxaNqeeRzNG3B7H3zQHsfXMAR98ZRIuqkpYN6vL6kKY0qObN99tPMXr2dgZ8tok/rltm96j5+CUSExND06ZNefzxx2nevDkDBgwgNVW7arlXr17kXIwZHx9PcHAwoFXGd911F/379yc4OJiZM2fy6aef0rZtWzp16sTly5cBOHHiBIMGDSI0NJTu3bsTGRkJwLhx43jyySfp2LEjr7zyCgsWLODZZ58F4OLFi9x99920bt2a1q1b517Ne9dddxEaGkrz5s2ZM2fObT/XwoULadmyJS1atGDSpEm5z8+fP59GjRrRoUMHtm7NW3QvLi6OkSNH0r59e9q3b1/ga6VVXhX+WaB2vsdBlucURXeZ2WYW7T5DtT8X0U76Eu/VgM8GhDCgWQ283CzfIpvqQMQ1yEoHF3dAW3jLmHEdPz9/Hutej8e61yMpPYtVB8/z3fYYJmyUHHQ3cWLnGho2HIzJaHf11e2tngwXDlr3PWu0hMHv3/KQqKgoFi5cyNdff80999zDkiVLePDBB2/5mkOHDrF3717S0tJo0KABH3zwAXv37mXixIl89913vPDCC4wfP57Zs2fTsGFDdu7cydNPP826desAiI2NZdu2bRiNRhYsWJD7vs8//zw9e/bkt99+Izs7O3eNnXnz5lG1alVSU1Np3749I0eOxM/Pr9DYzp07x6RJk9izZw9VqlRhwIABLF26lI4dOzJlyhT27NmDr68vvXv3pm3btgBMmDCBiRMn0q1bN06fPs3AgQOJiIgo7t9yocor4S8HnhVCLAI6AtdU/16xB3tOXWHSkgNEX0pkn8dBMhr0Y+lD3W8+0NPyjZx6GVxq5j2fnghulXIferuZuCesNqNDg9h+IoHjixqRdmILw2Zu5YORrWgZ5GvjT+QcQkJCaNOmDQChoaHExMTc9jW9e/fGx8cHHx8ffH19GTp0KAAtW7bkwIEDJCUlsW3bNkaPHp37mvT09Nz7o0ePxmg03vS+69at47vvvgO0lTp9fbV/wxkzZvDbb78BcObMGaKioopM+Lt376ZXr17kdC0eeOABNm3aBFDg+XvvvZdjx44BsHbtWo4cOZL7HomJiSQlJZVpK0arJHwhxEKgF+AvhIgFpgAuAFLK2cAq4A7gOJACPGKN8ypKaaVlZvPhH0eZv+0kNX09WDjEjUp/J0KbIYW/wL2ydpt6FSpZEn5mGmRnFLo5ihCCLg38kR36I7d/SeL1RIbP2sL4HvV5cUAjXByl2r9NJW4rNy6HnNPSMZlMmM1mANLS0op8jcFgyH1sMBjIysrCbDZTuXLl3I1VbuTl5VXs+DZs2MDatWvZvn07np6e9OrV66Z4yspsNrNjxw7c3d2t9p5W+V8npRwjpQyUUrpIKYOklN9IKWdbkj1S84yUsr6UsqWUUq2IpugmJj6Zu2ZtZd7WkzzUqS5/TuxBR/M+QBS84Co/D0vCT7ua91y6ZSco96KrdlGvBwaZyZ93GbgnrDazN55g9OztxF5Jsc6HqWCCg4PZs2cPAIsXLy7RaytVqkRISAi//PILoK17v3///tu+rm/fvnz1lTaTPDs7m2vXrnHt2jWqVKmCp6cnkZGR7Nhx6+stOnTowMaNG4mPjyc7O5uFCxfSs2dPOnbsyMaNG0lISCAzMzM3NtBW7fziiy9yHxf1g6okHKTMUBTrWHP4AkO/2MKFxDTmP9KeqcNb4O1mgqi/tOUUvAr/lbxAhZ8jzZLw87V0blK3G5g88DqzgfdHtmLW/e04fimJO6ZvZktUvHU+VAXy0ksv8dVXX9G2bVvi40v+9/fjjz/yzTff0Lp1a5o3b86yZctu+5rp06ezfv16WrZsSWhoKEeOHGHQoEFkZWXRtGlTJk+eTKdOnW75HoGBgbz//vv07t2b1q1bExoayvDhwwkMDOStt96ic+fOdO3atcDKlzNmzCA8PJxWrVrRrFkzZs+eXeLPeyO1PLJSYczfepKpK47QspYvXz7QjqAqntoXrp2Fz5pB79ehZxHrr1+Ohhlt4a6voI22XR5n98DXfWDMImg8uOgT/zAKrpyE57TK9FRCMo9/F050XDLv3t2Se9rXLvq1OlDLIzsOtTyyotzAbJZMW3mE//5+hH5Nq/PT+M55yR4gYrl22/yuot+ktBU+QIN+kHAcLp8EoK6fF4uf6kLn+n68suQAn6w5ij0XXorzUAlfcWpms2Tyrwf4evNJxnauy+wHQ/FwvWEmxqFfoXoL8G9Y9Bvl9OkL7eHfJuHn7G0b8XvuU5XcXZg3rj33htXmi3XHeWdlhEr6is2phK84rZxk/3N4LM/3acBbw5pjNNyw5s2lCIjdBa3uufWbGYzg5lu6Cr9qCNRsB4cKDjK6GA28P7Il47oE882Wk0xZfhiz2T6SvvrhY/9K82+kEr7ilAok+74Nmdi/EeLGBc4Adn8DRjdoc+uLegDw8C1dhQ/QcpS2z218VIGnhRBMGdqMx7uH8N32U7y98ojuydbd3Z2EhATd41CKJqUkISGhxFM2y+vCK0UpV+//EZlb2U/s17DwZJ+cAPsXanvXFjU7Jz83X229/BzFrfABmo+ANW/AngUwcFqBLwkh+M8dTck2w7ytJ/HzcuXZPrdoL9lYUFAQsbGxxMXF6RaDcnvu7u4EBQXd/sB8VMJXnM7czdHM2RTNw53rFl3ZA2z5FDJToNvE4r2xm3fBhJ+eqK2Db7j56sybVArUBoX/+Q56Tb7pYi0hBK8PacqVlAw+XnOMyp6uPNipbvHisjIXFxdCQkJ0ObdiW6qloziV5fvP8c7KCAa3qMGUoc2LTvbnD8DO2doUy4DGxXtzV2/ISMp7nJEErsW/OpNOT2s/JHbPLfTLBoPgw1Gt6NOkGm8sO8TaI4Wsv68oZaASvuI0/jl9hZd+3k+H4Kp8dm+bmwdocyQnwOJHtY1L+r9d/BO4ekFGct7jzFRw8Sz6+BsFhUHDAbDpk8J3z0IbyJ11fzta1PRlwqK9RF5ILP77K8ptqISvOIWLiWk8+f0eavi6M+fhUNxdimizxB2Db+/U9qcdPT9vo/LicPOG9PwVfkrJKnyAge9CViqsmFjkBucerka+fjgMLzcTj30bTkJSeqHHKUpJqYSvOLy0zGzGf7+HrPRkFgyrSuXLB+DEOohYAQd+0QZKt8+Cnx6CLztB4jm4/ydtZ6uScPUp2NLJTAYXj5K9h39D7beKyBXw99Qik34NX3e+fjiMuOvpPPnDHjKyzCU7j6IUQg3aKg5NXjjEtl9m8kHcFhobziIW3SIx+gRCxyeh2wvaHrUl5eqlJXwptT1sM1JK1tLJ0ekpiIvQBo2vxcKg9wudJdS6dmU+Gt2a5xfu5f3Vkbw5tFnJz6Uo+aiErzimS5Gwdgri2B90l0bOVg1DtBoDfg20No2rN7h6gouXVoW7eGibihc1iFscbt4gzVrv3tVTm+FTmq0LhYChM6BSLdj0kba0Q9Oh2kqdtTtA1franrjAsNY1+efUFeZtPUn74CoMbhlY+viVCk8lfMWxmM2w9XPY8B7ZJg9mmO8lstYovny8PxQ1SGstrpaNJzKS8hJ+aSp80JJ+r8nQ/G7Y8aW27MJBy9K4bpUgsDXUagc12/KfLm3Ze6Yyryw+QNPASgT7l3DcQFEsVMJXHEdGMvw6HiJXkNVkOPfFjiIm24NV93cvekaONeUk/PTrWksoI0VL/GUR0BiGTochn0FcJJz7B87+o91u/xLMmbgCP9dox1uiG8/84MaSZ7oXPSitKLegEr7iGNIS4fu7tUQ46ANej+3MnoRYvnu0DdV8rLcj0C255VT4lqmZmSlay8gaDAao3kz709ayzENWOlw8DKe24rbnW95jBkcuL2PR4smMG3O/dc6rVChqlo5i/9KT4MfRcH4f3PM9KzyHsSg8lqd61qd7w4DyiyNnCmbOwG1GKWbplITJTWvrdHkOnt0No+YR6J7Ow5FPc2bxq5CdZbtzK05JJXzFvpmzYfEj2oqWI7/hUq1+vL70EK1rV2Zi/0blG4trvgo/OwNkdtlbOsUlBLQYifvzu/jTpQ+1D31J5o/3FLwuQFFuQyV8xb6tewei1sAdHyObDefVXw+SmpHNJ6Nbl/9G4CZL6ygzNa+tY62WTjF5ePsSNG4+r2U9hjF6PXLBEEi9Uq4xKI5LJXzFfh1eqs1VDx0H7f/FL+Gx/B15iVcGNaFBNe/yjydnRk5Wmpb0ofwq/HxaBvlSs+9TPJbxb8wXD2tbKOZf1E1RiqASvmKfrp2F35+HWmEw+CNir6QwdcUROoZU5ZEuwfrE5JKvws9MsTynzxTJJ3vW52pQH16UE5Hn9sLCMZCVoUssiuNQCV+xP2YzLH1KG5QcMQdpdGHSkgNIKfl4dGsM5TEFszAmywBtVlpeS0eHCh/AaFlZc1VGO76r/grEbIbVLxe5VIOigEr4ij3aPRdObtQ2CvGrzy97Ytl6PIFX72hK7ar6JFigiArfhrN0bqNBNR+e79uAKTEtiW78uLZmUBFLLysKqISv2JvE89qiYvX7QOg44pPSmbYygvbBVbi/Qx19YytQ4evb0snxRM/6NAusxJgT/cms1w/+/I+21r+iFEIlfMW+rHlNm/J4x8cgBG+vOEJKRhbvjWipXysnh8EARteCFb5OLZ0cLkYDH45qRXxKNu+6Pg8eVWHJvwqu268oFirhK/YjegMcWgLd/w1+9dlw9BLL9p3j6V4NaFDN57YvLxcmD63Cz0rLe6yzFrV8Gd+jHvP3JXG404faRul//kfvsBQ7ZJWEL4QYJIQ4KoQ4LoSYXMjXxwkh4oQQ+yx/HrPGeRUnkp0Fq16GKiHQ9QVSMrJ4fekh6gd48XTv+npHl8fFXavwcxO+m77xWEzo25DaVT2YsKsy2Z2f1fr50Rv0DkuxM2VO+EIIIzALGAw0A8YIIQpbuPsnKWUbyx81sqQUtPc7iD+mDdS6uPP52ihir6Ty3ohWuJnsaKEwk7ulwk/Pe2wH3F2MTB3WguOXkvjGNAaq1oPfJ+SNNSgK1qnwOwDHpZTRUsoMYBEw3Arvq1QUGcmw4X2o3Qka38Gxi9f5ZstJxnSoTYeQEmxBWB5cPLT+fW7Ct48KH6B3k2oMbF6dzzacIa73R3AlBja8q3dYih2xRsKvBZzJ9zjW8tyNRgohDgghFgshahf1ZkKI8UKIcCFEeFxcnBXCU+ze9lmQdBH6T0UCU5YdxtvNxCsDm+gd2c1M7pCZv4dvHxV+jjeHNgfgtb2Vod1Y7e/2wkGdo1LsRXkN2v4OBEspWwF/Ad8WdaCUco6UMkxKGRYQUI4rISr6SIqDrdOhyZ1QpyMrD55ne3QCLw1sTBUvV72ju5mLR76WjgCji94RFVCrsgcT+jVkzZGLbKz7LLhXhtWT1AVZCmCdhH8WyF+xB1meyyWlTJBSWn4HZi4QaoXzKs5g2wytRdJ3CikZWUxbGUGzwEr6z7kviinfoK3JvWxbJtrIo11DaFjNm9f+iCWz1+twaisc/k3vsBQ7YI2EvxtoKIQIEUK4AvcBy/MfIITIvxHnMCDCCudVHF1yvHZlaItRENCIWeuPc/5aGlOHNy+fHaxKI3+Fb0f9+/xcTQamDm9B7JVU5iR1hRotYc0bagBXKXvCl1JmAc8Cf6Il8p+llIeFEFOFEMMshz0vhDgshNgPPA+MK+t5FSewfZZWLfd4iZj4ZL7edJIRbWsRFmxnA7X53Vjh26nO9f0Y3KIGMzfEkND9HUiM1VpnSoVmlR6+lHKVlLKRlLK+lHKa5bk3pZTLLfdflVI2l1K2llL2llJGWuO8igNLuQy75mibeAc0ZuqKI7iaDEwebIcDtfkVqPDtcIwhn//c0ZRsKZl2qLL297xtBly/qHdYio7UlbaKPnZ8pW0V2ONl1kdeYl3kJZ7v24Bqley3aga0Nk5Wut1X+AC1q3ryWLcQft17lsNNJ2hLVmz6UO+wFB2phK+Uv7RrsHM2NB1Gln8Tpq2KINjPk3FdQvSO7PaMblritOMefn5P925AgI8br21MQbYbq12Bm3BC77AUnaiEr5S/Pd9CeiJ0m8jC3Wc4fimJV+9oiqvJAf47mlzz1tKx8wofsFzP0Jh9Z66y2u8hbfG39dP0DkvRiQN8hylOJTtTq+6Du3PdryWf/3WMDiFVGdCsut6RFY/J3VLhO0bCBxjZLohWQb78d30CGe2f1BaoO7dP77AUHaiEr5Svw79B4lno8hxfbjhBQnIGrw9pirDD+eyFMloGatOTHKKlA2AwCKYMbcbFxHTmZN2pLaG87m29w1J0oBK+Un6k1GaK+Dcm1r8r32zRpmG2Cqqsd2TFl5Pk0685TIUPEFq3Kne2CmTm9ktcD3sGjq+FM7v1DkspZyrhK+Xn5EZtXZfOz/DRmigE8NLAxnpHVTJGS8JPu+YwFX6OVwY2Idss+SihG3j6wcb39Q5JKWcq4SvlZ9tM8Apgf9WBLNt3jse716NmZf03ECmRnCSfluhQFT5AHT9PHuoUzA97E4hrNV6r8mP36B2WUo5UwlfKx8UjcPwvZIfxvP1HNP7ebjzZy442Nimu3KpeOlyFD/BcnwZ4uZmYcq6L1stXVX6FohK+Uj52fgUmD/72upPwU1d4cUAjvN1MekdVcsZ8V9c6WIUPUMXLlad7NWDVseucavIviFqjqvwKRCV8xfZSr8CBXzC3HM27Gy7RqLo394QVuSWCfctf1TtghQ/wSNdgavq688qpDkiPKrDxA71DUsqJSviK7e37P8hKZY3XUKLjk3l5YBP7XQ3zdvIneaNjJnx3FyMvDmjMznOZRIaMhag/4ayq8isClfAV2zKbYfdczEEdeGuXkXZ1KtOvaTW9oyo9o+NX+AB3ta1F08BKvHCyvVblb/pY75CUcqASvmJb0evgcjQbKg3nQmIarwxq4jgXWRWmQEvH8Xr4OYwGwauDm3D0imBvjXvg6CptYF1xairhK7a1ay5mT38mRYTQs1EAner56R1R2RQYtLXv5ZFvp0ejALo39GdiTEekixds/VzvkBQbUwlfsZ0rp+DYH+yqcidxqfCyo11kVZj8Vb0DV/g5Jg1qwqlUd/b4D4eDi+FKjN4hKTakEr5iO3vmI4XgtTPtubNVIC1q+eodUdmZHHta5o1a1PLlzlaBvHS2O1IYYNsXeoek2JBK+IptZKbBP98RWakbMVlVeXGAE1T3UHDQ1ujYLZ0cLw5ozJmsyvxTZRD8873aFcuJqYSv2MaRpZCSwAcJXbknrDYh/l56R2QdTjJom1+Ivxf3hAUx6UJvpDkTdnypd0iKjaiEr9jGrq+55FqbHbRkQt+GekdjPQUSvnNU+ADP923IGVGT/T49Yfc3kHpV75AUG1AJX7G+c3vhbDhfpfRibJd61PB1jkoYuGEevvN8rkBfD8Z2Cea1+P6QcR12z9U7JMUGVMJXrG/3XNKFO3+a+vCUIy6QditGl3z3nafCB3iqZ31OuzTgkEd7yybzKXqHpFiZSviKdaVcxnzgF5ZkduH+Hi2p7OlcSZH8F405UYUP2sJqj/eox9SrgyAlHvb+oHdIipWphK9Yldz7A4bsdH53G8IjXUP0Dse2HHhphaI82i2EEx6tOOraXNudLDtT75AUK1IJX7Ees5m07V+z29yIQX374eWIyx+XhBMmfG83E8/2bcj7SXfAtTNw8Be9Q1KsSCV8xWrMx//GI+k0K93uZEyHOnqHY3sOulrm7dzfsQ7HfDpz0hiC3PK5tgCe4hRUwlesJm7dTOKkL20GPYSrqQL813LCCh/AzWTkhf6N+Cx1CCL+KBxdqXdIipVUgO9KnVy/oG3YXUFkxp8k4MJG1rgPYmhbJ+/d53DShA8wol0QkX59OSdqIDd/ClLqHZJiBVZJ+EKIQUKIo0KI40KIyYV83U0I8ZPl6zuFEMHWOK9dm94GZnfTO4pyE7VqOmYpqNP/Gcfd3KSknGxaZn5Gg+DfA5syM2MI4tw/cHKj3iEpVlDmhC+EMAKzgMFAM2CMEKLZDYf9C7gipWwAfAY4/55qWanabQWYy5yWmkzN6MXsdu9Et9BWeodTfhx5Xf9iGNi8Bsdq3Ek8lcne9Kne4ShWYI0KvwNwXEoZLaXMABYBw284ZjjwreX+YqCvcOhdMEogI0nvCGxu+/K5VOY6lXs85dibmygFCCGYOLgVczIHY4zZWDG2QVz3DvzyiN5R2Iw1En4t4Ey+x7GW5wo9RkqZBVwDCt0JQwgxXggRLoQIj4uLs0J4OshMzbvv5An/WmomARHfcs5Um6ZdhuodjmJlXRv4E133XhLxImvjJ3qHY3ubPoLDvzrtzCS7G7SVUs6RUoZJKcMCAgL0Dqd00q7l3c9I1i+OcvD7qhW04AR0eNzpWxy5HlsHDy/XO4py89zgtszPGoDp2Eq4FKl3OOUj0zm/b62R8M8CtfM9DrI8V6A630kAACAASURBVOgxQggT4AskWOHc9il/knfihB93PR2v/fNJEx7U7OG8vwbfJCgU6vXUO4py07p2Zc40fJgU6UbahgpQ5YPTft9aI+HvBhoKIUKEEK7AfcCN5c9yYKzl/ihgnZROPM8rM99ArRO3dOat2c0dYhsZze8B90p6h6PY0JOD2/NTdm9cIpbA1dN6h2Mb+VOSSviFs/TknwX+BCKAn6WUh4UQU4UQwyyHfQP4CSGOA/8Gbpq66VTyz8xJd86Ef+ZyCoZ9P+AmMqnU4ym9w1FsrEE1H841+xfZZkha/5ne4dhG/kIt/bp+cdiQVRY7kVKuAlbd8Nyb+e6nAaOtcS6HkL//l5WuXxw29PmaCCYa/iIjqAuu1ZrqHY5SDsbd0Z3lkd0ZfuAH6P8f8HbQMbai5C/OVIWvFFv+Cj87Q784bCTifCLXDq4kSMTj2vkJvcNRykmtyh5cavUkRnMml9dN1zsc68vOV5w5aStWJXxbyHTuhP/xn0d5xGUtZu8a0GSI3uEo5ejeQX34i46475tXcDaaM8jK972a6ZwXTKqEbwv5fx10svXEd8dc5sTR/XRlP4awRwvuAKU4PT9vNxLaPounOZlza2fpHY515a/ws5yvUAOV8G3DSSt8KSUfrI7kCY/1SIMJQsfe/kWK0xk2eDDbaY3XP/8reJGho8v/vZrtnGNvKuHbgpP28NcfvcThU+cZadiIaDoMfGroHZKiA283E1faPYuv+SrH1/xP73CsJ39V76STLVTCt4XMZDBYJkA5ScI3myUf/nGUxyrtwjXrOnQYr3dIio76Dh7BIdEInz1fIp2l/VGgwneSz3QDlfBtISMFXL3A4OI0/3GW7T/L0QvXGO/6JwS2gTqd9A5J0ZGbi4mrYc9T3XyRQ6ucpMov0MNXFb5SXJnJ4OqtbZDhBIO2GVlmPllzjIf9o/BJOgmdn6k46+YoReo86AEiDQ3x3zuDrIw0vcMpu/y/qTjB921hVMK3hYwUcPHUZrA4QYW/cNdpYq+k8oL3WvAJhGZ36R2SYgeMRgNJnV8mUF5i3+9f6R1O2alBW6VUMpLB1VPbEcnBE35yehZfrIvintpXqXJhq7Yqpsl5d3pSSia072iOmhpT6+As0tIcfMZOthq0VUojMwVcvCwJ37F/NZy35STxSRm8Unk9mDwgtAKtiqncljAYyO4xiUDi2L10pt7hlE3+JO/ghVpRVMK3hdwK38WhK4XLyRnM2RTNyEYu+EcvgzZjwLOq3mEpdqZZ9xFEuTalQeRsric78Bo0qsJXSiXT0sM3mMCcpXc0pfbFuiiSM7L4T7Vt2jdDp6f1DkmxR0Jg7PMfAoln5xIHXmMnJ+G7+qgKXymB3GmZjpvwY+KT+X77KR4M9cfv8LfQcCD4N9Q7LMVO1es4lBPuzWl+Yi4XLzvoGjs5Sd7NW1X4SglkJlsqfCOYs/WOplQ+/DMSV5OBl/13Qupl6DZR75AUeyYE3gPfIFAksP2XT/WOpnRypmW6qQpfKYmMFK2H76AV/p5Tl1l18AJPdquNzz+zoU4XqNtZ77AUO1e9zSBifNrR7dw8jp46p3c4JZedDgitWFMJXykWsxmyUrVZOg6Y8KWUTFsZQTUfN56oEg6JZ6H7v/UOS3EEQuB313v4i0QOL3lX72hKLjtDm1lnclMtHaWYclbKdPXUllZwsIS/+tAF/jl9lRf71cdtxxdQoyU06Kd3WIqD8KnfiZPV+jHg2i9s2x+hdzglk5WhJXsnuH6mKCrhW1tOwnfAHn5GlpkP/oikcXUfRnnth4QorXevllFQSqDWyPdwFxnErXyHbLO8/QvsRXaGNpVaVfhKseVsfuKAs3R+2HGKUwkpTB7cGOOWT6BqPbWMglJirtUbcTbkHu5IX83qjdv0Dqf4stPB6Kb9URW+Uiy5LR3HSvjXUjOZsS6Kbg386WXeARcOQPeXtN9SFKWE6tz9FtnChMumaSSnO8b3gNbScdX+qApfKZacCt/BBm1nroviWmomrw5qiFj/Hvg1hFb36h2W4qBEpUCutH6cgXIrS1eu0Duc4skZtDW6qcXTlGIq0NJxjB7+ibgk5m+N4Z7Q2jS/sg7iIqD3q2A06R2a4sACB08i0ViFpvuncf6qA2wKnp1haem4qD1tlWIqMEvHMSr8t1ccwcPFyMsD6sP6d6Fac2h2t95hKY7OvRJZvd6gnTjGmp8cYMPz7JyWjqrwleJysJbOusiLbDgax4R+DfE//itcPgF9XgOD+q+hlF3Vro9wwaspA859SfixWL3DubWs9HwtHcde5bYo6rva2hxolk5Glpm3V0RQL8CLh0MDYP00qBUKje/QOzTFWRgMVBnxCYHiMsd+nWrf0zRzL7xSg7ZKceUm/JyWjv328OdvPcnJ+GTevLMZrjtnwvXzMPA9Ne9esSq3+l05W/tORqb+yrINdjxNM/+grTlTu2reyZQp4Qshqgoh/hJCRFluqxRxXLYQYp/lz/KynNPu5V54lTNoa58V/qXraXyx7jh9m1SjV41M2Dodmt8NdTrqHZrihGqO+gBpMOC76S0uJ9vpgGjOlbY5O7o54Vz8slb4k4G/pZQNgb8tjwuTKqVsY/kzrIzntG8ZyZaRfpNdt3Q+/OMo6VnZvH5nM/h7Kkgz9Puv3mEpTkr4BnG9/UT6souVv3yjdziFy87p4auEX5ThwLeW+98C6rLMnN2uwG4T/q6Tl1m8J5Z/datHSPJ+OLAIOj8NVerqHZrixAIGvMgl9xD6nPyYIzF2uJpm/pZOzmMnU9aEX11Ked5y/wJQvYjj3IUQ4UKIHUKIW/5QEEKMtxwbHhcXV8bwdJCZAq7e2n077OFnZJl5felBalX24PmeteH3CeBbB3q8rHdoirMzueI5cia1RDxRP72G2d4GcPNfaQtOOXB724QvhFgrhDhUyJ/h+Y+TUkqgqH/BulLKMOB+4HMhRP2izielnCOlDJNShgUEBJTks9iHDMvmJ2CXPfy5W6I5djGJqcOb47l7FsQfgzs/1WYVKYqNeTfsRnSd0QxJWcrqtX/qHU5BN1X4OiV8KSEzzSZvfduEL6XsJ6VsUcifZcBFIUQggOX2UhHvcdZyGw1sANpa7RMUJkPHq/rsuKVz5nIKM/6OYmDz6vQNSIRNH0PzEdCwv96hKRVIyH0fkWysRJ1t/+HSVTva9DznStvcCl+nls76abDgDkhPsvpbl7WlsxwYa7k/Flh24wFCiCpCCDfLfX+gK3CkjOctWlY6/K8HLH8OkhNsdpoi3dTSsY+EL6XkzWWHMArBlDsawZLHtKp+0Pt6h6ZUMMKzCml9p9GSE2z54W29w8mTla4l+9xBWx0q/L0/wKaPoHpzm/zWXdaE/z7QXwgRBfSzPEYIESaEmGs5pikQLoTYD6wH3pdS2i7hm7Oh8SDY93/wRTvYPbd8++gFWjomQNrFfN4/Dl1g/dE4JvZvRM190+H8Phg6HXyKGnZRFNup3uUBoqv2YEjcXHbutIO5+VJqc+8LtHTK+Wrb0zvh9xegXm8Y8qlNrocpU8KXUiZIKftKKRtaWj+XLc+HSykfs9zfJqVsKaVsbbm17ZwsV08Y8A48uRUCW8HKF2FOLzizy6anzVWgpWNZWljnKv9aSiZTlh+maWAlxtU6C1s+hbYPQjPnniGr2DEhCHp4DukGd7z/eJ6UNNv0rIstZ0aOUadB28Tz8PND4BsEo+drC7jZgPNeaVutCTy8HEbNh+R4+KY//PYUJBU6zGA9mSl5v4oZLKtN6pzw3155hITkDD4dFIBpySPaxiaqlaPozLVyIHE93qW5jGLH91P0DSYnuZvcyn/QNisdfnpQ69nf93/gUej1q1bhvAkftF+JWoyAZ3drW/Ud/AW+CIWDi213zowk7SpbsIuEv/7oJRbvieWZ7kE03fQ0ZKZq/6ncfHSLSVFy1O/9MAd9e9Mt9msO79WxtZNb4eswaPvHq3A2HO7+Cqo3s+mpnDvh53Dzhn5vwdPbtcGQJf+C1ZMg2waJOCOl4Cwd0C3hJ6Zl8uqSgzQO8GBC4sdwdg/cPRsCGusSj6IUJmTc/0gS3rj+/jQpKTrN2smt8Mt5WmbECgj/Bjo/C82G3/74MqoYCT+Hf0MY+zt0egZ2zobFj1j3p3hWhjbwk9vSyenh63Px1bQVEVy6nsqPtZZgjFgGA6ZB06G6xKIoRfGuUp1LvT6iofkk+xb8W58gcpK70S1vlo6tK/zEc7D8WQhsDX3Lp6XldAnfbJbM3RzNobPXCj/A6AKD3tVWhYxYDksetd4smgzLvNn80zJBlwp/w9FL/Bx+ikV1f8c/8gfo+gJ0ebbc41CU4mjS6152BYyky6VFHNm0pPwDyEnuRpfyWTzNbIZfx2u/WYz8Ju+cQHjMZX7YcQrtWlbrcrqEfz0ti683R/P8or2kZNwi0XZ+Gga+CxG/w99WWjQs/bp261ZJu9Up4ccnpTPp573M9plPhwuLoONTWktLUexYi3HTiRZ1qLFuIsmXy3mtnexyHrT9ZwHEbNYmT/g3zH06MS2TCYv2MWdTNKmZ1u8MOF3C9/V04dN72nAyPpm3V9xmun+npyHsUdj6ORxdXfaTpydqtzkDojokfCklUxdt5PPM/zIw82/o9SoMUmvcK/bP08uH1OFf4ylTOPPN2PK9fiVnzr3RTUv6YLuWTlIcrH0LgrtDu4cLfOnNpYe4kJjG5/e1wdPV+ntKO13CB+jawJ8netRn4a4zrDp4vugDhdB+wlZvAcufh5TLZTtxmiXhu99Y4ZdfD3/tioVMOvMk7U1RMPxL6DVZJXvFYTRv04mt9f9Nk+RdHFj8bvmduMCgrY2vtP3rDW1yx5BPCnxvLt17lqX7zjGhb0Pa1bHN1EynTPgALw5oROsgXyYvOcC5q6lFH2hy02aupF6Bv94s20lzWzo5FX45Xnh1OZqkBaPpv+cpjC5uGP+1Bto+YPvzKoqV9XpgMrvcutD08KecPbipfE5aXoO2MVtg/0Lo8lyB2XIx8cm8sfQQYXWr8HSvIteWLDOnTfguRgPT72tLllnywqJ9ZGbf4tfDGi2hw3htHYsLB0t/0tyWjq92m1vh2/AS7fQk+HsqclZHDDGbmWF4EOMzOxG1bLs+naLYitFooM6j33BJVMXlt0dJTyyHZdJzkrvJNe8qV2sP2mZlwIp/Q+WCy5GnZWbz1I//YDQKPr+vDSaj7dKy0yZ8gGB/L969uyW7Yi7zwerIWx/c82XwqAxryzCAm15US8cGFb6UcOAXmBkGmz9hl2dP+qR/TOj9/yWgSiXrn09RylGN6jU52382vtlXODX3Qdv38/NX+EJot9Zu6WyfCfFHYfBHedfqAFOWHSbifCKf3duGoCqet3iDsnPqhA9wV9tajO1cl7lbTrJ8/y1G/j2qQOdn4Phfpa/y04oatLVyD//8AZg3CH59DLyr83vYt9wb9wgPD+xE1wb+1j2XouikQ9d+rAueSKPEHRz8ycbz1HMrfLe8W2u2dK6cgo0fQpM7tcUdLX4OP8NP4Wd4tncDejeuZr3zFcHpEz7Aa0OaEVa3CpMWH+DohetFH9j+MW0O/ZbPSnei9EQwuIDJXXts7R5+ehL8+Zq2GFzCcRg2k/ABS5i4zZX+zarzVE/b9f4URQ/9H3qVrR69aRb5Bcd3rrTdiXIrfNe8W2tW+H9MzpskYnEg9ipvLD1El/p+TOzfyHrnuoUKkfBdTQa+fKAd3u4mnvg+nKspRfzk9qgCoePg8FK4frHkJ0q/rlX3OSPvOb1AayT8S5Faot8+U5vK9Vw4Z4JH8uSPewmq4sEn97RGqNk4ipMxmYw0Gz+P04ZaVF39FPHnY2xzovyLp+XcWqvCj1wFR1dpM+Yq1wbgwrU0Hv8uHH9vN2aMaYvRUD7fuxUi4QNUq+TO7Afbce5qGuO/30N6VhFtltBHQGbDvh9LfpK0xLz+PeS1dMq6rvbJzTC3L6Rd1VYAHfo5icKbf327m4wsM3PHtqeSu22WU1UUvVWpUpXsUd/iLtO4NO9+UlNtsJRy/uWRQSvWrFHhZyTD6legWjPtuh8gNSObx77bTVJaFt+MC8Pf263s5ymmCpPwAULrVuWj0a3YdfIyryw+UPily/4NoG5X+Oe7kg8UpSfmXWULeQlflqGHH70RfhytrZP9xCao15PMbDPP/PgP0XHJzH4wlAbVvEv//oriABo0DyOq4zs0yzzMtq+eJNvaG6Bn3djScbPOLJ2NH8K1M9qGJkYXss2Sf/+8j8PnEpkxpi1NapTvBIsKlfABhrepxcsDG7Ns3zk+WXOs8IPajYUrJ+HU1pK9efr1GxJ+GRdPi4+Cnx6CqiEwbiVUqomUktd+O8jmqHim3d2CLmqQVqkgWt8xnsN1HqRv4m8sX/ChddeayS5s0LaMFf6lCK0F2+ZBqNsZKSVTlh9i9aELvHZHU/o2Lf/d5ipcwgd4uld9xnSozcz1x/l6U/TNBzQdqm1TePjXkr2xNVs6GcmwcIz2q+X9P4GXP1JK3l4Rwc/hsTzXpwH3tq9T8vdVFAfWfOx0TlZqzx2nPmTxst+s98bZGYDI+5518dT2jigtKbXd9tx8oP9UAD796xg/7DjNEz3q8Vj3emWPuRQqZMIXQvD28BYMaRXItFURfL89puABrp7QaKC2sFpJ1sxPvQweVfMeG8owaLv2v5AQpW13VllL7J+tjWLe1pOM6xLMv8tpVF9R7IrRRN3xP3HdtRo99k7kuzU7rPO+WelaVZ8z8cHFQ9u9rrT2L9Q6BP3+C15+zN0czRfrjnNvWG0mD25inZhLoUImfACT0cDn97ahX9PqvLHsMIt2nS54QLO7IDmuZG2dlMvgmW8NjNJeeHVqO+z6H3R4AkJ6IKVkxt9RzPg7invCgnjzzmZqRo5SYRm8/aj86C9UNqTRcsszzFsfUfY3zc7IWyUTylbhJyfAmtchqAO0fYjZG0/wzsoI7mhZg2l3t9D1e7fCJnzQll+Y9UBbejYKYPKvB/nfxhN5X2w4QPtHP7K0eG+WkQJZqTdU+KWYh282w5+vQqVa0G8KUkreXRXBp38dY0S7Wrw3ohWGcprCpSj2yhTYAtPIObQ1HKf6uueZuTaybD39rPQCa9Lj6qm1VUtjzeuQdg1552dMX3eC91dHMqx1TWbc19amyyYUR4VO+ABuJiNzHg5lSKtA3lsdyXurIrT/OK6eUL8PHFuj9eNuJ9Wy0qZn/oRfigr/0BI4txf6vkmm0YNXfz3I15tPMrZzXT4e1brc5usqir0zthhOdv93GGLchc+G13lj6cHSz965qcL3KF2FH70B9v8f5s7P89ZO+GztMUaFBvHZvbZdI6e49I/ADriZjMy4ry0PdqrD/zZF89xCy+YpDQdAYqw22n47OUsre/rlPVfSC6+yM+HvqVCjFVcb3MW4+btYtFu77PqtYc1VZa8oNzB2fQ7Z+TnGmv6icvgMnvxhD0nppRgzy0zRknwOF6+S9/DTr8PvEzBXqceTp/vw7fZTPN49hA9HtrKbQk0lfAujQRvInTSoCSsPnmfEl9s4F9BN+2LUmtu/QUqCdutRhgr/4C9w7TRn273IXV9uZ/fJK3w0qhUvDWysevaKUgTRfyq0uo+XXH6hxbFZDP9iM8cv3WIJlcJkpt6Q8EsxaLvqFeTV07yc8Th/n7jOtLtb8NqQZnZVqKmEn48Qgqd61Wf+uPacu5rK4PknuObbBKL+uv2Lb9XSKc5MH7MZueVzLns3os9yV5LSs/i/xzsyOqx2yT+IolQkBgPc9SW0eZAJpl95LHkOI2Zu4td/Yovf189M0cbscrh6aoVaMadUywM/w/7/46vsu1mf1pAFj7TngY51S/FhbEsl/EL0alyN35/rRoi/Fz8kNCL71DYuJ9xmTe7CWjolqPDj9/yGiD/KW5cH0KmeP6sn9CAsuOptX6coCtoEiWFfQKenGSNX8aP7B7zz82Ye+zaci4nFWIrhpgrfkvyLMXAbF7mNjN+eJdzciC21HmX1hO50bxhQyg9iWyrhF6GunxeLn+xMYNgwjJh554svmbs5moysIpZbSL2i3XqUbFpmSkYWX6w9xtkV0zgtq9Nu8Djmj2tPgE/5ra+hKE7BYND2bx4+ixbZkWz2fZO0E5vp+8lGZq0/TtqtNgXPTC1Y4efcv8XAbWpGNj/+sRGx8D4umX053H0W3z/eleqV3K30gayvTAlfCDFaCHFYCGEWQoTd4rhBQoijQojjQojJZTlneTIZDYwYejfZrpUY5hXBOysj6P3xBhZsPakN6uaXkqAtq2DMt4jZLXa8upaayeyNJ+j+wXq2rVtKa3EC374TGde9oV31/BTF4bR9EPHYX3h5efOD6W3errKaT/7Uvnfnbo4mMa2QNs1Ng7aeec/fIDEtk3lbTnLnh8vptO0J3I1mTA8vYWz/DnYzOFuUsm6LfggYAfyvqAOEEEZgFtAfiAV2CyGWSymPlPHc5cNowli/F73O7mHBuDBmrj/BW78f4dO/jjGkVSBDW9ckrG5VXK9fAO8b1sa4YQOU1IxstkfHs2L/eVYePE96lpkejQL4InszXA3At/O48v1siuKsAlvDE5sQK/7N3Qfn0yc4kpeyn+OdlRF8vjaKIS0DGdyyBl3q++NqMtzc0nEtmPDTs7LZdiKBPw9dYPn+c2RlpLHU5xNCTAkYxi7Hu24rHT5kyZUp4UspI4DbzSDpAByXUkZbjl0EDAccI+EDNOgLEcvpVfUKvZ7qQnjMZX7ceZpl+86xcNcZ3F0MLPWIwtXVhw1bTuLr4YKbi4HUjGxGYmBjxDlmRWzjwNlrZGSZ8XEzMSo0iDEd6tDCcAr+twn6vFHwP5yiKGXj5gMj5kC9nviufImvq0zl8Phf+SY8jpUHz/NT+BncTAZaBfnyXUoSJ+IyOfZPLEaDwO9CMt2Ab9YdZvW16xw+l0hqZjaerkaGtKjBq5kzqRp1EEZ+A3U76/1Ji62sFX5x1ALO5HscC3Qs6mAhxHhgPECdOnayOFj9vtrt8bVQrQlhwVUJC65KSkYWm6Pi2Rl9Gd+9CexJb8DUFQV/jg1zM3Di4jUMNQQPdapLr8YBtA+uiruL5SrcJTO0Xbba/6ucP5SiVABCQNsHteXFv7+b5gff49N7ZpKWmc2WqHh2RCcQfuoKxqxUNsck88Hx/QCEibN0c4NtkachsA73dahNj0YBdK7nh/vhn2DpL9BzMrQcpfMHLJnbJnwhxFqgRiFfek1KuczaAUkp5wBzAMLCwqy86HUpVa4N/o3hxN/Q5dncpz1dTQxsXoOBzarD/qsM6diWLt36k5SWRVpWNh4uRly/cuVfYUE8NrCQKiDuGBz6FTo9VXCwV1EU66rXS9uAZPss6DAe98BW9GtWnX7Nqmst16lZPNKrGYPa9CLbLPFI8IOfYO6YpoimXfLeJ+kS/PEq1OkMPSfp9WlK7bYJX0rZr4znOAvkn0weZHnOsTToB+Hf3NzrA20nqqw0RKVAqnq5UtUr35ocBpei18P/+7/a4FDXF2wXt6Iomh4vw54FWtIfkW/Y0TITx93DmxB/L+0515oAiLRrBd9j63Rto6OhM7RZQQ6mPCLeDTQUQoQIIVyB+4Dl5XBe62rQB7LSIKaQ1TMTz2u3Nw7agjY/uLBpmUeWQ+QK6DoBvO1zzq6iOBWPytDmfm29quSEvOczkrRb13zTMnN+4865vibnfvg8aHkPBDjm8uRlnZZ5txAiFugMrBRC/Gl5vqYQYhWAlDILeBb4E4gAfpZSHi5b2Dqo2xVM7lpb50ZXT2m3lQu5ss5gunla5pVTsOxZqBWqJXxFUcpHmwe078ejK/OeS0vUbt0r5z3n6g3CmHd9DcDh37RZO52fKZ9YbaBMCV9K+ZuUMkhK6SalrC6lHGh5/pyU8o58x62SUjaSUtaXUk4ra9C6cPHQkv7xtTd/7fJJ7bZqyM1fM5gKVvjmbFjyGCC1Ef78S7IqimJbga2hSjAcyTf8mNO2yb89qRBalX9jwvdrCDValkuotuB4TSg9NegL8cfg6pmCz1+JAVefgssq5DCaCvbw9yyA2F0w5JPCf0AoimI7QkDjIXByc95VtDkJ39234LH5E/71CxCzBVqMyNsVywGphF8SDSzj1ze2da6c1KqGwv4j5K/wpYSds6FWGLQcbdNQFUUpQr2ekJ0OZ3Zpj9NvlfAtPfwjywAJzUeUW5i2oBJ+Sfg3gkpBN7d14o6CX/3CX2Mw5a24dyVG+w2h9X0OXSUoikOr20Xrz5/cqD3OrfArFTzOpwYkntPuH/oVqjWDavrtR2sNKuGXhBBaWyd6U96Sx6lXtEHbwCIurTa45FX4p7Zpt8HdbB+roiiFc/PRJkxE5yT8nEHbGyr8KsFw9bTWwj2zQ2vnODiV8EuqQV/tV8Cz4drjCwe12xqtCz/eYMzr4V86AiYP7SIuRVH0E9JD20o0LVG7jsZgKrhaJmgJPzsDdnypPXbwdg6ohF9yIT21qv3wb9rjnD5gzTaFH59/WmbCca3144AXbCiKUwnpDjIbTu/Qrp71rn5zm9WvgXa740sIal9029aBqMxTUh6VofldsG8hpCdp2x8GtgYv/8KPzz9om3A87z+Roij6CeoARleI2QzXz2v9+hvV7gBYfgiEjivP6GxGJfzS6PiU1tZZNAbO7ITmdxd9rDHf0grXL0KlmuUTo6IoRXP11GbLxWyGa2fBJ/DmY1w84P6foP9UaD2m/GO0AZXwSyMoVEv6JzeBbx0IfaToY3OWVsjKgIzrBTc5VxRFPyHdtT5+/FHwb1j4MY0GalfDG4zlG5uNqIRfWoPeg/Eb4MnNWpunKDnTMnMu4PBUq2Iqil1oPDjvfg3H2MCkrFTCLy0hoGbbWyd7yJuWmXMBh6rwFcU+1GwLTYdC5TpaJV8BlMcGKBWbwbK0Qs6qe54qQ/lhGAAABm5JREFU4SuK3bj3BzCbK8zMuYrxKfVkMGrTMlWFryj2qYIke1AJ3/ZypmXmVPhqZytFUXSiEr6tGV0sg7aqpaMoir5Uwrc1o6t2eXbKZTC63Xz5tqIoSjlRCd/WXDy0rRFTL2vVvVolU1EUnaiEb2smN8hMg5QrasBWURRdqYRva6YbKnxFURSdqIRvayY3QGpbpKkZOoqi6EglfFszuWu318+rCl9RFF2phG9rLpaEn5WmeviKouhKJXxby6nwQVX4iqLoSiV8W8uf8FWFryiKjlTCt7UCCV8N2iqKoh+V8G1NtXQURbETKuHbmotq6SiKYh9Uwre1AhW+n35xKIpS4ZUp4QshRgshDgshzEKIsFscFyOEOCiE2CeECC/LOR2Oi0fefdXDVxRFR2Xd8eoQMAL4XzGO7S2ljC/j+RxPpZp59yvQRguKotifMiV8KWUEgFArQBZNVfWKotiJ8trTVgJrhBAS+J+Uck5RBwohxgPjAerUqVNO4dnYnZ9DlWC9o1AUpYK7bcIXQqwFahTypdeklMuKeZ5uUsqzQohqwF9CiEgp5abCDrT8MJgDEBYWJov5/vYt7BG9I1AURbl9wpdS9ivrSaSUZy23l4QQvwEdgEITvqIoimIbNh9FFEJ4CSF8cu4DA9AGexVFUZRyVNZpmXcLIWKBzsBKIcSfludrCiFWWQ6rDmwRQuwHdgErpZR/lOW8iqIoSsmVdZbOb8BvhTx/DrjDcj8aaF2W8yiKoihlpyaGK4qiVBAq4SuKolQQKuEriqJUECrhK4qiVBBCSvu9tkkIEQecKuXL/QF7XLtHxVUyKq6SUXGVjDPGVVdKGVDYF+w64ZeFECJcSlnkCp56UXGVjIqrZFRcJVPR4lItHUVRlApCJXxFUZQKwpkTfpErcupMxVUyKq6SUXGVTIWKy2l7+IqiKEpBzlzhK4qiKPmohK8oilJBVIiEL4R4UQghhRD+escCIIR4WwhxwLKp+xohRM3bv8r2hBAfCSEiLbH9JoSorHdMAEKI0UKIw0IIsxBC1yl0QohBQoijQojjQojJesaSnxBinhDikhDCrpYeF0LUFkKsF0IcsfwbTtA7JgAhhLsQYpcQYr8lrv/qHVMOIYRRCLFXCLHC2u/t9AlfCFEbbQ3+03rHks9HUspWUso2wArgTb0DsvgLaCGlbAUcA17VOZ4ch4AR6LxpjhDCCMwCBgPNgDFCiGZ6xpTPAmCQ3kEUIgt4UUrZDOgEPGMnf2fpQB8pZWugDTBICNFJ55hyTAAibPHGTp/wgc+AV9D21bULUsrEfA+9sJPYpJRrpJRZloc7gCA948khpYyQUh7VOw60ndqOSymjpZQZwCJguM4xAWDZMvSy3nHcSEp5Xkr5j+X+dbREVkvfqEBqkiwPXSx/dP8+FEIEAUOAubZ4f6dO+EKI4cBZKeV+vWO5kRBimhDiDPAA9lPh5/co/H97dw/aVBSGcfz/DIqCdVMQK6RDcVFQB0G6iCKIlIpbBwXBtYNrzeDqJA4OLm4GQVBBUCkFO0opSv1CdyNIJyc3fRzOKYSgjWJ6z03v+9tOCLkPIfflfN0cnpcOUTP7gc897S41KF6jQlILOAosl02S5KmTVWANWLRdh1y3SB3Un5vx4f91AEodbHTIOnCNNJ1TuUGHv9tuA21J88AccL0OufJ72qSheKeKTH+bK4wuSbuAh8DVvhFuMbZ/AEfyWtVjSYdsF1sDkTQNrNl+JenkZlxj5Av+nw5Zl3QYmADeSII0PfFa0nHbX0vl+o0O8IyKCv6gXJIuA9PAaVf4kMY/fF8lfQEO9LTH82thA5K2kYp9x/aj0nn62f4maYm0BlJy0XsKmJF0DtgB7JZ0z/bFYV1gy07p2H5ne6/tlu0Wafh9rIpiP4ikyZ7meeBTqSy9JJ0lDSdnbH8vnaeGVoBJSROStgOzwJPCmWpNqbd1F/ho+2bpPOsk7VnfhSZpJ3CGwveh7Xnb47lezQIvhlnsYQsX/Jq7Iem9pLekKadabFUDbgNjwGLeMnqndCAASRckdYETwFNJCyVy5AXtOWCBtPj4wPaHEln6SboPvAQOSupKulI6UzYFXAJO5d/Uau7BlrYPWMr34AppDn/o2yDrJv5aIYQQGiJ6+CGE0BBR8EMIoSGi4IcQQkNEwQ8hhIaIgh9CCA0RBT+EEBoiCn4IITTEL8E7MUWa/mdbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyf3ya6_PWFB"
      },
      "source": [
        "### Step 2: solution of diff.eq.\n",
        "We have $$\\frac{dP}{dt}= N1(t)*N(t) = f(t, P(t))$$ , we can solve this diff. eq with a Neural Network(numericaly) or with any other numerical way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25zK0EXXPWFC"
      },
      "outputs": [],
      "source": [
        "#(0,10) \n",
        "#t0 --- > net(t0) = A\n",
        "#sigmoid\n",
        "#less hidden neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "MxB3euNsPWFC"
      },
      "outputs": [],
      "source": [
        "x = torch.Tensor(np.linspace(-4, 4, 100)[:, None]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "xV5g975PPWFC"
      },
      "outputs": [],
      "source": [
        "NN = nn.Sequential(nn.Linear(1, 50), nn.Sigmoid(), nn.Linear(50,1))\n",
        "A =net2(x[0])\n",
        "Psi_t = lambda x: A + (x+4)*NN(x) #NN is responsible for the solution of O.D.E\n",
        "f = lambda x: net1(x)*net2(x) #they are both trained. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "jE9fFB1IPWFT"
      },
      "outputs": [],
      "source": [
        "def loss_fun(x):\n",
        "\n",
        "    x.requires_grad = True\n",
        "    outputs = Psi_t(x)\n",
        "    Psi_t_x = torch.autograd.grad(outputs, x, grad_outputs=torch.ones_like(outputs),\n",
        "                        create_graph=True)[0]\n",
        "\n",
        "    return  torch.mean( ( Psi_t_x - f(x) )  ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Pd6JWAKEPWFT"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(NN.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "5FcYtodXPWFU"
      },
      "outputs": [],
      "source": [
        "losses_N=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gHJywHbPWFU",
        "outputId": "7e33bcce-af15-4685-bb16-9ee1ea1beb34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0247, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0252, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0259, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0267, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0271, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0264, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0250, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0254, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0255, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0250, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0248, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0251, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0259, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0270, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0277, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0273, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0256, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0255, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0258, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0251, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0247, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0251, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0258, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0267, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0273, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0270, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0257, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0256, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0252, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0246, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0255, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0263, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0270, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0270, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0262, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0248, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0251, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0254, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0249, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0248, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0245, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0244, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0243, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0242, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0241, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n",
            "tensor(0.0240, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def closure():\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    l = loss_fun(x)\n",
        "    losses_N.append(l)\n",
        "    print(l)\n",
        "    #l.backward()\n",
        "    l.backward(retain_graph=True)\n",
        "    return l\n",
        "\n",
        "for i in range(1000):\n",
        "    optimizer.step(closure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "xwunUL1EPWFV",
        "outputId": "15291729-b944-4bb9-db2f-744b14803c0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAETCAYAAAB9dqLFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xUVdrHv2dm0ishoZcgvUdKpEVaQAE74CqWdS2IuutaVmWLyqK4+sqKBd9FxYVXEClBEQtKlyJSpPdmEjqBhPRkMjPn/WMm994JKQPMpJ7v55MPuefcyT1zuTPPOc/5Pc8jpJQoFAqFQlFdMFX1ABQKhUKhMKIMk0KhUCiqFcowKRQKhaJaoQyTQqFQKKoVyjApFAqFolqhDJNCoVAoqhXKMCkUCoWiWmGp6gFcCQEBATImJqaqh6FQKBSKa+TUqVNWKWVAaX01yjDFxMRw8uTJqh6GQqFQKK4RIURaWX3KladQKBSKaoUyTAqFQqGoVtQoV155SCm1H4VCUfMRQmAyqblzXaTGGyaHw8H58+e5dOmSMkoKRS3Dz8+PFi1a4O/vX9VDUVQiNd4wpaSkYDKZiI2Nxc/Pr6qHo1AovISUkosXL5KamkqbNm2qejiKSqRGGyaHw0FBQQFt27bFYqnRb0WhUJRC/fr1SU9Px+FwKLdeHaJG/08Xu+6EEFU8EoVC4QuKP9vKTV89OJZ+jOXHllNkL/LpdWq0YVIoFApF5TFz+0xumnsTDac25OllT/vsOsowKViyZAm//PKLdrx27Vri4uKu+e9+++23DBo06Jr/TmUyY8YM3n77ba/+zZL3d9u2bfzud7/z6jXK4+uvv6Zjx47ExcWxZ88et77Zs2cTERFBXFwcnTt3ZsSIEaSmpmr906dP58033wRg586dzJ8/3+31CQkJ/Pbbb75/E4oqR0pJ0oEkADIKMkjLKzM+9ppRhklx2RdnbcBms13V6yZMmMALL7zg1bGUvL+9evViwYIFXr1GecyYMYNXXnmFnTt30rVr18v6Bw8ezM6dO9m3bx/t2rXj2WefBSA/P5933nmHP/3pT0Dphun555/n1Vdf9f2bUFQ5e87v4Wj6Ue14dMfRPrtWrTJMBbYC9p3f5/OfAltBueMQQvDGG28QHx9Pq1atmDVrltZ35MgRRo0aRe/evenWrRvTp08H4OOPP2b8+PEA7N+/HyEEy5cvB2Dy5MlMnjz5suvMnj2bxMRE7r33Xjp16kS/fv3Yv38/d955Jx07dmT48OHk5OQAUFRUxMSJE4mPjycuLo67776bjIwMvv/+e5YuXcrbb79NXFwcM2fOBJxf7E8++STdu3enc+fObNu2TbvunDlz6NatG926dWPUqFGcOnVKu8aTTz5J27ZtiY+PZ82aNWXeo3feeYfevXsTFxdH79692bRpk9YXGxvLCy+8QM+ePWnTpo3bCqaivpdeeon4+Hh+//vfk5OTw8MPP0yXLl3o0qUL//znPwFYt24drVu3Jj09HYA//vGPPPbYYwBMmjSJZ5555orv76pVq+jbty/XX389nTt35tNPPwUo9f6WXJGWdT+N1+/atSu9evXi+PHjpd7Po0ePkpiYSLdu3YiLi2PJkiUAPP3006xfv56//e1v9OvXr8z/j2JuuukmDh06BEBSUhL9+/cnJCSE8+fP88orr7BmzRri4uKYMGECAKNGjWLZsmVkZmZW+LcVNZvF+xdrvwdZghjRZoTvLmYMTK3uP02bNpVGbDab3L9/v7TZbFJKKfee2yuZhM9/9p7bK8sDkFOnTpVSSnngwAEZGhoqi4qKpM1mkz179pQHDhyQUkqZm5sru3btKrds2SKPHTsmW7VqJaWU8t1335V9+/aVL7zwgpRSygEDBsiNGzdedp1Zs2bJ8PBwmZKSIqWU8v7775fXXXedPHv2rJRSylGjRsnp06dLKaWcMmWKnDx5svbayZMnyyeffFJKKeXvf/97OW3aNK1vzZo10mw2y19++UVKKeV//vMfOXz4cCmllHv27JENGzaUJ0+elFJK+frrr8ubb75ZSinl9OnT5ZAhQ2RhYaEsLCyUgwYNkgMHDiz1Hp0/f177fdOmTbJ9+/baccuWLeUDDzwgHQ6HTEtLk82bN9fef0V9jzzyiHQ4HFJKKV988UU5btw4abfbZU5OjoyLi5Pz58+XUkr5xhtvyFtvvVUuWLBAdu/eXebn50sppXz11Vfln//85yu+v+np6dpzePHiRdmiRQt54sSJMu9v9+7dK7yfxdc/fvy4lFLKl156SY4fP77U+xkfHy9nzJghpZTy8OHDMioqSiYnJ0sppRw4cKD86quvSn3drFmz5O233y6ldH6eHnroIfnggw9KKaV8+OGH5QcffFDquUYGDx4sv/nmm1L//rVS8jOuqDo6f9hZ+w68a8Fd1/z3gJOyjO/6WrViqk7cd999AHTo0AGLxcLZs2c5dOgQ+/bt45577iEuLo5+/fqRnZ3N/v37ue666wA4fvw4K1eu5F//+herV68mJyeH/fv3Ex8fX+p1+vbtS4sWLQCni6h37940bNgQgN69e3PkyBHA6U6aO3cucXFxxMXF8cUXX5S7N9CmTRtuuOEG7RrHjh0DYM2aNdx88800bdoUgCeffJLVq1djt9tZtWoVDz74IP7+/vj7+/Pwww+X+fd37NjBwIED6dKlCxMmTODQoUPk5+dr/Y888ghCCKKjo7nrrrtYuXKlR30PPfSQpuRauXIljz32GCaTiZCQEB588EFWrFgBwMSJE7FarYwfP56FCxcSGBh4Tff34sWLjB07li5dujBkyBAuXrzI3r17y3z/xZR3P4uv36pVq8v+H4xkZ2ezfft2HnnkEQDatm3LgAEDWL9+fYXXLx5DXFwcPXv2RAjBv//9bwBOnjypvdfyaNSokUquXMs5eOEg+9L2ace+dONBDY9jqs4Yv+jMZjM2mw0pJVFRUezcubPU1yQmJrJs2TKOHDnCwIEDkVKyePFi+vbtW2acVsnrlHZdcK6MP/jgA4YPH37V4y+N8qT6ZfVZrVbuuusu1qxZQ+/evcnKyiIiIoLCwkKCgoKu6TqhoaEenZednc3x48cJCQkhLS2Ndu3alfoaT+/vhAkTGDlyJIsXL0YIQY8ePSgoKN/lW9EYS7u+p3tnVxJCMXjwYM31ZyQ4ONij91BQUFDm/5uidmB04/mb/bml3S0+vV6tMkyto1qz94mKZ6neuM7V0L59e8LDw5k1axZ/+MMfAOfeQFRUFFFRUSQmJvLiiy9y4403AjBkyBBeffVVbc/jWrjjjjuYNm0aAwYMIDg4mLy8PH777Tc6d+5MeHi4x3sEgwcPZsqUKZw+fZomTZowY8YMhg4ditlsJjExkblz5zJu3DiklG57a0YKCgqwWq3aSuSDDz647JzZs2czcOBA0tPT+eqrr/jiiy886jOSmJjIp59+ysCBA8nLy2POnDm89NJLgHPVdd9995GYmMgDDzzA1q1bqV+/vkf3oDQyMjJo2bIlQgjWrVvHrl27tL7y7m9599NTwsLC6NGjB7NmzeKxxx7j6NGjbNiwgffff/+q3w9At27dtP2m8t7HgQMHeOWVV67pWorqTbEaD2B46+GEB4T79Hq1yjAFWgLp3KBzVQ+jTCwWC99++y3PPPMM06ZNw263Ex0dzbx58wAYOnQoqampJCYmAjBs2DCmTp3K0KFDr/naL730EoWFhdxwww3abPqll16ic+fOPPDAAzz00EMsWbKEp556qtz0L126dOHtt9/m5ptvBqB58+Z88sknADz22GPs3buXTp06Ua9ePRISEvj1118v+xvh4eG8/vrrxMfHEx0dzT333HPZOTExMfTs2ZPMzEz++Mc/um3cl9dn5OWXX+bpp5/WlGhjx47l7rvvZvr06aSnp/Pyyy9jMpl44oknePDBB/n22289vJuX8+abb/Lkk0/y2muvERcXp7lBgXLvb3n380r4/PPPmTBhAtOnT0cIwcyZMzXDf7WMGTOGhx9+mNdffx1wPp9Tp06lW7du9OvXjxkzZpCcnIzdbqd79+7XdC1F9eV4xnF2ntW9PL524wEIWYMiqps1ayaNvmy73c7hw4dp167dFc0wFdWb2NhYlixZUmosVXl9Cu8zatQoJk2aRO/evUvtnzhxIm3atOHRRx/1yfXVZ7zqeXvj27y48kUALCYL5/5yjqigqGv+u0KIU1LKZqX1KfGDQqEok/fff59z586V2d+kSZNyRS6Kmo/RjTek1RCvGKWKqFWuPEXtIDk5+ar6FN6ndevWtG5d9p7q00/7Li2Nouo5kXmCLae2aMeV4cYDtWJSKBQKRRl8eeBL7XeTMHFHhzsq5brKMCkUCoWiVIxuvBtb3kiDkAaVcl1lmBQKhUJxGWeyz7AxdaN2PKbjmEq7tjJMCoVCobiMrw5+hURXbd/Z8c5Ku7YyTAqFQqG4jMUH9GwP/Zr3o0lYk0q7tjJMPiA2NpYOHTq4pY/p1asXa9eurbQxJCcnExkZWWrf7NmzEUIwZ84crc3T2knJycnMmDHDW8MsldmzZ3PHHZWzyeoLTp8+TUJCglf/Zmn3feTIkW6ZGXxJeno6/fv3Jy4ujilTplzWL4Sga9eudO/ena5du7Jo0SKt78yZM/Tp0weHwwE4M7gbUx1Nnz6dN954w/dvQuExablp/JT8k3ZcmW48qGVy8YIiO6npeT6/TouoYAL9yg/2Kyws5NNPP+Xxxx/3yRhsNluZ+fM8oWXLlrzyyiv87ne/w9/f3+PXFX9BFpc98DZXW0fJFxR/kZpMVzZ/a9KkiccJVD2ltPv+/fffe/Ua5bFixQpCQ0PZuHFjmeesX7+eyMhItm3bxo033sjgwYOJjo7mtdde46mnntLu4z//+U+eeeYZLQ/g+PHj6dixI0899RQRERGV8n4U5fP1oa+xS7t2fFfHuyr1+rXKMKWm5zF82jqfX2f5szfSrmFYuedMmjSJv//97zzwwAMEBwe79WVnZ/Pcc8+xa9cuCgoK6NOnD9OnT8ff359BgwbxzDPPaCuGMWPGcMstt/DQQw/x0EMPYTKZOHr0KOfPn+fgwYPcd999HDp0CKvVSvPmzfn0009p1KhRhe8hLi4Os9nMhx9+qBWGM/Ljjz/y2muvkZ+fj9ls5q233mLw4MFMmDCBlJQU4uLiaNGiBX/84x+ZOnUqy5cvJysri/r16/Phhx8yfvx4PvvsM9auXct///tfjh49yoQJEzh//jwmk4lJkyZp71EIwSuvvML333/PoEGD6NxZTyt1+vRpbr/9dp544onLAjn37NnDE088QV5eHgUFBYwbN45//OMf2v3fs2cPGRkZnD59mrZt2zJ79mzq16/vUV9OTg4nTpxgxYoVrF69Wqv71Lx5cz7++GOioqLo06cPL7/8MmPGjGHTpk3ce++9bN26ldzcXOLi4rh06ZL2/l5//XWWLl3KuXPnePfddzlw4ACLFy8mMzOTTz75hEGDBmGz2Rg1ahQXL14kPz+f7t2788knnxASEnLZfV+6dKlbFoyK7u+UKVNYsmQJaWlpvPLKK1quRiN2u52JEyeybNkywJnH79///jfr1q3jhRdeIDMzk7i4OKZOnaqlzSqNXr16ERoaSnJyMqGhoSxYsICpU6cCaIY1ISEBs9nM8uXLadCgAcOHD2fevHk88cQTFT67Ct9jdOP1atKLlpEtK/X6ypXnI7p3787gwYOZNm3aZX3PP/88CQkJbNmyhV27duFwOHjvvfc8+ru//vor3333HQcPHgTg3XffZdu2bezevZuEhAQmTZrk8RjfeOMN3nrrLbKystzajx8/zqRJk/j+++/59ddfmTdvHuPGjaOwsJAZM2bQvn17du7cydKlS0lISGDbtm0UFhZq2cKLy1CsWLFC+wK77777GDt2LLt372bRokU88sgjpKSkaNc0m81s3brVrfDfnj17GDZsGFOmTCk1u0BsbCyrVq1i+/bt/PrrryxevNitUuz69euZN28eBw8epHnz5vz1r3/1qG/Tpk189tln7N+/n4yMDF544QWWLVvG7t276devH48++ihBQUEsWrSIZ599lq1bt3LfffcxZ84cYmJiSr3XoaGhbN68mU8//ZT777+fxo0bs23bNt544w2tYq7ZbGbevHls27aNvXv3EhERoSW4LXnfS1LR/Q0ICGDLli0sW7aMp59+utSV6ccff8zWrVv59ddf2blzJ8eOHWPatGkkJiYyefJkrdJteUYJnOVGCgsLadu2LVu3bqVVq1ba5KzYHbl+/Xp27txJgwZO+XHfvn1ZtWpVuX9XUTlk5Gew8rheSqay3XhQy1ZM1Y3XXnuN+Pj4y9xeS5YsYdOmTbzzzjsA2qrEE8aOHUtYmL5amzdvHnPmzKGgoICCggKio6M9Hl/79u257bbbeOutt+jbt6/W/sMPP3D06FEtyzk43VmpqamX/Y2goCDi4uLYuHEjK1euZOLEiTz33HM4HA5tpVFcL6jYDWSsF9SypXMmVtLw7Nu3j9tuu40lS5aUmSA0Pz+fJ598kp07d2IymThx4gQ7d+6kT58+gDPPW/Hqcfz48dx1l+6OKK9v5MiRWh2i0uolTZ48GbvdTrt27bR7N3ny5HL3lX73u98BztVEbm6ulrg2Pj5eq+kkpWTatGl899132Gw2MjMzPao668n9La0+WLNm7mnKVq5cyUMPPURAQADgTMr74YcfahnZK6J4FVSvXj2+/vprIiIiVE2nGsg3h7/B5tAnLqM7VU62ByO1yjC1iApm+bM3VnyiF67jCbGxsYwbN07LzlxMcZ2l0moAWSwWrUgccFk9HGO9oeLSBps2baJBgwYsXbr0issPTJo0ie7duxMbG+s2vmHDhmlZz40Ul/02kpiYyMqVK1m3bh1vvvkmXbt2Ze7cudSrV49GjRqRnZ192WtK1gsqWUepSZMmFBYWsnr16jIN09/+9jeio6PZsWMHFouFu+66q9z6Qd6u6QSwfft2YmJiOHHiRJmvAb2uUvEExHhcvHqZN28eq1ev5qeffiI8PJz333+f1atXl/t3PR3n1dR1upKaTqDvMRlRNZ1qHkY3XveG3WkTVXa1AV9Rq1x5gX5m2jUM8/lPRcIHI//4xz+YO3cup0+f1truuOMO3nrrLe3LISMjg6NHjwLOyrGbN28G4LfffmPDhg1l/u2MjAzCwsKoX78+VquVjz766IrvWZMmTXj00UfdVFE33XQTK1euZPfu3Vrbli3OfFml1eRJTExk3rx5REZGEhISQmJiIq+88orm8jHWCwK0ekHGFVlJ6tWrx4oVK1iyZAmTJ08u8/03a9YMi8XCoUOHtOq0xXz//fdaAtKZM2e6uaDK6zMyePBgfvjhB+3/z1gv6dtvv+XHH39k3759bN68mQULFpT5fjwhIyOD6OhowsPDyc7OZvbs2VpfeTWdrub+lkZiYiKfffYZVqsVm83GzJkzPS4sWRYlazoVj7fkezlw4IAqnVENyC7M5sejP2rHlZUbryS1yjBVR6Kjo3n66ac5c+aM1jZt2jTNBdatWzeGDh2qJSd98cUXWbNmDV27duWvf/2rW12fktx88820b9+e9u3bk5CQcNWlICZOnOi2z9SmTRvmzZvH448/Tvfu3enYsSPvvvsu4Pyi6dy5M126dOG2224DnO6pzMxMrW7UsGHDSElJcasj9fnnn7NgwQK6d+/OmDFjPKoXFBYWxg8//MDPP/+s7cMY+cc//sGsWbPo1q0bEydOZMiQIW79CQkJjBs3jg4dOpCSkuJmfMvrM2Ksl9StWzfWr1/PJ598QmpqKk888QQLFiwgKiqKRYsW8Ze//EVzy10NDz74IHl5ebRv354RI0a4uQZLu+9Grub+lmT8+PH06NGDHj16EBcXR2xs7DUXqWzVqhUNGzZk3z69LPfzzz/PsGHDiIuL4/z584DTfTxmTOXvZSjc+e7IdxTaC7XjqnDjgarHpKilTJo0iUuXLmkG1dM+hfdZtGgRa9eu5cMPPyy1f//+/Tz++OOlSuzVZ7xyGbtoLEn7nfnxOkZ3ZP9T+312rfLqMdWqPSaFQlH9GDt2LOfOncPhcJQaE3bixImrckMrvEteUR7fH9Fj46rKjQdqxaRQeJ1CWyHp+elkW7MptBVil3ZMwkSgJZAw/zCigqIIsARU9TBrBOozXnl8eeBLRi/UjdGOx3cQ18h3laJr7YqpWDVUk4yrovZSYCvgVNYpMgoySu232q1kFWZxKvsUUUFRNA1rqgyUh1ypQlBx5RS78ABa12tN99RZsGkpWC+ByQR+4RDTH9qMhwYJ4MP/E6+KH4QQ7wshkoUQUghRpqkVQjwihDgihDgmhPhECOF3NdczmUyYzWaP5KgKha+QUnI25yz7z+8r0yiVJD0/nX1p+0jLTfPx6Go2RUVFCCGUYfIxhbZCvj38rXY8mmOIo+9DfjLYL0FROuQlQ8rnsGogzA+C5IXgo0WBt1dMScD/AGVqnIUQrYDXgB7AOeBrYDxQ+s5oBcTExHDq1CmaNm1KYGCgeoAVlYrdYScl4ziZ1pzL+sJMECLAIsAmIVdCtkPvd+AgJSOF3MJcmoY3xSSUSNaIlJJz584RGRmpPtc+ZsW+OWRb9XjDMWWH8jmRhfDz72DHszD8ZwjxbsoirxomKeU6qHDZPQZYKqU86zp3BvA3rtIw1atXD3DmVDMGpioUvsYhHZzLOYvVXuTWHmIyEST8yJQmMhEIJBZhx08UEYAk0wE5BgN1gQukWJKJCWmgvoBLEBgYqKUtUvgAKeHghySt+pPW1MICvTz1MOefhtU3wy37veraq4o9phZAiuE42dV2GUKI54Dnio/Lyjxcr1496tWrh8PhUPtNikohs+ASt/63N9sznfFpQvrT2DGU1mIwKYWtgdIzK/QK2ccdkWsI9l/PI+dtZBoM1J2thzNrzEIsphq99es1hBBXnNldcQXkJMOy3litF/g6V2++K/QKbUz2YUjbCA0GeG1o1foTIKV8B3in+LhZs2blWh31ECsqg6LMI4z+uBM/59lAQoh9MDG2P2CXURwGoOzHdGNWJzZmdaKF/128Fj2bKdkbSXHZsC8OL6XB0vt5d/SiMl+vUHiF7N/gm9aAZE0eXDJMkCp045VGzlGvGqaq+CZPBYwOyVhXm0JR/clJ5ulZ7VmbZ8MkQ4mxvkx00fNIGXXZqVHmTJr7nyXCfHmuwFRrY6ac/iuDeYGm5hCt/b29Scxa+9fLzlcovIbBKAEsNmyPNjZD38DSX1Yuod7Np1cVK6bFwAYhxCSc4ocJwPwqGIdCcWVIyYx53ZiRKbE4mtDA+ip+sqnbKV2DjvBA/e8YEr6VaEtm8cs4XRTD8qw+zLt4M0cK9XnZmuyBtPBrS45lEpk48/FNWPcmPZsn0K31yEp7a4o6Qk4yfNOWYqNkk7DE4Ma7MxRMV7pVFNbOKSP3Il4NsBVCfASMAhoBF4FsKWUbIcRMnIKHpa7zHgMmul62FpggpSwq5U+6UTLAVqGoTPZs+hu9VvwLaW9Jw8I3MKPveUZbMnit6X+4Ofzncv3zdmniq4xBTDnzCBl2/fXBpiyO+02i0OR0Bnbxh60TDhBYr4PP3o+ijiElLG4E1vNa05o8GGIoGLC6KQz2rHiCk6CmLlXeleVlhPIDbGt05geForIoOLGC+LnDOVDQjEaFb2JGL+/QP3Qn01u8RT2LwWUn/KDzy9Dl786d5HPrYdc/4aKzjMX5ono8c+Iv/JyjZ9T2Ezmk+v8dq+kYAM9HwtRHfoPQ2Ep5j4pazsHpsP1Pbk1/PA8fuhK9R5vhTCtneING+2fh+qnOZ/jsOtg/BXKPQ2hr6PQ3aHjjVavxlGFSKK6Fc+v5y/wbmZYRQePCaVikLl8eXW8lbzb7AD9hCFXoPBm6/aP0D+zZ9bDaWY6iSJr5+8mnWJihl5YQIouT/n/BZjqNCdh2XSTX35/u0yh7RR0g+zf45jq3JoeEZr/BGdej+1g4fFxc07Hts9BzqjPjg48ozzApGZtCUR4OB9u+G8g7GRZirH9zM0p31VvF283eczdKg9dB95fLNiSNEuDW42AKwU/YeavZ+/y+/jdat5ThNLS+ikmG4ACeOH0Jx3G1Bau4BqSEH3pc1rypQDdKAKOL1XhD1kPvd3xqlCpCGSaFohzs25/j8fOSyKI/EOjorLUPCdvC283ewyQMHodRx6Bx2eXVNcJawd1ZYIlECHi1ycfcXW+51m2RTYm2vgTSxOYC+GT5OOemtUJxNRz6EIouXdZsVONFmlx7S7cch0bek31fLcowKRRlkXWc/93yHvvz4gi33641twlI5b0Wb2MWhuCPIesh4rpS/kgZmEwwcgdgxiQkU5p9SL/QXVp3kKMH4ba7APjrBbj03Q0+y0umqMVkHb9sXwlcOgiDYbo9BPxvPQ7hrSpxcGWjDJNCURo5yZxb0oZ/XAijvvVZrTlIFPBRyymEmfP1cwevu7pZZmgs3HoEEPgJO//b4l809z+rdUfa7sff0Y4MB7x17jwc+s/Vvx9F3SMnGb5tW2rXtkJINSQnGd3vzWpjlEAZJoXicqSE5f2YnC7xKxyPhfpa19+bfErrQIO+9vrpnrnvyiKsFdxyFIBISw7vNX8bM07Hv8BCtPUvCBnAu5fg1JanwOEo768pFE5czzCU/rwYV0uhZj+G9fpz5YzLQ5RhUihKkprEoawzzE7vSqh9sNY8JGwL90Ut08+zRECHJ6/9euHXQc/pAPQIOcSzDT/XuvxkEyJs91IgYdJFYM/r1349Re0nbQMUnCm1S0pIMhimWzuMJtByNekefIcyTAqFESlh82P8Nc1MRNEErTnYlMe/mk13F9uN2Ok9GXe7JyGwMQBPNEiiZ/B+rSvcdid+jlj+mwVHdryqhBCKijnycZldu6xwzJDOYHSnMZUwoCtDGSaFwkhqEj9nZ7Iq8zb8pZ466LmGn9PQL10/r+eHEBbrvesK4YygR2AWDt5o9iEWV4ZygZn61j/ikCbezACW91dCCEXZZP8GKXPL7E4yxIEH+wUzou2IShjUlaEMk0JRjJSwZTwT08KIsN2jNbcOSOb30TNHE5EAACAASURBVHp1T8zh0O4J718/NBb6OWOW2gem8HiDxVpXgOxAiH0wn2VBavZpOF9mLU5FXUZK+LF3ud2LDG68UW1HEex3JTmIKgdlmBSKYlKTWJd1iT05YzChZ/ye0nSGexBtn099l4mh5ViwhAHwpwYL3FV6RQ9glwH8TwaQPM8311fUbFKTwHqxzO59VjhscOONqYZuPFCGSaFw4tpbeiWtPmG2W7TmhNCt9Andq58X0BhajPbdOISAGz4FINBkZWKjWVqXhWjCbLczMwvOHpqh9poU7rhW/OVhFD0EWgIZ2bZ6ZrCvO4ZJSqf74/hs57/KR68wkprExuxM9mTfgwm9rvRfG3/mft5Nm3yft67FGKfiDxgZsZHrgw9qXRG2MRQ5IvhPJvBjP/UcK3RSk0rN8GDEaJhGtBlBqP/VVAX0PXXDMOWmwDcdYNVg2DLB+e83HZztCoVrpvlyWgyh9mFa880Ra+kU9Jt+XusJENqylD/gZYSAGz7Rfv1H45lal4lgImxj+E8mFOSfgZQk349HUf1xrfjL44DV6corprq68aAuGCYpYeUQyDkM0gaOQue/OYed7WrGqUhNYmv2JXZm34lw1c4U2HmpUYl9nNhxlTemFmPAz1lao2fIQYaHb9K6Qm0juGiLYF42sHW8eoYVztWSLbPcUxbn+mm/+5v9uaXdLeWcXbXUfsN0foOzfghgcwj2F+h1dMg9rmacdR3XaunNixGE2m/Smm+KWE+rgNP6eYFNoEElJrcUAuL1WJQ/N9SNpIlAwm138e4lkNZLSqFX1/FgbwkgqTBc+/2m1jcRHhBeztlVS+03TGeW4XDAv871pv3+d7n12CT3rC5qxlm3SdtASt4l1mTe5ra39OcGxgmLK8aosmsitRijBd12DvqNYYZVU5htFPsKw1mTD6R8UbnjUlQvPNhbOmKFXdm6Wq86u/GgLhgm4MWzg/jo3KvYHa2x29swOa2v3lmkZpx1muT5TE0PItQ2SmvqF7qZjkHJ+jn9FlTO3lJJtKBbJ0830OsyOVdNt/HeJeC3z9Tkqq7i4WppcUGY9rufyY9b293qy1FdM7XfMDUZwcsNNiLFBa3p/9Luo8hhmP2qGWfdREoyj/4f8zOGYkJXJz3fcJF+jjkEWlbh7DI0Fto4g3m7Bh9jSNgWvcs2gu9yAjhRkKtc0nWVtA0VrpZAkESsdpR4XSL1gur5dFjXSu03TDEDiAgIYES9BVqTdMTy97OGjNBqxlk3SU3i4/Q8/Iv01VK7wIP0DNHl2bR6sOrLmsfeq/06PuZL7XczEQTZh/BpFrDlMfUM10WSK65u/FvXD/j13B7tuLq78aAuGCYhoNWD/LvxChB6FP3C9HHkO1xv365mnHUOKSna/BgfXLweP9lca34q5hv381reS5UTM0BT6N0QspcuQUe1rnDb7XyaKbAVZapnuK4hpXNSXR7mEBZn5emHwszt7W8v5wXVg9pvmABi7yHEbOOuKIPLztGMv5wZpB8rEUTdIjWJrzMyKSjUJbPh5nRGRGzUz/GLrFwlXlkYFHpCwKPRS7QuP9mMi9ZeLMtFPcN1jdQksOeUf06rB0k6oOdcHNJqCPWD65fzgupB3TBMrhnnvxqvQZhOas3fpt+jr5qUCKLu4Nowfi+9MUGOXlrzH+ovw99kKOsZ/0nVu/GKMcQ1jYzYQCOLvmcabruTjzJRz3BdwkPRQ2rUEDaf2qwd1wQ3HtQVw+SacQaYHIyL1ldNQjbh5bMGhZ4SQdQN0jZwIPcS+3JGIVwfARNF3Fe/RBFAX+bEu1IMqyZ/k43fR+sux0BHN1bktCC1CPUM1xU8ET34RbI4LVU7NAkTd3S4w8cD8w51wzCBc8ZpDuXVBusRhr2mxeljsBXHNSkRRN0geT4fXrIQYqhOOzxiIw38DB/0G2ZWn9VSMa5nGGBc1A/4i0KtK8R2M59lo57huoIHogfiP3Fz4w1sOZAGIQ18OCjvUXcMk0sE4W9ycEs9XdkkHW35nwvdnQdKBFH7kZLcY//H/Iw+mInQmv9gXC2ZQ6rXaqkY1zMMEGHJ5ZZI3W0XYh/C7Ex/pE09w7UeD0UPpyL78PMJPQ6uprjxoC4ZJoBYZ/G3NxqvAqHnlfrvhdH6JFNtINduUpOYdykXc9Fwramx3yniQ/bp51QHiXhZxOoFDO+L0o2pmVDOFgzg5wKUdLy246Ho4cuDX2mHAsGdHe708cC8R90yTC4RRJi5kAHhuo/eZuvBJxnXOQ/UBnLtRUrk5sf4IL0BgY44rfnB+svd7VB1kIiXhUE63iP4IO0CkrWuUPsI/i8LZzJPtWqqnXgoeqDlvSQd0J+BAS0G0DissQ8H5l3qlmEybCC/3fg7JAVa13vnDSk6Ujzw3ypqHqlJbM7OJDU/URM9COyMrrdKP6e6SMTLooR0/L76P2hdgY6OLMpqSb4DtfKvrXiQFw+/SM4Gt2F9ynqtqSa58aCuGSbQZLeN/bPpGrpSa8623sjaXFc+qZR56kNd23DNNP9zyUSoPVFrHhK2xV30UJ0k4mVhkI7fUW8N/kKfYAnrTXydi1r510akdNaTq4j4T/jq4BIk+nfY6I7VcM+0HOqeYTLMOP/Z8Hut2UQA/zzrKhKnPtS1j7QNZBVc4uusrlikrkwaV3+5fk51k4iXheEZjjDncnukPjMOsQ9kdqazppSSjtcy0jZWvFpyPcNGN16/5v1oGt7Ux4PzLnXPMIFWurpnSCrR/ru05iN5IzlR5Lol6kNdu0iez8IcsNh0iXikOYOBYb/q51RHiXhZGKTjRlekmQjW5/TktA1I+Vyt/GsT2UcAR/nn3DCTtLwLrE1eqzWN6Viz3HhQVw2TENBoCABPRn+nNVtkI14538N5oOJBag9Swm9zmJkZQLC9n9Y8ut5PWITrg15dJeJlYZCOx4fso7GfHpsXbBvC/GygKNs5y1bUDvJOlt/vXx9ajGbJwSU4pG7ARneqQc+1i7ppmADCOwDwYP1f8DOlac0rLt3i3DxWMU21h7SNHMjPZk/uDZgI1prvjFyjn1OdJeJl4ZKOm4RkbD39vQQ74pmXGQZIuLCpjBcrahRSwoF/l39Oi7tBCDc3XnzTeFpEtPDx4LxP3TVMTUYAYBEObonUlU1mew/+NyPGeaDiQWoHF35hVhaE2AdpTa0CUukcdEw/pzpLxMsiZoBzlgzcVW+11izw41B+AketwIH/Uc9wbSA1yRkGUB7+kVzMu8iq47prtya68aAuGyZDPMjEBssBOwACEx9fSHR+llU8SM1HSor2/YvPMsMJcvTUmsfUW6MvkAKiq7dEvCyEgE4TAYgNOEP3oP1aV6htCPNzgMILSshT0/E0dqnxCJYeWopd2rWmmujGAy8bJiFEWyHEz0KIw0KIrUKIzqWcM0gIkS+E2Gn4CfLmODwcrKZsauifQbugbVpXrjWRn/Nd31rbnlAzzppM2gaWZaSTZ70RgVlrvi3yJ/2cji/VPDdeMdF9AOfY747SV00BsgOfX2rifHSVkKdm42HsEg0GuLnxejTuwXX1rvPx4HyDt1dMHwEfSynbAW8Bs8s475CUMs7wk+/lcXiGIR7kTzG6bNgiG/LWhW7OA2uG2kCuySTP579ZEGJQ4/UO3ktz//OuI+H6cq+hxPTX1Hm3RKzHTJHWdabgRvZYgeQ5anJVU7mC2KWMgkusOLZCa6ppsUtGvGaYhBANgF7AXFfTYqC5EKKNt67hdQyrppsjthFgytC6NmcPJ90O4HDJNBU1Dik5e2Q2y7IbEyDba813GoQC+IU5v9xrKkJAqwcAZ2LXhLDtWlewPYEvsgFbjnLn1VSuIHZpycElFDn0icnYTmN9PDjf4c0VU3PgjJTSBiCllEAqUJokpLUQYrvL3fekF8dw5bQYA35R+Ak7t0bqrpBAe18+ynDORMmtQKapqJ6kbWDepTwC7fr+kRkbI41ValveV3PdeMUYErveYQi29Zct+eJSS5c7T6XZqpF4GLuEECzcv1Brur7R9bSt39a3Y/MhVSF+2A40k1L2AO4EJggh7i7tRCHEc0KIk8U/OTkVZNS9GoSAls4P9oRofRks8OfT9IHOD/Whd5QrpCaSMp+52RBiMEw3hu0g0mJ4jmqiGq8kBiFPYvhm/Ax1mi5ZE9hcACSrYNsaiYexSxfzLrLyuJ5i7e7OpX6l1hi8aZhOAI2FEBYAIYTAuVpKNZ4kpcySUma6fj8JfAEklPYHpZTvSCmbFf+EhoZ6cbgG/J11edoEnqRlgK5syi0czNp8VIqimoiU7Ds4hz35TfCXrbXmURH6iqLaJ2z1FINLOtScz5AwXcgTYk9gXjZKYVoTuYLYpSUHl2Bz2LRmZZhcSCnP41wN3e9qGg2clFIeNZ4nhGgshDC5fg8DbgF2eGscV4UrpgngoSh9/yFAduDd9IbOA+UKqVmkJvF5RjbBdn3/yCKKGBaxWT+nJiRs9RSDkOe2yHVas59syuLM63BIVMbxmkbaBo9ilwA3N16vJr1qrBqvGG+78h4HHhdCHAYmAn8AEELMFELc5jpnNLBHCLEL+AVYAczy8jiuDIMr5PZ6GxHoM4/1WYM4Z0O5QmoSUuLY/BifZztXDMXcGLqDCHOu86CmJGz1FCEgdhwAQ8K3ESB0oWte0Y38UoBa+dc0PJkMNx7BhbwLbkG1d3eq2asl8LJhklIeklL2lVK2k1L2klLucbU/KqVc6vp9upSys5Syu+vfSS6hRNVhcIVEWbK4IVRXNgXZBzFHFV+rWaRtYEN2JqetTfCX+sxxlKEUOa1qgeihJK690iBTIcPC9ZVhiD2BRdmugzPLSnmhotohJSTPK/8clyv6ywNfugXVju1cc9V4xdTdzA8lMbhC7q23Vmv2k82Zeam1c7GkXCE1g9PLmJMFwQbRg58oItHwZU2Le0p5YQ0nZoBzJQjcZlDnWWRDFme1cT661gqkx4rqgSdBtS5X9MJ9uhsvvmk8sZGxvh1bJaAMUzEGV8iwiM34G1wh5wsGsbUQ5QqpIRTkX2RRTjluvNoieiiJENDxeQBuDNtOgMjTurKt/ZzPcOpCNbmq7niSgsjlij6fe541yfq+eG1w44EyTO64XCHBpkJuCtezMgfbbuS/ma5bdfr70l6pqC5IyXf755Fra4q/bKU1jzKsIOjwXO1z4xUT3AyAQFORmzov2N6XpBzAelG5pKs7aRsqXi25XNFfHvjSrcRFbXDjgTJM7sQM0IuvRa3Vmi3UJymzq7McRvbBqhmbwjNSk5ibkeMWu+Rf0o3n+vKulYS1pfhjPSLyF63ZTzZn4aVmzsWSyv9YvTntwT6gyxVtdOP1bda3Rpa4KA1lmIwYiq8NCN1JhFlPUSSLBvBVDnB2jfpQV1ekJH3TeL7Ldd9fujHsV8LNxW4tk+vLu5YS01/bKx0cttUtd16GtS/bCwFrusr/WJ2xViARd7miz+ac5acUPRlxTY9dMqIMU0lc6V0swsGtET9rzcH2vk53nlLnVV/SNrIoIxPpaOzuxosw7Av616vZufEqQgiInwFAmDmf/qE7tS7NnacKCFZfpKxYJu5yRZd0443pVDNrL5WGMkwlMcQ0jYzUZ5VmItmY25mUIpQrpLpy4RfmZkmC7Hq2cAs2hoRv1c/pPaP27i8V02KMVkBwZIRugAJkOxZlxTgfXVVAsHqSmgRF6eWf43JFL9i3QGvq37w/zcJrj4taGaaSGNR58SF7iTTry+pge38+y0K5QqojUpKycwobCiDYoRumvqG7dTWeK69YrcdQQDAxYjMCPcblfGEfdltRBQSrIx6VuHC6ok9nn2Z9ii7oqU1uPFCGqXRa6u68EYYZZ5C9H3OyTEipXCHVjrQNLMy4hElGEuDoqDUPD9cFAHSaWPtXS8W4CghGWzLpGaznf9TdeSiFaXXDkxIXLlf04v2LkThXvAJRq9x4oAxT6cQMMLhC9FmlhShSCzuyrRDlCqlunF7G/GwItscjDI+1nhuvhhcEvFIMBQSNk6sAR2cWZoY7D5TCtHrhSYkLlyvamBsvoWUCTcKa+HZslYwyTKVhcIX0Cd1DhDlL6wq29+fzbJQrpJpxJCOF7YUQZO+rtXUPOkQjv4vOA/+o2i16KImhgOBNBsMkMHOq8AYOWFEK0+qGhyUuTmWdYkOq/t1TW4JqjSjDVBbRfQATfsLOTQZ3ULC9H19kCWwSlXesuiAlCw58hZBBBDnitObhEQY3Xvs/1x03XjEuhWkz/zQ6BupJ/oPt8c7QB6UwrT5ICQemlX+Oq8RF0n79/0wgGN2p9u2bKsNUFjH9tbxjIwwVTy1Ec6moPavyUHnHqgupSSzIzCfI0QOBn9ZszN5Rq4Nqy8KgML3JUO4j0HE9X2a77pNSmFYP0jZ6XOLCqMYbGDuQRqGNfDmyKkEZprIQAjo+C0D/0F2EmfSqpyGO/szNRuUdqw5Iyb51j7LX6tzYL+Y6/5O0Dih2jdTyoNqyMChMh4Zt0ZpNBLIvvxsnilAK0+rChV+ocH+p8QhSM1PZdFKfcNVGNx4ow1Q+rlm2v8nmVmAu2N6Pr7Iht0DlHaty0jay4FIWSAtB9l5a8/CITbrnrrYH1ZaHS2HaJegYMZaLWnOwPZ4luaCCbasBUsL+N8s/JyAaGgxg/l49+NYszLXSjQfKMJWPIe/YzeF6FgiLbIjV0Yqvc1CukCpGpm1iQTYEOrpiIlRrd5OJ14Wg2rJwKUyFgMRwfdUU5OjNl8U1mpTCtGpJ2+BMrlseHV8CIfhi7xda09DrhtIgpIGPB1c1KMNUHoa8YwlhOwkUBVpXsL2P051nzVCukKpCSnZun8LhIuf/RzExlnTigg87D+pKUG1ZGINtDYbJIhvwS14rLtpRCtOqpsJKtc5QhwNpB9h5Vk8xdW+Xe307ripEGabyMOQdCzIVkhC2Q+sKst/A8jw4b3O44g8UlU7aBhZkZIIUbmmIhoVvxiRcK4C6FFRbFi6Faf/QXQQYJlcB9hv4xpUUQylMqwhPKtW6Qh2Mq6UAcwB3drjTx4OrOpRhqogWY8AvCsCtXHWAbAOOGBbkALkVxB8ofII89T0LssFftsVCfa1dj9upY0G1ZeFSmAaarCSE7tKag4pl46AUplWFJ7WXes9AgpthGtl2JBGBEb4dWxWiDFNFCKFtIA8N34LJkHcs2HGDM9j28HvKR18FbEk7QrLNXY0XZsqlb8hu50FdC6otC4PCdKjBnRcg27Eytx65DuDEIvUMVwUV1V5yVar99cyvHE3XY9HGdR3n44FVLcoweYK/c2ZS35JFz2A9jUuQ/QY2F0By7kW1z1TZSMmCQ98C7vtLg8K24W+yOQ/qYlBtWbgUpm6Z1gGTrRc/5KL2maqKrArSQjUa4hQ97NFXS2H+YYxqO8rHA6talGHyhCYjtF+HGbIJBDq6ImQIC7NRkttKxnF+HQuzCrE4muEnm2vtbtke6mJQbVm4FKYN/dLpGqTviQbZ4/mqeJ+pwk14hVeREs6uLv+csPbYHXbm79P/b+7ocAdBfkE+HlzVogyTJxiSuhr3mQQWguw9nftMB/+tXCGVyMad73LK5r5a8hdFDArb5jqqo0G1ZWFQmBrdeYGO6/k2xw+rBJI/V89wZZKaVHG2hyYjWZ+6ntPZp7Wm2qzGK0YZJk8wSG5bBZymTUCq1hXs6MP2QjiSdV658yoLKZl/yFmywWiY+oXuIsyc7zyoy0G1pWFQmCaWyAJRaOvO2jxU7rzKxJPaS64S6kY3Xv2g+iRel+jjwVU9yjB5iktyC+6rpiB7T5AWFuSoCPrKwnZuLUlZVswyigDZQWsfbsyNV5eDasuixRjwi6Rz0DEaWS5ozcFGd54KGK8cPKm9FDsOq6OIpAP6ZOHuznfjZ/Yr50W1A2WYPCWmP/hHAzDMkFXARAiBjq4syEZF0FcSP+35hPN2p/ikGIGDxOIJg0vJpCiBK3eeEO4iiCBHb77OBodEBYxXFp7kxmtxDyuOrSA9Xy+1XhfceKAMk+cIAZ1eACAu+DAxFv1hCbbfwF4r7M9SyqbKYH6qM/rdKBPvEXyQBn6uGWircWq1VBaG0IdiLDKGC7ZWbC4AUAHjPucKcuMZY5eahTejf4u64Z5WhulKcLnzTEKWyDsWDxKnCEJF0PuUIpuVL88cRMgQAh3dtHa33HjhnatgZDWEmAHgF0W/0N0EiEKtOcjeW3fn2fKqZmx1BQ9z4+XZ8llycInWdE/nezCJuvGVXTfepbcw1GgaWiLvmJ9syYJskIUZVTW6OsHqnR+QbpcE2XsisGjtbjJxS3AVjKyG4AoYDzIV0t+YBcLRm69yXJ7ozH1VN766QEVBta6MJd8c+obcolyt9d6udcONB8owXRklajS5zzjjOVQEu4/MV/tMPmThrpmAUw1ZTNuAFFoFFMtplUy8QlwB48Z9pgBHe45bw9lnxZm7TT3DvsNaUUHAy3Pjta/fnusbXe/jgVUflGG6UlxBm0GmQvqF7taagxy9AViQfkntM/mIIpuVr04fAunnVntJz42Hkol7gitgfEiYbpgEJoLsvVTJdV8jJaQsKv+c9n8mo+ASy47qK6t7u9yLqEP7psowXSmGGk1DjHnHHB0wyXAW5IBM/qKMFyuuhVWb/0mGQxLo6I4J3V2nai9dIa6S6038L9Ax8LjWHOTorWTjviZtIxRVsL8U3IyF+xZitVu1prrkxgNlmK4cQwT9EC3LQPGMsyfHi+DXg5+pD7W3kZKF26YC7kG1jfwu0DXIldxSycQ9w1hy3SjisfdgR4GF5CKUbNxXVCgTN0NYW+bsnqO1xDeNp139dj4fWnVCGaYrxRBB39Q/jQ6Bv2ldmjvvUq5yhXgZ69m1LMmygjQRbIhfGh7+i75AanWfWi15iks2bnTnOWPyOrEkB5Rs3Ad4IhMPjOa4pTEbT+iTgge6PeDjgVU/lGG6GlwR9FByxtkTpJmFOSC3TlCrJi+y6shSMhzOTXoz9bT2m4zZHlrcUwUjq6G4ZOPdg48QZdY3492Suqo6Y97FE5l4h7/w+R69cKDFZOGeLnXvuVaG6WowuEJKzjgDHJ1ItcHmLOUK8SYLk50GKMigxgs35xAfutd54ApIVHiISzZuFg4Ghesu6SBHbzbkw3kbqs6Yt/GghLqsf4ObG29EmxFEB0f7dlzVEGWYrhaXKyQu+LDbjDPYEQ/AohypXCFewmq3suTEDpDu2R6GhG3FT7gKNzYfq9x4V4pLNj7UkNTVTzbF5GjC17mANV1NrryFhyXUt1j9OJKuf2/c3+1+Hw+seuJVwySEaCuE+FkIcVgIsVUIUWoIvhDiESHEESHEMSHEJ0KImpeV0OUKuWzGaXfuMy3KAUdRTlmvVlwBK4+t4JLNip9siZ9sorW7y8Qjq2BkNRyXbDwhbAcWbFpzkD2exTkAKjGx1/CwhPqcPXO1w/CAcG5td6uPB1Y98faK6SPgYyllO+AtYHbJE4QQrYDXgASgDdAQGO/lcfgeY8l1txlnMyyOJpywweaUNVU1ulrFwi1vA+5qvABRyMCwX/WTGo8o+TJFRbjqjIWb84gP1bM9BDl6syoPLtlRiYm9hQcl1K1Nb2X+Xt3dN7bT2FpfELAsvGaYhBANgF5AsclfDDQXQrQpceoYYKmU8qyUUgIzgJop0ne5Qi6bcbrUeQsPf6c+1NdIYVEBS35bB0CQwY2XELqTYJMr84arbo3iCjHUGRsSZiwe2Bm7DOYbVXLde3hQQv2HYz9yMV8XR9RFNV4x3lwxNQfOSCltAC6jkwq0KHFeCyDFcJxcyjk1A5cr5LIZp921z5RlxZG8sEqGVltYufN9Mh0SsyOGAKnPcYYb3XixKpv4VeNKTDw03JgFwkKQ43q+LPZEq5Lr14aHJdTn7tbdeC0iWpDQMsHHA6u+VGvxgxDiOSHEyeKfnJxqtmfjiqCHy2ecQgZzygab1o9Xq6ZrYOE+p2EPduixSybsbjJ9JRO/BlwB460CTnOdvy4PD7LH80Me5DiAFJU775pI21BhCfVL9RNYemipdnx/1/vrTCbx0vDmOz8BNBZCWACEM7FTC5yrJiOpQEvDcWwp5wAgpXxHStms+Cc0NNSLw/UCbhH0l884ARZmZCll01VSWFTAkhPbAXc1Xq+Q/dS3ZDkPlEz82jAEjLsVD7T3osBh4odcnJv2yp139VS04vSLJCntFIV2PSl0XVXjFeM1wySlPA9sB4rv6GjgpJTyaIlTFwO3CSEauYzXBKDm+gpcAojSZpwASdngUIbpqlix4z2yHBKTDCPA0UVrdwuq7fiScuNdK66AcWPuRzMR+DvaudR5qDpjV4snMvHYcW5qvJ6Ne9IxpqOPB1a98fZa8XHgcSHEYWAi8AcAIcRMIcRtAFLK48CrwEbgKJCGU81XM3Epm+DyGSfSxGk7/Pzrv5Qr5CpY6PqwBtl7IzBr7cMjXCXUXXVrFNeIENDyXnqH7CfMpNf/CXb05ttcKHAA1gqkzorS8UAmnhw5kHUp67Tjuix6KMarhklKeUhK2VdK2U5K2UtKucfV/qiUcqnhvE+klK1dP49IKYu8OY5KxahsKmXGCbAwPVO5Qq6QQlshX589DLi78ToGHqe5/znngatujcILRHbGT9i5MWy71hRkjydHwqp84MQiNbm6GiqSiftFMvukLpwyC3OdTEFUkrq7u+ZNXMqm0macAEk5YD/9XRUNrmay/OiPZNmsCBlAoEMvkOYWVNv+z8qN5y3MzjIixlW/v2yF2RHjdOcp2fjVUYFM3NFgELN3/Z92fEu7W2gY2tDXo6r2KMPkDVwl150zTj3os3if6YwdNp6rII5B4cbCHR8CEOi4HhOBWrtb7SVX0UaFF3DVGRsUtg1hKMsQ5OjF1zlgkyjZ+JXigUx8TWEgKZl69Mwf4v7g61HVCJRh8gaGkutDS5lxAiw8sly5QjykciDWkgAAIABJREFUwFbA18d/AtyzPTT3P0tHrcyIWZVQ9yYu2Xh9SxbXBx/SmoPsvUl3wE/5QPLn6hm+ElKTKpSJz7qgB9Q2CGnAyLYjfT2qGoEyTN7CNXsfFPbrZTNOgKTMfOzn1pX6UoU7Px79gWxbIUiTtuqEErWXAqPV/pI3McjGjTFigY7uCBngDLZVJdc9R0rYMqHcUzJNESz+bb12/EC3B/Az17y0ob5AGSZv4XKFRFmy6BGsu+2Kv1jP2WHDIVVy3RMWbf9fAAIcnTETrrUPN8rEO/xF7S95m2LZuFsplwACHd34KgccElVy3VPSNlaoxpvvF0eBrUA7Vm48HWWYvEVMf/B31k1xk427ZpwAC3f/n/pQV0B+UT5fH18LuKvxosyZ9Ao54DpSMnGf4AoY7xCYTBO/81pzkD2eM3b4pQBVct1TKiyhDrPOp2m/927Sm84NSi3GUCdRhslbCAGdXgDcs40L/Al0dAcgKbMA+9mfqmR4NYUfj/5Ajr3IWXvJUBQwMXwzZuH6oCuZuO9oeQ9ClIzJ6w0SV7CtKrleIR6UUN8vI9l8fr92rFZL7ijD5E1csvH2gSk0LTHjBDhvh3V7P6miwdUMFu1wuvH8ZWsssoHW7iYT7z1DufF8havO2FCDO89CNH6yFYtzXAt+W17Vja8m4EEJ9Vmm7trvgZZA7u1aMwss+AplmLyJSzbunHHqq6YQRzxI5xfpwhM7q2p01Z78onyWHi8ucaGvloJN+fQP3eU8sERAi9FVMby6gavOWN/Q3QQKff8j2B5Pig22FAKZ+8p+vaLCoNoiCXNO7NGO7+xwJ5GBqtClEWWYvIlBNp5oMEwmGYW/dEqbF58+gM1ecxNd+JIfjv5Ajt0KuO8vDQzbTqDJ2U6jIWq15Gv8Iwg0WekfultrKq7MvCAbZ+43tVdaNtbyJeI/WMM4l5+uHSs33uUow+RtXLLxPiG7CTXpLo9glzsvzS75aeeHVTK06s6CfQsAsDia4C9jtXY3NV5Y+0oeVR3EVWfMuOr3l+0wyQgW5oCjSMnGy0RKSFlU7in/LdIDw1tEtGBIqyG+HlWNQxkmb+OSjQeYbG6lv8MM9YQW7VL7TCXJtebyzaElAATb+2ntfqLIbSOeJioA0ee46owZZeMCE0H2npyywcYClGy8LNI2QlHZ+0unbfDNWT2A+ffdf4/ZZC7z/LqKMkzexhVBD04lWTEmRyssDmcOLOXOu5ylh74mz+asRxNs1xV3/UN3EWF25R9UJdQrB5dsvLH/RToFHtOai0U8C7IBa7qSjZdGBTLxTzMFdunsFwgeuf6RShpYzUIZJm9jiKAfHLYNM3atK8i1arpgl6zdPLlKhlddmb/9PwBYHA0JkHqqoZERhi8/VUK98nDVGRvqFpPXA6TFmZRYSriwqaxX100qkInbJczM1p/fEW1H0DKyZZnn12WUYfIFrgj6SEsOvUN0BVOEwZ23cNvbyhXiIiM/g2Wpzi+5IIMbz4ydYcakraqEeuXhqjNm3GcyEUygozPn7K7ceQf+Rz3DRiqQif+YB6lF+mrq8Z6PV8aoaiTKMPkCQ8l1ozvPYu+CSYYA8GVmIUUq2BaALw98SZHDubIMMbjx+obupp4l23mgSqhXLq46Y92DjlDfrKfWcVPnqVIY7lSQff0jg1ivaVhTlbC1HJRh8hUuV8gwg2GSmAm0O5O6XnTAmqPfVMnQqhvz9zo/0GZZnwDZQWsfYXTjNR+r3HiVTXQfTEIw2M2dF69lgSiSqJLrxVRQQv1kEXyrl2rjkesfwWKyVMLAaibKMPkKVwR9y4CztAvQ661ESYM779jaKhhY9eJszllWJztr1hjVeAKHe+0lfxWAWOm4AsaN+0x+sgkW2YyLDlidhyq5XkwFJdQ/zdIlESZh4tEej1bOuGooyjD5ClcEPbi78wLsPUE6Z0pfndxBkc1aJcOrLiTtT8LhUikZ1XjxIfuI8TN80BuPqOyhKVwB4wNCd+AvdBVp8QRiQQ6q5Hox5WR7sEmYmaWv9ke2HUnziOaVMaoaizJMvsQ/AoBhEfrM3yZDCHR0ASDdLlm984MqGVp14Ys9zlIgJhlJoKOT1u6mxlP7S1VHcDPCzPkMCN2hN7kM05c5UJiv9pmAckuo/5ALJ2268Vaih4pRhsmXuCLouwcdIdqSoTVHG915rmwHdZGUSyn8fPJnoDgFkf44uiVt7fiS2l+qKlwB4zdH/Kw1Bcg2WBwNyXTA93mokusVlFD/KEv/vVl4M0a0Uav/ilCGyZe4JLcmId1y54U6bgDXBOqrE9uwugJL6xoLDEY5xK6viHoG76eRX7HsVtVeqlJcAePDwje7x+S5chnOyQJS6njuvHJKqP9WBN8bRA+PXv+oyvTgAcow+RKX5BZwi8fJtzfAT7YCIMMuWbXj/SoZXlVTrMYzyXDNvQkwwjA7V7WXqhhXwHg9SzZ9QvWM2MEOpzvv21xIL7hUd915UsKW8WV2/+8lXfRgFmYlevAQZZh8jatGU//QXQQZygg0kroCbeGu/1bBwKqWQxcOseOsc98i2N4H0GeRNxv3l1TtpaqnxRiwRLj9vwQ6OmGW9SgCFmYDKV9U2fCqlHLUeHkOpxqvmNGdRtM0vGklDaxmowyTr3G5QgJNVgaF60ldIxy6YfrqzME65877Yq/+RRZikIl3DzpMM39XyWlVe6l6IAQ0GsJN4b8gDHngNHdeNpDyed1055Wzv/Z5NmQY0ub9Kf5PlTCg2oEyTL7GkDvv5nB9xplta4nF4Ux/n+mAFdvfq5LhVQVSSubunguASYYQ6IjT+txWS6r2UvUhvAMN/DLoGXxAaypW5/1cAMdys+peUtdygmqlhA8MC6m4RnH0b65c0p6iDFNl4HKFDAnf6hYP0ljqD+qi3XXHnbf51GaOZTizVju/3PQIeLf9JVV7qfrgUpjebFBLBjq6YpJhAMzNpu4ldS3Hjbfu/9s78/CoqrOB/96ZSSb7Sghhk7AJggsugHUpVi11AUGhoFD6YV1acam41C52sa0tbbUuVKuAUrTViuKKKBaVRVFBdpB9hxAggeyTycyc74+5ufcOJBBgMjOZnN/z5Mk95557573P3DvvPe95lxpYbQtRvKv/XYh+yWoyWjFFAsMUku6s4dK0ZWZ3dsBSTG8VbaC2ztPQ0XHHSytfMrcz/Jea22cmb6KLu8gaqGsvxQ6Gh+lg24uD4CTZH/SYfKkC1LpJrcucd4yg2qdtTnq5ybnc2PfGCAgUP2jFFCkygjng7KaqMl9XXIGC4HYAPloe/+Y8r9/Lq2vrvfEySQicZe4bkrXAGqhrL8UWhodpp8T99E3ebHan+i8BYEsdfFFW0rq88xoJqt1VB29VWu1bz72V5ITkCAkVH2jFFCkMU8iVGV/iwmd1273z1r0WcbEizZxNcyitKQXqUxBZ3njXZNp+1HTtpdjD8DC9NnOh2ZUUOBuHCmY4mV5O6wm2PUZQ7bNlmBFfDnHwkwt+Ejm54gStmCKFYQrJdFXxrbSVZneObZ3p7V3L8dTVREO6iPHSKsuMlxuwzHjnp6ylQ703HujaS7GI4WF6rW1mKzjNHIf/qYDKba3EO6+RoNqqAPzT1j2s1zA6Z3aOoGDxgVZMkcIWbGvPA3eorifOQB4A5QHF3GVPREW8SHCo5hDvbgyW+nCqXPBbQbXXZllv4dqMF6MYHqYdEw9wXso6szvV/20AKhXMLC2Lf3PeMYJqXywPdRG/Z8A9ERIqvtCKKZIYppArM7/AYUvv0hFr1vTqyhejIFhkmLluJl5/0FUpxZaCyIGfq+1mvP5TtBkvVjE8TIfaZk1JgT44A20AmFpO/AfbNuKN51PwuJUSk/4d+nNJ50siKFj8oBVTJDFMIbmucgakrjG7c23Btm/t20SFp7yho1s8djNeW5sZb2DaGtrWl7jQQbWxjeFhenXmopCXq3oniM89sG7jjPg25zWyjvZmJWyzlo954FsPaBfxk0QrpkhiC7a1m/NK6s4ImraAGgVvfPnnqIjXnGw7tI1FO4OzIlcgH5/filEakmnzxtNBtbFPRi/yEg7zrbRVZleaYc4DmFpSFb/Bto0E1SoFf7XNlrpmd2V4r+ERFCy+0Iop0himkMGZi0PSu/TAmkHMWPWvaEjWrMxYOcPcTrPFLrnwhZRU0EG1LQDDw9RuzktQ3XEF2gMwoxxqixc2eGiLpxEz3kIPLLFlFZs4cKLOIn4KaMUUaQxTSNuEQ1xoy9acbvux/qR0LzsObY+CcM1DQAV4cYW1dpavrGu9OH0F2a4Ka7AOqo196oNtMz4nwZbJJNU/CICSALz91aPxac7b3rAZzz5byknO4f/O+b/IyBOnhEUxiYhDRJ4WkS0isllE7jzG2O0iskFEVhh/o8IhQ4vCCLa9LutTs2t/XQ/cASvz8MuL/xhpqZqNeVvnsaNsBwCuQEc8/kJzX0hQra5U2zIwPEwzXVUMSl9qdmf5vwMqaIadUlIJO16PloTNg1KwbcZR3Wtrg+U/6plwwQRSE1MjKFj8Ea4Z01jgDKAn0B94QET6HGP8KKXUOcZf6yvhWp93LOPzkNx5ZzosO/2Mda+j4uSNc9ryaeZ2fmCQuZ0odSF1qnSl2haE4WE6Inue1afa4Tbqav2vBjYs+lF8zZoOLAJ/5VHdfyy1tpMcLiZcMCGCQsUn4VJMo4ApSim/UqoU+C+gk0M1Rt7FkJB11Bunqvu2Wdl2Y9Vhvtr9ZZQEDB+lNaW8uf7NYEMJGYHLzH2XZ3xFhrPaaOlKtS0Kw8P0svSl5DitiNJM/xXm9uSDFfEV09SAN94GL7xqTz90xnXkp+VHUKj4JFyKqTOww9bebvQ1xgwRWS0i00QkL0wytBxEoP/zQKg576CvAzl0N9szvpwUacnCzr9X/duMXXIHzqDabz20w7NsKV10pdqWheFhmujwMSz7E7M71X8RooJ54aaXQ/nOt6IlYXhpxBvv0VLzXZJEgQev+Htk5YpTmqSYRGSxiBxs5K/TCX7mpUqps4BzgYNAoy5oIjJRRHbX/1VWHj2NbrEY3nmXZywh1VFtdvd1DDK3X904h9oWXEBQKRVixuvGd8ztbGcZg9Ktwom6Um0LxLiH7ea8AElm8HSlgunbWv6sH2jQG29rXbAYYD3je1xJx8wT/TnUNESTFJNS6kKlVJtG/nYBO4HTbId0MfoaOtdO438d8ATQaGi0UupxpVTH+r+0tLQmXlYLwPDOS3J4GWxbZymrvQRU8Gspratl9sb3oiXhKbOsaBkri428gCoBX501I7o2ayGJDiMaUQfVtkxEoPd9nJG8jT5JVsbx9upyc3vylsUEAv6Gjm5ZNOCN96dSK1mrC3joe89FVKR4JlymvJnArSLiFJEcgmtORzk1iEiqiGTZum4ElodJhpaH4Z03NPtTs+uwP5dCx9lme9rnLdc7zz5bylH9qVXWi8XwLMv8Q+/79GyppZISrMI8IseaNXl9fc1yLpu8AeYu/nVURAsbDXjj7agzsqkbjCs4jS7ZhWjCQ7gU00vAemATsAR4XCm1GkBEhorIVGNcPvCJiKwSkdXAt4FxYZKh5WF4512ctoI8l+Xa00VdaW7P2bOcnYd3HHVorFPprTTLpwN0VZYZrzBxD/1SNliDjR83TQskvQfg4Lqs+SExTfmB75rbTy3+S8v2ztv5+lHeeH8sxSxe4wB+3vt7ERcrngmLYjK88SYopboqpboppZ607XtHKXWLsb1VKdVPKXWWUupMpdR1Sqnt4ZChRWJ457kkwPXZliPAbs9AXCoYB6GAaYt+GxXxToWXV71MhTdogHeoDEq955n7hmV/YpsgOYwfN02LxPDOy3GVc2WGtZ6U5r8SlAuAOVU+Vq94PFoSnhoNZBLf6IUXbLOlm9Khe88xERYsvtGZH6KJzTtvZPb/zG6vSmSA04ppmrbuTXwB31GHxypKKZ5Z8ozZ7i2X4sdltkPMeInZ2huvJWPL/zg2932z2xPIIitgfa9/mf/zljlrasDp4eGS0LWl3+an68DwMKMVU7TpPAISc+metJtzU74xux0+Kx5kT00Zcza+39DRMcminYtYvd+ebslaDD8/ZS2d3cXWYO2N1/LpPAISsrgwdRVd3bvM7kJlpZd6payOHVtaYCaII2KXlnngNZtV77ZM6HbxC/oeDjNaMUUbWwFB+6xpZ21POonl6Pj8Fy0npumZpdZsqY0qpMhrmepusJkstTdenGDM/EVgbO4cs7u0rg/uQPAe9gOPfd5y7mGgwdilX5RY28kCv8pL1/dwM6AVUyzQZiAgXJu1gCTxmN1niuUE8f6Oxewu3x0F4U6MfZX7eGPdG2b7bId1DcniCSnLzYCp+k0zXug8Apxp3JA9L+QePsdhzZqm7ljBweqD0ZDu5DjCjPdJNXxohRzy0ywo0LOlZkErplgg7yJwppHurOEqWwmIPZ5BOIwF5ACK55fGfpzE1GVTqQsEvbNEJVDssVIQXZO1kHRnTbDhTNVvmvGECBSOI9NZxXVZ883uw57vIIYjT03Az2Of/y1aEp44ttglv4J7D1i7shzwQF6GvoebCa2YYgERKPwBACNzPjK7D/uzuCjhQrP9zyVPxXQmCK/fG+L0cKHrQioC6WZ7dM5ca3DhOP2mGW90GQ3AD9rMNrs8KpkLHJYr9VNfPsH+qv0RF+2EOSJ2aVo5rPRau3+RA9kdLtf3cDOhFVOsYDzUA1PX0DXRMtm5664xtw94ynl1zSsRF62pvLL6FYoqi8x2mt+KZenq3sV5NucOTtM5fuMOI/yhb/JWBqZa1W3raoearuPVvlomLWoBFZptsUuH/fBL29pSjwS4Jwtd1LIZ0YopVjAeaocoxtjcbjd5+tLLaTlBPLnwkZgsh6GU4m+LLTNNL1c+G2rOMdujsj+yXi513aX4RAS63ATAbXmzzO5Sfy6XuKzikM8s+Qd7K/ZGXLwmc0Ts0iOlcNCWVenxNsGErbqoZfOhFVOsYItpGnHEAnIvrAdgeek2PtsZe6UE5m6Zy5r9a8z2eTanBxe+kABiXXcpjjktOPMflP413d1WukzxDjfTcHv8Xh5d+Gg0pGsaO183nR7We+FpWxjT4BS4JhVIyNIvV82IVkyxhBEPkukKXUDeUH0Z2ZJstp9cEHu5xx5b/Ji5ne9wsaHKMuN9J2MJeQn1T7euuxTX5F0MzjQcorg1702ze4e3kO+6zzXbz339HBsObmjoDNHFNlsKKLh9v5V6yAn8Pc94p+o/Rb9cNSNaMcUStlnTD2zmvOpACoMSrFxzs7bOZ0vploiL1xgr9q3go62W08ZV7gs54Msx22NssS0kpOtMD/GM4Z0HwVpjbVyHzF0u7yicxqzJF/Bx39z7oiHhsbG5iE8rhwU11q67s6B3Ijr+LgJoxRRrGPEgfVO2cE7KerN7f81QXEY5jACKv3wWO8GKv1/we3M7WeCwx3LY6JK4l0vSbAnkTxuj3zTjHcORJ8lRx81t3ja719b0YWSylTl/9qbZfLj5w4iLd0wMF/EiHzxgC7nq7IJHco2Gjr9rdrRiijVsb5zjc98xu3d7OzDY3d9sT1/xInvK90RcvCNZVbyKWd9YC92jU05jeXVfsz02dzYOsTlraG+8+Mdw5AEYlzubbFvp9Zram8ix/abf++G9sZMH0nARVwruOgBlAWvXs20hzYGOv4sQWjHFIsYb59VZn9EhwYr5UN7h1D/T3oCPx23rOtHCPltKEsjwX2tre0LSLOkF41aCzSSd5qwJ8dBbUd2H8amWt+Y3B7/hqS+firiIDWK4iL9cAW/Y8uGNToOrU42Gjr+LCFoxxSLGG2eC+Bl/hClksLuX2f7n0mcoqS5p6AwRYc3+Nby+zkrMOT49lbllg8z2sOz5ZLqqrAP0gnHrwXDkgeCsKcc2a9pSNYbeCdbQX338K7Ye2hppCUMxnB6218EEW4aHXAc8kWcbp2f8EUErpljE9sY5Omcu6Q7r9S3TN9zcrvbVRjXFyyPzHzG33QJd1PeoDljegz/ItZWF1wvGrQvbPZzq9ITMmpZX9+bWVMszs8ZXw+3v3R7d+Lydr+P3HuYH+6DCZsKbmg/59RVb9Iw/YmjFFKsYb5xpzhpuyv3A7P6y8kIud1sVX5/48u8UVRQ1dIZm5as9XzFz3UyzfUu6izdKh5rtAamr6ZO8zTpALxi3PgxHHoBxbd4LqdL8dsnN3JZh1ej639b/MW35tIiLCJizpUdKYZEVPsgtGTAszTZOz/gjhlZMsYrtjXN8m3fNstUKBwX+0eawGl9tyDpPJFBKcf/c+812isDZzm9T7Ms1+27PszKM6wXjVorNkSfFUcv97V4yd233tudsuZoOlm7ing/uYf3B9UeepfnZ+TrvHTrMI5bepHtCMGbJRM/4I4pWTLGM8cbZLqGEUbYEqIsqLmVIkjVrmrJsCptLN0dMrHc2vMPCnQvN9v1ZwsyS6812D/cOBqV/bR0w4EX9ptla6WK9RI3InkevJGsW/dyBG3ki15qSVNdVM/r10Xh8HiKGUmxaeDNjbbUr3QKvtjO88OrRM/6IohVTLGN747wjbyaJtllTrn80TmOYL+DjwY8ejIhItb5aHvyf9VntnNA/4Tw21lr5/G7Ne9NyEXemw2kjIiKbJgbJuxgSgzNppwT4ZYFlrivzp7OqYiz3ZlnDVxav5O45d0dsvenAxhe4emdlqGt4HpyXZBukZ/wRRyumWMd442yfeJBROVYw4qfllzI6pZPZfnP9m3yw+YOjDg83kz6bxMaSjWb7dzkw/cBIs93WVcJ1WZ9aBwzUhdRaNSIweInZvCR9BZelW+2XSq5mdHJP+rmtQ6Ysm8KTXz7Z7KJVe6sY8vbtbK6z+m7PgPGZRwzULuIRRyumWMcWrHjkrCnRO5Ys2zd45/t3NqsZZFPJppDkm/3ccLrzbJZU9zH7bm7zDm6HETCp7fIagPRCOG+y2fxN++dxS7CumMLBr/fexX/ynWS7Es0x9829j3c3vNtsItXU1TD8XxfxZY2VNvyKZHiqbQODtYt4xNGKKdaxOUEUJJZwY441K/q44iLuSD3DbG85tIVJi5onVZFSip/M/gm1/uAPigN4Lg+eLB5rjslxljHWluNP2+U1Jj3vMD30uriLuDvfqg673lPIx2XDeSPfi8thVGxWAUbOHNksVoDqumqGvDKEuXtXmn1nJ8IbBUY5CztJ7bWLeBTQiqkl0HlEcPYB3Nn2v6Q6qs1dayp+xLm2p+kPC//A0r1Lwy7C5K8mM2/bPLM9IROqfeeyrLq32Xd73huk1ZdOdyTp2ZLGwrZeCsF6TacnbTfbTxTfRAdHZ/6Rb82aav21DHt1GHM2zSFc7KvcxxUzrgi5l7slwPsdIMPZwAHf/Vy/XEUBrZhaAiIwYAoAeQmHuaOtFT+0suZ0xiZfGuIIMXbWWKrrqhs40cmxdv9aHvjoAbPd0QWP5AiP7bNmS21ch0JKatPnF/qB1oRi89BLED+PdpiMEPQ68KpE7t75AONS6vjTWdeZ42r9tQx5ZQjPLnn2lD9+WdEy+k/pz+Ldi82+ngkwvyO0dzVwQLcfQ9ppDezQNDdaMbUUbCleftTm7ZAceq8evJmHsqyMCxtKNvDTD34alo8try1nxMwRpglPgBn58HHFIFbV9DTH3Z43ixRHrXVgn1+G5fM1cYTNQw/gvNT13Gar2bTeU8ifi8bzUM3b/PGyP5j9fuXnjvfvYOyssRz2HOZE8QV8TFo0iYFTB7KrfJfZ3zcRPu1ISCxVCEY1Xk3k0YqppWBba0pyeHmw3XRzV7EvF/GOY6DNxXXKsik8s+SZU/rIgAowZtaYkKDHB7JhQJKbv+z7odnXIaE4NP3Q+c+AQ99amiM4wkMP4L78l+ibbMXgTS8ZyrzyC/hFcglPX/U0DrHuo3+v/jdn/OMMpi2b1qSM5EopZm+czTn/PIeH5j1EXcByvxuSCp93goLGlJJeW4oq+tejJdF5BCQVADA0awEXpa0wd71ccg2/zOhJpu0bvXvO3Sdtn1dKMWH2BN7baCmcS5Kd/D4Xntt/A/vq2pj9Py94kSSH8dAn5ECPH5/UZ2paAUd46CU6fDzZ6a8ki+VN+tOd97N59Uzu7H0Ns2+aTXZStrmvqLKIW969ha5PduU3n/yGL3Z/gdfvNffX+mpZXrScPy38E2c8cwbXvnItaw+sNfc7gIdz4M0CSG/010/02lKUkagmTjxBOnbsqHbv3h1tMaJL5XZ4pxCAbbXtGbxxMl4VXDA+PWk7dxbcy7B9ddTHC7qdbt4e/TaDuw9u8kcEVIB7P7iXp76yyhF0Sslmaf4hqv0FDN44mVoVDDw5P2UtM7v9zHqGh2yD9C6neJGauEYpeC0d/Fbm+ddKr+TB3feY7a6Ju3mz1+/IvHEPeyr2Mv7t8SFVku0IQpuUNigUh2oO4Vf+Bsf1Ss/nhcxiLkxucLfFt16DLiOPM0hzqojIHqVUx4b26RlTSyOtC/T9HQCF7r3c3dZyu93g6cKyiv8LyfFV669l6KtDmbpsapNOX+WtYuTMkSFKKdudyXttDpHnhId232UqJSHAw+2nWkqp8xitlDTHRwQGvBDS9f2cj0LMwVu9Hblr64+pWzuZDhkd+HDsh7w+8nV65PQ46nQKxYHqAxysPtigUmqX1o6nLrqHVflNUEquTJ2pJAbQiqkl0vdXYJQMvC1vVoiN/sWD13GW81wetdaY8fq93PrurYydNZbiymIa49Ptn9LvuX4hFWkzEtOY27aMs9zwSulgvqg6y9w3Lnc2Z6dssk7Q4/ZTvzZN6+C0kaYzTz2/bj+FgamrzPaCyvO4772d+PfMR0S44YwbWDdhHe+MfofrTr+O1ITUI89qkuRK4uoeV/Py8JfZcfc27tr/NAlNsczp2LuYQJvyWiobn4GlEwDY4unAtZu8/T8+AAANnklEQVSepEYFvR9ynYd5q8dE/lu1nwcPgv0bTnYlM+bMMVzV4yoKswrx+Dys2LeCV9e+yoIdC0I+on1aPu9kH+C8pACbPR25dtMTeIzPaJ+wn7k9J1hxS0ntYfhu/VBrmk7FNni3a0hXqS+DYZsfY6e3wOy7MecDHv3BSKTg0pCxdf46lu9bzrZD29hXuQ+Xw0WGO4NebXrRp20fUhJSggOXToSNfz++PO4CuH6PvocjxLFMeVoxtVSUgjc7gCdYi+mVksH8fM9d5u5eSdt4vduDLPDUcNM+QpJUNoWBHQbyeuomOqgSagJuhm/+G+s9heb+6YW/ZlD6MuuAodt1zIfmxPl6ImwIVRrbawsYuWUSB3w5Zt/Y3Nn87tb7cGZ1O7Hz750Pnw5qwkAHDN2q7+EIoteY4hExPIcMk97onA8ZnvWxuXu9p5B7dj7AlSlO1nSGEWmNnOcIspKy+OsVf2Fh3wvooEoIKGHirokhSumWNm+GKqUL/6sfaM3J0e9vHPkz1MVdxMtdHybLWW72vVxyDXc/+zy1TS3vohQs/10TlRJw7WZ9D8cQWjG1ZNK6wLeCzg8i8KeOT9MvxYo5mlfRn5/uvJ92LgczC2BlZ/jJWWPolNEp5DQuh4sBHQbw+HcfZ9uP5nP/3r/g2vo0SsGfisYzp+wic+xZyRt5sN2/rIMT87QHk+bkcTjg8k+P6j49aQczCn9NhrPS7Jtddik3P/NfDm+ff+xzVm6HmXnwzW+bJsO5/4CMwuOP00QMbcpr6Rxh0jtQl8WwzY+zp85Kk3xF+pc82fmvpDqNWJGeP+VQ719RXHOARGciHdI74HYmwrbX4IvR5mn/UHQL0w4OM8+T7yrhre4TKUgsMXq0+UMTJooWwCffPqp7fc1pjNv2CPtt1ZE7Juzjn5fuoO/lvw0N5FYq5B5uEq5MGHlIrytFAb3GFO9Ubod3ugNBV9nttQWM2vLnkFLnvZO2MrnzJLol7bGOc6SBIxkIgK/EOp0/mZ/vvpN3y6wfihRHDa91+xl9k7caPQJDtmr3cE34+GYyLL/rqO5d3raM2/p7tnk7mH2J4uXhgqmMabsYhzMBAh7wlx917HHRcXdRo9nXmETkGhH5WkRqReSJ44ztISKfi8hGEVkiIn2ONV7TBNK6wJBN1K83dXEX8Uq3n9Pelk/vG09Xrt70FE8Xj6LCbwRzBCrBd8BUSkrB/IpzGbLpiRCllOao5l+Fv7EpJeDaLfqB1oSXXhMg8eiCSJ0S9zOr+/1ckmata3pVIg/vvYMxm+5nV5WcnFL6zkJ9D8coYZkxiUhPIBkYCaQppRrNICoiHwMzlFLTRWQE8DOl1AVN+Rw9YzoO5VvhPctraX9dFrduf5iVNaeHDMt0VnBN5iL6p64lP6EET8DNOk8hc8ouYk1N95CxOc4yXij8HeekWFVr+c5CaKfziGmagSNm/3b8ysETxTfx9P5QU12SeLgtbxa3582yzNXH47L5cIT7uabp+PwB/ErhdjVUK6RpRMyUJyK/BbIaU0wi0hbYDOQopXwiIkARcLFS6rjuNloxNYHihTDPeuA8gUT+um8cLxwcijrBCXL/1DU81fmvtEuwzHxctgAKLgmXtBrN0VRsg3e7ERqBZ7Go4mx+tvuekHVUgLauEia0ncn3cz4i2Z7p/kgufA0KtcNOY/gDioOVtew9XMO+Mg97yzzsK6sx/nsoOlxDcUUtj1zXhzEDTn59OZYU03nAf5RSp9v6vgIeUkp93MD4icDE+nZmZmaHw4dPPO19q6NsC8wOnfl8XdWLSft+yFdVZx738CxnOffm/4cxue/jElsAlFZKmkhxHOVU4U/m0aKbeaX0qqP25ToPM67Ne3w/+yObo47BoPnQvvXOlJqqdPyB4+uFOy/rzv2DTz/uuMY4ZcUkIouBo5NUBemnlNpljPstYVRMR6JnTCfA/kXwv6OVyNKq3rx1eBCLKvqxw9vOnEWlOao5P3UdgzMWc132p6G1lUCb7zSRp3I7zLkA6g42OmRVdXf+UHQLX1X1PWqfAz+Xpi/n+uyPGZS+lIwrP4zre7jOH+BgZS37DCVzKkqnKVzfrwOPjzrnpI+PpRmTNuVFkkAAlt4Hmxv2R/EEEqkMJOPCT6azsmGPWVcWXLVcLxJrooNSsP4fDXrr2YfMLR/I5P2jWF3T8PtzgkMY2C2XS3vkcX6XbPq0zyTR1TLCOOsVzv7yWorLPRRX1HKg3ENxeS37K6z/JVVemsPJOic1kXYZSbTPSqJdZhIFmcm0z0qiZ346fdpnnvR5Y0YxGWM+BabbnB8eUkqd35Tza8V0klRsgw/OhboTNIOe9w/o+RMd46GJPk24h5WCzyrPZurB4Syo6EeAxhfmkxIcnNUhi57t0ujRNp0e+WkUtkklL82Ny9m8CisQUJR76iip8lJa5aWkMvi/tKrW7Kvv319RS0lVbbMoHAgqnYLMJAoyLaVTYPvfLjOJpISTd3A4Fs2umETkcuBfQAZBn+Uy4A6l1DsiMhQYqpS6xRh7OjAdyAXKgfFKqdVN+RytmE4BpYKOEZufg5Jl4C0FVQe4gopH1YHTHXQ97zIGetyhq9BqYov6e3jTP+HAZ+CrIOT+lQRISIHkdhTljeONQ5cza8Veth6oOu6p63EI5KW7aZeRRHZqImluF+lJLtKTEkhJdOJyCA6H4BTB6RBEhDp/gDpfAK8/gNf4X+sLUOHxUeGpo9LjM7crPD4qvb5mUzR27EqnIDPZUDyRUTpNQQfYajSaVsuWA5XM+6aYj9fvZ8Wuw3jqTjCjcYyR7naRl+EmPz2J/Aw3+RlJ5KUH/+dnJNE23R11pdMUtGLSaDQawOsLsK6onKXbS1lXVM6m4ko276+kpq7hqreRIjXRSU5aIjmpbnJTE8lJTSQ3NZG8dDdtM5LIN/63TXeT6nZFVdZwcSzFFB9XqNFoNE0g0eXgnE5ZnNPJKlIYCCj2HK5hz+Eaiss9FBlebOWGGa6y1voLBBR+pQgEgq7XAaVIcDpIdDlIrP9vbKclGWZAd9AUaLaTEshIcpGb6iYnLaiAYn12E2m0YtJoNK0ah0PolJNCp5yUaIuiMdCr2xqNRqOJKbRi0mg0Gk1MoRWTRqPRaGIKrZg0Go1GE1NoxaTRaDSamEIrJo1Go9HEFFoxaTQajSam0IpJo9FoNDFFi0pJJCK1wIFTPE0aUBkGcWIVfX0tn3i/xni/Poj/awzH9eUppdwN7WhRiikciMjuxvIzxQP6+lo+8X6N8X59EP/X2NzXp015Go1Go4kptGLSaDQaTUzRGhXT49EWoJnR19fyifdrjPfrg/i/xma9vla3xqTRaDSa2KY1zpg0Go1GE8NoxaTRaDSamKJVKyYRaSsixSLyVrRlCScicreIrBGR1SKySkTGRlumcCAiPUTkcxHZKCJLRKRPtGUKFyKSJCJvGde2UkQ+EpHu0ZarORCR8SKiRGRYtGUJNyLiFpHJIrLJeP5ejrZM4URErhaRZSKywviN+WFzfE5rr2D7HPAekBttQcLMWuAipVSZiHQClovIYqXUlmgLdoo8BzyvlJouIiOA6cAF0RUprDwPzFFKKRG5E5gKDIquSOFFRLoAtwJfRFeSZuPPgAJ6Gt9ju2gLFC5ERICXgUFKqVXGd7leRGYppSrC+VmtdsYkIj8CtgELoy1LuFFKzVNKlRnbu4B9QKfoSnVqiEhb4HyCDwbAG0CneJlVKKU8Sqn3leWN9AXQJYoihR0RcRBUtncBtVEWJ+yISCrwI+CX9d+jUmpfdKUKOwrIMrYzgBKa4btslYpJRAqBHwO/jLYszY2IXAFkA0uiLcsp0gkoUkr5AIwHfyfQOapSNR/3AG9HW4gwMxH4TCn1dbQFaSa6AaXAL0RkqYgsFJHLoy1UuDCeuVHALBHZASwCfqiU8ob7s+LSlCcii4EejezuB7wA3KmUqgnOTlsWx7s+Y5aEiJwJvAiMUkpVRUo+zakhIr8AugNx86MmIn2BG4BLoy1LM+ICTgPWKaUeEpF+wEci0kcpVRxl2U4ZEXEBvwKuV0otEJELgHdE5Eyl1MFwflZcKial1IWN7RORTOAs4L+GUkoDUkRknlKqRfwQHOv66hGRMwiun92slFrU/FI1O7uAAhFxKaV8hr27M8FZU9wgIvcD1wNXKKWqoy1PGLmEoGlyk/HctQOeF5ECpdSz0RQsjOwEAsC/AZRSy0VkG3Am0OIVE3AO0F4ptQBAKbVERHYTfNn/KJwf1OpMeUqpMqVUrlKqi1KqC3A/MLelKKWmICK9gfeB25RSYb1hooVSaj+wDKj3MLwB2K2U2hw9qcKLiEwEbgSuVEodjrY84UQp9axSqsD23H1B8P6MF6WEMWuYBwwGc8mgEPgmmnKFkfqXw94AxvpuN2BDuD8oLmdMGp4CMoFJIjLJ6PuZUurDKMoUDm4HphumrnJgfJTlCRsi0hF4DNgKfGLMKmqVUgOiKpjmRPkxMM147gLA7UqpPVGWKSwopYpF5DbgNREJEJzY3KmUCrvVQqck0mg0Gk1M0epMeRqNRqOJbbRi0mg0Gk1MoRWTRqPRaGIKrZg0Go1GE1NoxaTRaDSamEIrJo1Go9HEFFoxaTQajSam0IpJo9FoNDGFVkwajUajiSn+H0WqRgZ05oWdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 480x320 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = torch.unsqueeze(torch.linspace(-4, 8, 800), dim=1) \n",
        "y = torch.sin(x)  \n",
        "p_t_second = Psi_t(x)\n",
        "p_t_first = net2(x)\n",
        "fig, ax = plt.subplots(dpi=80)\n",
        "ax.scatter(x.data.numpy(),y.data.numpy(), color = \"orange\")\n",
        "ax.plot(x.data.numpy(), p_t_second.data.numpy(), 'g-', lw=3, label ='new method approximation of P(t)')\n",
        "ax.plot(x.data.numpy(), p_t_first.data.numpy(), lw=3, label ='Neural Network approximation of P(t)')\n",
        "#ax.plot(x.data.numpy(), yrk, lw=3, label ='RK approximation of P(t)')\n",
        "\n",
        "plt.legend(loc='best');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w90OsDqUPWFW"
      },
      "source": [
        "# Solution of O.D.E with RK method:\n",
        "I have the O.D.E $$ \\frac{dy}{dt} = N1(t)*N(t) = f(t,y(t)) ,y =p(t)$$\n",
        "The RK methods is:  \n",
        "1. $$ k1 = f(tn,yn) = N1(tn)*N(tn) $$\n",
        "2. $$ k2 = f(tn+\\frac{h}{2}, yn+h\\frac{k1}{2}) = N1(tn+\\frac{h}{2})* N(tn+\\frac{h}{2})$$\n",
        "3. $$ k3 = f(tn+\\frac{h}{2}, yn+h\\frac{k2}{2}) = N1(tn+\\frac{h}{2})* N(tn+\\frac{h}{2})$$\n",
        "4. $$ k4 = f(tn+h, yn+hk3) = N1(tn+h)* N(tn+h) $$\n",
        "So, $$y^{n+1} = y^{n} +\\frac{1}{6}(k1+2k2+2k3+k4)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BMdQ0USjPWFX"
      },
      "outputs": [],
      "source": [
        "x = torch.unsqueeze(torch.linspace(-4,4, 2000), dim=1) \n",
        "N = len(x)\n",
        "h = (4+4)/N"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.sin(x)"
      ],
      "metadata": {
        "id": "qYFUz4hacBXP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_k0jC169PWFX"
      },
      "outputs": [],
      "source": [
        "yrk = np.zeros(int(N))\n",
        "yrk[0]=net2(x[0])\n",
        "for i in range(0,int(N-1)):\n",
        "    k1 = net1(x[i])*net2(x[i])\n",
        "    k2 = net1(x[i]+(h/2))*net2(x[i]+(h/2))\n",
        "    k3 = net1(x[i]+(h/2))*net2(x[i]+(h/2))\n",
        "    k4 = net1(x[i]+h)*net2(x[i]+h)\n",
        "\n",
        "    yrk[i+1] = yrk[i] + (1/6)*h*(k1+2*k2+2*k3+k4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nL3iZXFGPWFm",
        "outputId": "8db38d6d-ee6f-4937-b604-42e4285fcbb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(x,yrk, label ='rk')\n",
        "plt.plot(x,y, label ='analytical')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koYNtfIXPWFn",
        "outputId": "fa5587ae-8344-4c59-d62b-ef2c072c36b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.043492283363593745"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "y_num = y.detach().numpy()\n",
        "abs(np.mean(y_num-yrk))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change of range of x:**"
      ],
      "metadata": {
        "id": "Co-Hx_TUdLsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.unsqueeze(torch.linspace(-3,5, 2000), dim=1) \n",
        "N = len(x)\n",
        "h = (5+3)/N"
      ],
      "metadata": {
        "id": "w8SPkjJwdPz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analytical\n",
        "y = torch.sin(x) \n",
        "#rk\n",
        "yrk = np.zeros(int(N))\n",
        "yrk[0]=net2(x[0])\n",
        "#yrk[0]=y[0]\n",
        "for i in range(0,int(N-1)):\n",
        "    k1 = net1(x[i])*net2(x[i])\n",
        "    k2 = net1(x[i]+(h/2))*net2(x[i]+(h/2))\n",
        "    k3 = net1(x[i]+(h/2))*net2(x[i]+(h/2))\n",
        "    k4 = net1(x[i]+h)*net2(x[i]+h)\n",
        "\n",
        "    yrk[i+1] = yrk[i] + (1/6)*h*(k1+2*k2+2*k3+k4)"
      ],
      "metadata": {
        "id": "HlqN4uJ6eKsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x,yrk, label ='rk')\n",
        "plt.plot(x,y, label ='analytical')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Ps42mEM2dV8F",
        "outputId": "1b4ce5c6-4e29-4425-b24d-802dd117e86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sLdisoWbtLlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}